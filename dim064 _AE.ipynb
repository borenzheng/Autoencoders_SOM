{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for dim064 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model,load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "x_train = pd.read_csv('./dataset/dim064_train.csv')\n",
    "x_test = pd.read_csv('./dataset/dim064_test.csv')\n",
    "y_train = pd.read_csv('./dataset/dim064_train_label.csv')\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = pd.read_csv('./dataset/dim064_test_label.csv')\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Normalization\n",
    "# #x_train.max().max()\n",
    "# x_train = x_train.astype('float32') / 157.\n",
    "# x_test = x_test.astype('float32') / 157."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Basic Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                832       \n",
      "=================================================================\n",
      "Total params: 1,612\n",
      "Trainable params: 1,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0677 - val_loss: 0.0658\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0639 - val_loss: 0.0626\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0611 - val_loss: 0.0604\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0593 - val_loss: 0.0590\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0582 - val_loss: 0.0580\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0574 - val_loss: 0.0573\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0568 - val_loss: 0.0568\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0563 - val_loss: 0.0563\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0558 - val_loss: 0.0559\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0554 - val_loss: 0.0554\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0549 - val_loss: 0.0550\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0544 - val_loss: 0.0545\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0539 - val_loss: 0.0540\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0534 - val_loss: 0.0535\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0529 - val_loss: 0.0531\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0524 - val_loss: 0.0526\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0519 - val_loss: 0.0521\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0514 - val_loss: 0.0516\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0510 - val_loss: 0.0512\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0505 - val_loss: 0.0507\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0500 - val_loss: 0.0503\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0496 - val_loss: 0.0498\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0491 - val_loss: 0.0494\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0487 - val_loss: 0.0490\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0483 - val_loss: 0.0486\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0478 - val_loss: 0.0482\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0474 - val_loss: 0.0478\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0470 - val_loss: 0.0474\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0466 - val_loss: 0.0470\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0462 - val_loss: 0.0466\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0458 - val_loss: 0.0462\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0454 - val_loss: 0.0459\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0450 - val_loss: 0.0455\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0446 - val_loss: 0.0451\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0443 - val_loss: 0.0447\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0439 - val_loss: 0.0444\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0435 - val_loss: 0.0440\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0431 - val_loss: 0.0436\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0427 - val_loss: 0.0433\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0424 - val_loss: 0.0429\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0420 - val_loss: 0.0426\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0416 - val_loss: 0.0422\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0413 - val_loss: 0.0419\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0409 - val_loss: 0.0415\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0405 - val_loss: 0.0412\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0402 - val_loss: 0.0408\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0398 - val_loss: 0.0405\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0395 - val_loss: 0.0401\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0391 - val_loss: 0.0398\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0388 - val_loss: 0.0394\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0384 - val_loss: 0.0391\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0381 - val_loss: 0.0388\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0377 - val_loss: 0.0384\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0374 - val_loss: 0.0381\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0371 - val_loss: 0.0378\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0367 - val_loss: 0.0374\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0364 - val_loss: 0.0371\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0361 - val_loss: 0.0368\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0357 - val_loss: 0.0364\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0354 - val_loss: 0.0361\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0351 - val_loss: 0.0358\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0348 - val_loss: 0.0355\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0344 - val_loss: 0.0351\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0341 - val_loss: 0.0348\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0338 - val_loss: 0.0345\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0335 - val_loss: 0.0342\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0332 - val_loss: 0.0339\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0329 - val_loss: 0.0335\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0325 - val_loss: 0.0332\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0322 - val_loss: 0.0329\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0319 - val_loss: 0.0326\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0316 - val_loss: 0.0323\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0313 - val_loss: 0.0320\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0310 - val_loss: 0.0317\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0307 - val_loss: 0.0314\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0304 - val_loss: 0.0311\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0302 - val_loss: 0.0308\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0299 - val_loss: 0.0305\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0296 - val_loss: 0.0302\n",
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0293 - val_loss: 0.0300\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0291 - val_loss: 0.0297\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0288 - val_loss: 0.0294\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0285 - val_loss: 0.0292\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0283 - val_loss: 0.0289\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0280 - val_loss: 0.0286\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0278 - val_loss: 0.0284\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0276 - val_loss: 0.0282\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0273 - val_loss: 0.0279\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0271 - val_loss: 0.0277\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0269 - val_loss: 0.0275\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0267 - val_loss: 0.0272\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0264 - val_loss: 0.0270\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0262 - val_loss: 0.0268\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0260 - val_loss: 0.0266\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0258 - val_loss: 0.0264\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0256 - val_loss: 0.0262\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0255 - val_loss: 0.0260\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0253 - val_loss: 0.0258\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0251 - val_loss: 0.0256\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0249 - val_loss: 0.0255\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0246 - val_loss: 0.0251\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0242 - val_loss: 0.0247\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0239 - val_loss: 0.0244\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0238 - val_loss: 0.0243\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0236 - val_loss: 0.0241\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0231 - val_loss: 0.0236\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0230 - val_loss: 0.0235\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0229 - val_loss: 0.0233\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0227 - val_loss: 0.0232\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0226 - val_loss: 0.0230\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0225 - val_loss: 0.0229\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0222 - val_loss: 0.0226\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0219 - val_loss: 0.0224\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0218 - val_loss: 0.0223\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0217 - val_loss: 0.0221\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0216 - val_loss: 0.0220\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0215 - val_loss: 0.0219\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0214 - val_loss: 0.0218\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0213 - val_loss: 0.0217\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0212 - val_loss: 0.0216\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0211 - val_loss: 0.0215\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0210 - val_loss: 0.0214\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0207 - val_loss: 0.0211\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0206 - val_loss: 0.0210\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0205 - val_loss: 0.0209\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0204 - val_loss: 0.0208\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0203 - val_loss: 0.0207\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0203 - val_loss: 0.0206\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0202 - val_loss: 0.0205\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0200 - val_loss: 0.0204\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0200 - val_loss: 0.0203\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0199 - val_loss: 0.0202\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0196 - val_loss: 0.0200\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0194 - val_loss: 0.0198\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0194 - val_loss: 0.0197\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0193 - val_loss: 0.0197\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0193 - val_loss: 0.0196\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0192 - val_loss: 0.0196\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0192 - val_loss: 0.0195\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0191 - val_loss: 0.0195\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0190 - val_loss: 0.0194\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 28us/step - loss: 0.0189 - val_loss: 0.0193\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0189 - val_loss: 0.0192\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0188 - val_loss: 0.0192\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0187 - val_loss: 0.0191\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0187 - val_loss: 0.0190\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0187 - val_loss: 0.0190\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0185 - val_loss: 0.0189\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0185 - val_loss: 0.0188\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0185 - val_loss: 0.0188\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0184 - val_loss: 0.0188\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0184 - val_loss: 0.0187\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0184 - val_loss: 0.0187\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0182 - val_loss: 0.0185\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0182 - val_loss: 0.0185\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0182 - val_loss: 0.0185\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0178 - val_loss: 0.0182\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0176 - val_loss: 0.0179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3gVZfr/8fednFTSIISW0HuHEEAUBUSRoqCAAvaKKK66rrsLq2v77vrT1bWsvaMuglhQrFhwVWwQlCK9BQklvfeTPL8/ZoIhnIQEcjIp9+u6znXOmXnOzJ1J+eSZ8owYY1BKKaUq83G6AKWUUg2TBoRSSimPNCCUUkp5pAGhlFLKIw0IpZRSHmlAKKWU8kgDQql6JCJGRHrUoN1YEUk82eUodTI0IFSTISL/E5EMEQmoNH2RiBSLSG6Fxwan6lSqsdCAUE2CiHQBTgcMMNVDk38ZY0IqPAbXZ31KNUYaEKqpuBz4EVgEXHGiCynftSMifxGRZBE5JCLni8hkEdkhIuki8rcK7QNE5DEROWg/HqvYgxGRP9vLOCgiV1daV4CIPCwiv4lIkog8KyJBJ1BzuIi8JiIpIrJPRO4UER97Xg8R+VpEskQkVUTetKeLiDxqf41ZIrJRRAac6HZTTZMGhGoqLgcW249zRKTtSSyrHRAIRAN3AS8AlwLDsHopd4lIN7vtHcApwBBgMDACuBNARCYCtwNnAz2Bsyqt50Ggl/3ZHhXWV1tPAOFAN2AM1ra4yp73f8BnQEsgxm4LMAE4w15/BDALSDuBdaumzBijD3006gcwGigBWtvvtwF/rDB/EVAIZFZ4vFrFssYCBYCv/T4Ua7fVyApt1gHn2693A5MrzDsHSLBfvww8UGFeL3tZPQAB8oDuFeaPAvZWqCOxmq+5fDm+QBHQr8K864H/2a9fA54HYip9/kxgB1a4+Tj9PdRHw3xoD0I1BVcAnxljUu33b3DsbqaHjTERFR7V7YZKM8aU2q8L7OekCvMLgBD7dQdgX4V5++xp5fP2V5pXLgoIBtaJSKaIZAKf2tNrozXg76GGaPv1X7DCaI2IbC7fzWWMWQU8CTwFJInI8yISVst1qyZOA0I1avY++4uAMSJyWEQOA38EBotIfRyIPgh0rvC+kz0N4BDQsdK8cqlYQdO/QmiFG2NCqJ1UrN5T5RoOABhjDhtjrjPGdMDqWTxdfnqsMeY/xphhQH+s3s2fa7lu1cRpQKjG7nygFOiHtS9/CNAX+BZrX7y3LQHuFJEoEWmNdQzhv/a8ZcCVItJPRIKBu8s/ZIwpwzq28aiItAEQkWgROac2K7d7OsuAf4pIqIh0Bm4rr0FELhSRGLt5BtauqVIRGS4iI0XED2tXVyHWdlTqCA0I1dhdAbxijPnN/m/5sDHmMNbuk0tExGW3+0ul6yBSq15krfwDiAc2ApuAn+1pGGM+AR4DVgG77OeK/mpP/1FEsoEvgN4nUMMfsP7I7wFWY+1ie9meNxz4SURygRXALcaYvUAYVkBlYO2SSgMePoF1qyZMjNEbBimllDqW9iCUUkp5pAGhlFLKI68GhIhMFJHtIrJLRBZ4mB8gIm/a83+yh0tARC4RkfUVHmUiMsSbtSqllDqa145BiIgv1oU4ZwOJwFpgjjFmS4U2NwKDjDHzRGQ2cIExZlal5QwE3jfGdEMppVS9cR2/yQkbAewyxuwBEJGlwDRgS4U204B77NdvA0+KiJijU2sO1qmE1WrdurXp0qVLHZStlFLNx7p161KNMR4v0PRmQERz9FWkicDIqtoYY9wikgVEYl38U24WVpAcQ0TmAnMBOnXqRHx8fN1UrpRSzYSI7KtqnjePQYiHaZX3Z1XbRkRGAvnGmF89rcAY87wxJs4YExcVVdsRCpRSSlXHmwGRyNHDDMTw+xAEx7SxL2gKB9IrzJ9NDXYvKaWUqnveDIi1QE8R6Soi/lh/7FdUarOC3wdVmwmsKj/+YI9nfyGw1Is1KqWUqoLXjkHYxxRuAlZiDUn8sjFms4jcB8QbY1YALwGvi8gurJ7D7AqLOANruOM93qpRKdUwlZSUkJiYSGFhodOlNBmBgYHExMTg5+dX4880maE24uLijB6kVqpp2Lt3L6GhoURGRiLi6VClqg1jDGlpaeTk5NC1a9ej5onIOmNMnKfP6ZXUSqkGp7CwUMOhDokIkZGRte6RaUAopRokDYe6dSLbs9kHxIHMAh75bDsJqXlOl6KUUg1Ksw+IzPxi/rNqF9sOZztdilKqgUhLS2PIkCEMGTKEdu3aER0dfeR9cXFxjZZx1VVXsX379mrbPPXUUyxevLguSvYKb15J3Si0DQsEICm7yOFKlFINRWRkJOvXrwfgnnvuISQkhNtvv/2oNsYYjDH4+Hj+P/uVV1457nrmz59/8sV6UbPvQbQK9sflIyRl6+l0Sqnq7dq1iwEDBjBv3jxiY2M5dOgQc+fOJS4ujv79+3PfffcdaTt69GjWr1+P2+0mIiKCBQsWMHjwYEaNGkVycjIAd955J4899tiR9gsWLGDEiBH07t2b77//HoC8vDxmzJjB4MGDmTNnDnFxcUfCy9uafQ/Cx0eICg0gOUd7EEo1RPd+sJktB+t2F3C/DmHcfV7/E/rsli1beOWVV3j22WcBeOCBB2jVqhVut5tx48Yxc+ZM+vXrd9RnsrKyGDNmDA888AC33XYbL7/8MgsWHHMHBIwxrFmzhhUrVnDffffx6aef8sQTT9CuXTveeecdNmzYQGxs7AnVfSKafQ8CoE1YoPYglFI10r17d4YPH37k/ZIlS4iNjSU2NpatW7eyZcuWYz4TFBTEpEmTABg2bBgJCQkelz19+vRj2qxevZrZs61riAcPHkz//icWbCei2fcgANqGBrAvLd/pMpRSHpzof/re0qJFiyOvd+7cyeOPP86aNWuIiIjg0ksv9Xitgb+//5HXvr6+uN1uj8sOCAg4po2TFzNrDwJoExZAUo72IJRStZOdnU1oaChhYWEcOnSIlStX1vk6Ro8ezbJlywDYtGmTxx6Kt2gP4tBGbt1xJVsKLqPIPZ4Al6/TFSmlGonY2Fj69evHgAED6NatG6eddlqdr+MPf/gDl19+OYMGDSI2NpYBAwYQHh5e5+vxRMdiSt0FTw7jtuJ5/PH2u+nYKrjui1NK1crWrVvp27ev02U0CG63G7fbTWBgIDt37mTChAns3LkTl6v2/9972q7VjcWkPYjwGACiJZXknEINCKVUg5Kbm8v48eNxu90YY3juuedOKBxOhAaEXyDuoCii3akk68VySqkGJiIignXr1jmybj1IDRAeQ7Sk6qmuSilVgQYE4NuyE9E+aSTpxXJKKXWEBgQgER2JljSSsgqcLkUppRoMDQiAiE4EUExRVpLTlSilVIOhAQEQ3hEAk/mbw4UopRqCsWPHHnPR22OPPcaNN95Y5WdCQkIAOHjwIDNnzqxyucc7Hf+xxx4jP//3kR0mT55MZmZmTUuvUxoQABFWQLhyDlBW1jSuC1FKnbg5c+awdOnSo6YtXbqUOXPmHPezHTp04O233z7hdVcOiI8//piIiIgTXt7J0ICAIz2ItmXJHNIzmZRq9mbOnMmHH35IUZF14kpCQgIHDx5kyJAhjB8/ntjYWAYOHMj7779/zGcTEhIYMGAAAAUFBcyePZtBgwYxa9YsCgp+P855ww03HBkm/O677wbgP//5DwcPHmTcuHGMGzcOgC5dupCamgrAI488woABAxgwYMCRYcITEhLo27cv1113Hf3792fChAlHredk6HUQAEERuP1C6OBOY19qHtERQU5XpJQq98kCOLypbpfZbiBMeqDK2ZGRkYwYMYJPP/2UadOmsXTpUmbNmkVQUBDLly8nLCyM1NRUTjnlFKZOnVrl/Z6feeYZgoOD2bhxIxs3bjxqqO5//vOftGrVitLSUsaPH8/GjRu5+eabeeSRR/jqq69o3br1Uctat24dr7zyCj/99BPGGEaOHMmYMWNo2bIlO3fuZMmSJbzwwgtcdNFFvPPOO1x66aUnvZm0B2EzYTHESCoJOqqrUoqjdzOV714yxvC3v/2NQYMGcdZZZ3HgwAGSkqo+ueWbb7458od60KBBDBo06Mi8ZcuWERsby9ChQ9m8efNxB+FbvXo1F1xwAS1atCAkJITp06fz7bffAtC1a1eGDBkCVD+ceG1pD8LmatWZjqlbiU/Lc7oUpVRF1fyn703nn38+t912Gz///DMFBQXExsayaNEiUlJSWLduHX5+fnTp0sXj8N4Veepd7N27l4cffpi1a9fSsmVLrrzyyuMup7px88qHCQdrqPC62sWkPQibRPWmmxzkt5Qsp0tRSjUAISEhjB07lquvvvrIwemsrCzatGmDn58fX331Ffv27at2GWeccQaLFy8G4Ndff2Xjxo2ANUx4ixYtCA8PJykpiU8++eTIZ0JDQ8nJyfG4rPfee4/8/Hzy8vJYvnw5p59+el19uR5pD6Jc2/7448adsgs4xelqlFINwJw5c5g+ffqRXU2XXHIJ5513HnFxcQwZMoQ+ffpU+/kbbriBq666ikGDBjFkyBBGjBgBWHeGGzp0KP379z9mmPC5c+cyadIk2rdvz1dffXVkemxsLFdeeeWRZVx77bUMHTq0znYneaLDfZc7vAmeHc0fy27m3/fch4+P54NOSinv0+G+vaO2w33rLqZyrXtRJr50L9tHso7JpJRSGhBHuAIoCOtGb9nP3lQ9UK2UUhoQFfi07Ucf2c/O5GMPECml6ldT2f3dUJzI9tSAqCAwZhAdfVLYuveA06Uo1awFBgaSlpamIVFHjDGkpaURGBhYq8959SwmEZkIPA74Ai8aYx6oND8AeA0YBqQBs4wxCfa8QcBzQBhQBgw3xnh1HAxp2x+AnP0bgbq/+bhSqmZiYmJITEwkJSXF6VKajMDAQGJiYmr1Ga8FhIj4Ak8BZwOJwFoRWWGMqXi54DVAhjGmh4jMBh4EZomIC/gvcJkxZoOIRAIl3qr1iHbWVY5tszeRkVdMyxb+Xl+lUupYfn5+dO3a1ekymj1v7mIaAewyxuwxxhQDS4FpldpMA161X78NjBfrssMJwEZjzAYAY0yaMabUi7VawqPJD+vO6T6/sj7RmeF1lVKqofBmQEQD+yu8T7SneWxjjHEDWUAk0AswIrJSRH4Wkb94WoGIzBWReBGJr6uuqKvXeEb6bGVTgt48SCnVvHkzIDxdaVb5iFNVbVzAaOAS+/kCERl/TENjnjfGxBlj4qKiok62XgD8e51FkBRTsPu7OlmeUko1Vt4MiESgY4X3McDBqtrYxx3CgXR7+tfGmFRjTD7wMRBLfeh8Gm5xEZW0msIS7+/VUkqphsqbAbEW6CkiXUXEH5gNrKjUZgVwhf16JrDKWOe1rQQGiUiwHRxjgOrHwq0rASHktInjVLOeb3boGRRKqebLawFhH1O4CeuP/VZgmTFms4jcJyJT7WYvAZEisgu4DVhgfzYDeAQrZNYDPxtjPvJWrZWFxc6gj89+Nq356viNlVKqidLB+jwpzKboX734uHQkk+58l0A/37pZrlJKNTA6WF9tBYaR1m0aE/me1Zt2OV2NUko5QgOiClHjbiRIiklZ9bTTpSillCM0IKrgFz2Y31qPYUrOm/y8dafT5SilVL3TgKhGm+kPECxFpH90n9OlKKVUvdOAqEZgh35s7zCDM3M+YN2Xy5wuRyml6pUGxHH0uuxR9rq60OvbW8hJ3Op0OUopVW80II7DLygU94X/pdj4kvvqRZTm6yB+SqnmQQOiBnr3GUD8iMdoXXyAPc9dDGU6BIdSqunTgKihc6bMZGXHW+mZ9R1bX7/N6XKUUsrrNCBqYeJVd/J5yDT67l3Erk+ecrocpZTyKg2IWnD5+jDyxudY6zuUzj/9nQO/rHS6JKWU8hoNiFoKCw6i/bVL+Y32hL5/NVn79cwmpVTTpAFxAmLatyN/5hLcRshbNIOinFSnS1JKqTqnAXGCBg4YxOYzniHSncT+Z2di3EVOl6SUUnVKA+IknD7+PL7odRc98n5h96J50ESGTldKKdCAOGkT59zMe2GX0CPxXRI/edjpcpRSqs5oQJwkXx9h7PWP8D/fUbRfcz9Zmz5xuiSllKoTGhB1IKJFIFGXvcIO0xHXu9fgTtrudElKKXXSNCDqSP8u7Uk4+0UKynzJenkGFGQ4XZJSSp0UDYg6NGn0CN7r9SChhQdJeeViKHU7XZJSSp0wDYg6dvms2bwQ/geikr8n4/2/Ol2OUkqdMA2IOubv8mHmtQtZ4jOFlhtfpOCnRU6XpJRSJ0QDwgvahgXS/ZLHWF02EL9P/kRZwvdOl6SUUrWmAeElI7q3Yd+ZT7GvLIrCxRdD5m9Ol6SUUrWiAeFFF48ZxNLuD+IuLiJ30UVQlOt0SUopVWMaEF4kIvxxzhQeDPkrQZnbyF92HZSVOV2WUkrViAaElwX7u5h79XX8m8sI3v0xJavud7okpZSqEQ2IetA5sgVxs+5gmXsMfqsfwvy63OmSlFLquDQg6smZfduRdMb9xJf1ovTdeXBwvdMlKaVUtTQg6tH8s/rz387/JLm0BcX/nQ05SU6XpJRSVfJqQIjIRBHZLiK7RGSBh/kBIvKmPf8nEeliT+8iIgUist5+POvNOuuLj49w75xx/D3oDkrz0yl542LQGw0ppRoorwWEiPgCTwGTgH7AHBHpV6nZNUCGMaYH8CjwYIV5u40xQ+zHPG/VWd/Cg/24/YoLWVB6I36H4nG/f7PeaEgp1SB5swcxAthljNljjCkGlgLTKrWZBrxqv34bGC8i4sWaGoS+7cOYMnsej7hn4tq0FPPFvU6XpJRSx/BmQEQD+yu8T7SneWxjjHEDWUCkPa+riPwiIl+LyOmeViAic0UkXkTiU1JS6rZ6L5vQvx1hE/7GYvd45LtH4YennS5JKaWO4s2A8NQTqLwvpao2h4BOxpihwG3AGyISdkxDY543xsQZY+KioqJOuuD6ds3p3dg27C4+Lh0BKxfCxmVOl6SUUkd4MyASgY4V3scAB6tqIyIuIBxIN8YUGWPSAIwx64DdQC8v1uoIEeHuqYN4t8vd/FjWj7LlN8DOL5wuSymlAO8GxFqgp4h0FRF/YDawolKbFcAV9uuZwCpjjBGRKPsgNyLSDegJ7PFirY5x+frw6CUj+VfLu9leFkPZm5fC/rVOl6WUUt4LCPuYwk3ASmArsMwYs1lE7hORqXazl4BIEdmFtSup/FTYM4CNIrIB6+D1PGNMurdqdVpooB9PXjWGPwXcxQF3OGWvT9cL6ZRSjhPTRE6xjIuLM/Hx8U6XcVJ2JuXwh2dWsEjupk1gKT5XfgRtK58ZrJRSdUdE1hlj4jzN0yupG5CebUP551WTuMx9BxlFQtlr0yB1l9NlKaWaKQ2IBmZY51b8dc5kZhcuJLegCPPqeZC+1+mylFLNkAZEA3RWv7ZcN30iFxUsJC8v1wqJjH1Ol6WUamY0IBqoi+I6MmPSOcwu+AsFORmYRZMhI8HpspRSzYgGRAN23RndOGv8OVxYsJCC3CzMK1MgvUme7auUaoA0IBq4W8b3ZPTp45mZv5CC/BzMonMhbbfTZSmlmgENiAZORFgwqQ9xp4xhet5CCvLzYNEUPbtJKeV1GhCNgIhwz3n9GRB7KufnLaSgsNAKiZQdTpemlGrCNCAaCR8f4cEZg+g1cATn5S6koLjEConkbU6XppRqojQgGhFfH+HRWUPo2ncY5+YsIN9dBq+eC0lbnC5NKdUEaUA0Mn6+Pjx1cSxd+wzl3OwF5LvF6kno2E1KqTqmAdEI+bt8eOqSWLr2HsLE7IXkEgivnge//eh0aUqpJkQDopEKcPny9KWx9Og9kLMzFpLtagWvXwC7v3K6NKVUE6EB0YgFuHx55tJY+vbpy5lpfyUjMAbeuAi2fex0aUqpJkADopErD4mBvXswNuV2UkN6w5uXwqa3nS5NKdXIaUA0AQEuX569bBixvbsyJulWkloOhXeuhXWvOl2aUqoR04BoIqyexDCG9+7EmIPzOdj6VPjgZvjhaadLU0o1UjUKCBG5RUTCxPKSiPwsIhO8XZyqnUA/X569dBin9unI2MS5JLQ5C1YuhK8fgiZy50ClVP2paQ/iamNMNjABiAKuAh7wWlXqhJWHxLj+MYz/7Qq2tzsXvvoHfH6XhoRSqlZqGhBiP08GXjHGbKgwTTUw/i4fnrw4lkmDYpiYMJuN7S+E7/8DK/4ApW6ny1NKNRKuGrZbJyKfAV2BhSISCpR5ryx1svx8fXh89lD8fX2Y+sv5LOkexqhfXoKCDJjxEvgFOl2iUqqBq2kP4hpgATDcGJMP+GHtZlINmK+P8NCFg5k9vBNzdo/ns05/hG0fwuKZUJjtdHlKqQaupgExCthujMkUkUuBO4Es75Wl6oqvj3D/BQO5fFRn5u4Yzjtd7sb89oM1yF9uitPlKaUasJoGxDNAvogMBv4C7ANe81pVqk75+Aj3Tu3PtaO78qdtvVnU6f9hUnbAy+dAxj6ny1NKNVA1DQi3McYA04DHjTGPA6HeK0vVNRHhjil9mT+uO/dui+bJmIcx+alWSOhw4UopD2oaEDkishC4DPhIRHyxjkOoRkREuH1Cb/54Vi/+va0l97d5BGMMvDIJ9q9xujylVANT04CYBRRhXQ9xGIgGHvJaVcprRIRbzurJHZP78sKOIP4U9hBlQa3gtWmw8wuny1NKNSA1Cgg7FBYD4SJyLlBojNFjEI3YdWd048EZA3lvry/X+f6D0lbdYcksWL/E6dKUUg1ETYfauAhYA1wIXAT8JCIzvVmY8r5Zwzvx5MWxfHNIuKjo7xTHjIL35sE3D+tV10qpGl8odwfWNRDJACISBXwB6JjSjdzkge1pEeBi3uvrmFx8M+/3jqLFqv+D7AMw6SHwremPiFKqqanpMQif8nCwpdXksyIyUUS2i8guEVngYX6AiLxpz/9JRLpUmt9JRHJF5PYa1qlOwJheUfz32hEk5xvO2nMxGUPnQ/zL1n0livOdLk8p5ZCaBsSnIrJSRK4UkSuBj4Bqb1tmn+n0FDAJ6AfMEZF+lZpdA2QYY3oAjwIPVpr/KPBJDWtUJ2FY51a8ef0oSoxw5oaxHDj1PtjxqXWv67xUp8tTSjmgpgep/ww8DwwCBgPPG2P+epyPjQB2GWP2GGOKgaVY11FUNA0ov6vN28B4EREAETkf2ANsrkmN6uT1bR/GW/NGEezv4pzv+rB9zNOQ9Cu8dDak73G6PKVUPavxDYOMMe8YY24zxvzRGLO8Bh+JBvZXeJ9oT/PYxhjjxhq+I1JEWgB/Be6taX2qbnRt3YK3bxhFu/BAzvuyJWvPWGQN8Pfi2XBgndPlKaXqUbUBISI5IpLt4ZEjIscb7c3TcOCVT42pqs29wKPGmNzj1DdXROJFJD4lRccVqivtw4NYdv0o+rQLZdYnZXw0/FXwD4ZF58KOlU6Xp5SqJ9UGhDEm1BgT5uERaowJO86yE4GOFd7HAAeraiMiLiAcSAdGAv8SkQTgVuBvInKTh/qeN8bEGWPioqKijlOOqo1WLfxZct0pjO4ZxfzPcnmx9/OYyB6wZI51AFsp1eR5857Ua4GeItJVRPyB2cCKSm1WAFfYr2cCq4zldGNMF2NMF+Ax4H5jzJNerFV50CLAxUtXxDE9Npp/fJ3Ova0fxnQfDx/+ET67E8r0liBKNWVeO8ndGOO2/+tfCfgCLxtjNovIfUC8MWYF8BLwuojswuo5zPZWPerE+Pn68O8LB9M2LJBn/rebw31v58lhHXF9/wRkJMAFz1u7n5RSTY6YJnLFbFxcnImPj3e6jCZt0Xd7uffDLQzrGMHrA9YRtOou6DAU5iyF0LZOl6eUOgEiss4YE+dpnjd3Makm5srTuvLknFg2HsjmvPjBpJ33CqRsgxfPguStTpenlKpjGhCqVqYMas+rV48gKbuQKSvD2HveW1BaBC9NgN2rnC5PKVWHNCBUrY3qHslb80YBcN47efw4/i0I7wj/nQnrFjlbnFKqzmhAqBPSp10Yy+efSsdWwVzy1gGWDXoRuo2FD26Bz+/WM5yUagI0INQJax8exFvzRnF6z9b85cO9PBB5L2bYVfDdY/D2lVBS4HSJSqmToAGhTkpIgIsXL4/jkpGdePab37gp6zJKxt8HW1ZYV17n6hXuSjVWGhDqpLl8ffjH+QO4Y3JfPt58mFmb4siZ9jIkbYYXz4TkbU6XqJQ6ARoQqk6ICNed0Y2nL45l88Fszv2iJQfOfxvcRdZosDs/d7pEpVQtaUCoOjVpYHuWzD2F3EI3U97NZ/3Ed6FlZ3jjIvjhab2VqVKNiAaEqnOxnVqy/MbTiGzhz0VL9rNi2MvQezKsXGid5eQudrpEpVQNaEAor+gUGcy7N5zGsM4tufmdnTwUcQdm9O3w86vw+gWQn+50iUqp49CAUF4THuzHa9eMYM6Ijjz1v73MOzSJoqnPQuJaeOFMSNnudIlKqWpoQCiv8vP14f4LBnLXuf34fEsSF3wbQ8rMd6E4zxrDaecXTpeolKqCBoTyOhHh6tFdefnK4exPz2fSO4X8OmU5RHSGNy6EH5/Rg9dKNUAaEKrejO3dhndvPJVgf1+mv7GfD4fbB68/XQAf3gqlJU6XqJSqQANC1auebUN5b/5pDO0YwU1v7+TfLe/EjP6TNcifHrxWqkHRgFD1rlULf16/ZiSz4jryxFd7uPHwFIqmPgP71+jBa6UaEA0I5Qh/lw8PzBjInVP6snLzYaav7kjqzHegOBdeGA/bP3G6RKWaPQ0I5RgR4drTu/HSFcPZl5bPpHeL2Dj5fYjsDktmw9f/0mHDlXKQBoRy3Lg+1sHrID9fZryxj7cGvQCDZsNX/4S3LoeiHKdLVKpZ0oBQDUKvtqGsuOk0TukWyZ/f38mdMh/32ffDto/hxbMhbbfTJSrV7GhAqAYjItifRVeN4Pox3fjvT/uZs2koGTOWQu5heGEc7NKL6pSqTxoQqkHx9REWTurLf+YMZdOBLCat8GXLeSuse14vvhC+e1wvqlOqnmhAqAZp6uAOvHvDabh8hfPfOMC7Q/bFli8AABbTSURBVF+GvlPh87vgnWuhON/pEpVq8jQgVIPVr0MYK24aTVznltz23i7uCfgzpWfeBb++Ay9NgPQ9TpeoVJOmAaEatFYt/Hnt6hFcO7ori37Yx8VbTyVr+huQtR+eGwtbP3S6RKWaLA0I1eC5fH2489x+PDZrCOv3ZzLhQ382TPkAIrvBm5fAZ3fqOE5KeYEGhGo0zh8azfIbTyPIz5fpSxJ5qdezmLhr4fsn4NWpkH3I6RKValI0IFSj0q9DGCv+MJoJ/dryf5/u5vr0OeSf9ywcWg/PnQ57v3G6RKWaDA0I1eiEBfrx9CWx/P3cfqzalszEL9uxc9oKCGoJr02Dbx7WITqUqgMaEKpREhGuGd2VN68/hWJ3GVOWpvJ27OuY/hfAqv+DxTMhN9npMpVq1LwaECIyUUS2i8guEVngYX6AiLxpz/9JRLrY00eIyHr7sUFELvBmnarxGta5FR/dPJqRXVtx+4rd/Kn0DxSd8zDs+w6eOVVvaarUSfBaQIiIL/AUMAnoB8wRkX6Vml0DZBhjegCPAg/a038F4owxQ4CJwHMi4vJWrapxiwwJYNFVI7j1rJ4sX3+Qid/1ZMfUD6BFFCyeAZ/+DdxFTpepVKPjzR7ECGCXMWaPMaYYWApMq9RmGvCq/fptYLyIiDEm3xjjtqcHAjq2gqqWr49w61m9WHLdKRSWlDLlzVRe6vsiZvh18ONT8OJ4SNnhdJlKNSreDIhoYH+F94n2NI9t7EDIAiIBRGSkiGwGNgHzKgTGESIyV0TiRSQ+JSXFC1+CamxO6RbJJ7eczvg+bfm/lQlcfvhCMqe9ClkH4PkxEP+KjuWkVA15MyDEw7TKv5lVtjHG/GSM6Q8MBxaKSOAxDY153hgTZ4yJi4qKOumCVdMQEezPM5fGcv8FA1mbkM6ZH7Zg9dnvQcxw+PBW6wB29kGny1SqwfNmQCQCHSu8jwEq/1YeaWMfYwgHjrprvTFmK5AHDPBaparJEREuHtmJD24aTZvQAC5dlsjfQu6j8OwHIOE7ePoU2LhMexNKVcObAbEW6CkiXUXEH5gNrKjUZgVwhf16JrDKGGPsz7gARKQz0BtI8GKtqonq2TaU9+afxvVjurE0/gDjv+3NuskfQOve8O51sOwyyElyukylGiSvBYR9zOAmYCWwFVhmjNksIveJyFS72UtApIjsAm4Dyk+FHQ1sEJH1wHLgRmNMqrdqVU1boJ8vCyf15a15p+Lv8mHGsmTuinyY4nF3w46V8NRw69iEXlyn1FHENJEudlxcnImPj3e6DNXAFRSX8vBn23n5u710bBnMExNCGLz+Xkj4FjqNgnMfgzZ9nC5TqXojIuuMMXGe5umV1KpZCfL35e/n9uPNuaMQgWlLk1kYej/5k56AlG3w7GhY9Q8oKXS6VKUcpwGhmqURXVvxyS2nc+3orixbl8jpn7XnozErMAOmwzcP6VXYSqEBoZqxYH8Xd57bjxU3nUbHVsHMf28/F6dezcGpSwBjXYW9+CJI3eV0qUo5QgNCNXv9O4Tz7g2n8s8LBrD5YBZj3xEe7/UaJePvhd9+gKdHwso7oCDT6VKVqlcaEEoBPj7CJSM78+WfxjJlUHse/d9vjFk9kE/HfYgZfDH88BQ8Mcw+26nU6XKVqhcaEEpVEBUawKOzhvDm3FNoFeLPvPcSOT9xNpvP+wBa97KuxH7mVNj6gV5kp5o8DQilPBjZLZIV80fz7wsHczirgClvZTM/4B+kTn7B6kG8eak1AOCe/zldqlJeo9dBKHUc+cVunv9mD899vYfSMsPlp0RzS+t1hP7wMGQnQtcxMP5uiBnmdKlK1Vp110FoQChVQ4ezCvn3Z9t55+dEAly+XDOqPfNDvibox8cgPw16T4Yz/gzRsU6XqlSNaUAoVYd2p+Ty+Bc7+WDjQUL8Xcwb1YZrXJ8QGP8sFGZBj7PgjL9Ap5FOl6rUcWlAKOUF2w5n8+jnO1i5OYnwID9uHBXFFX5fErj2aatH0eV0GPMX61k8jWyvlPM0IJTyok2JWTzy+Xa+2p5CSICLK4dHcX2Lbwhd9zTkJkHMCDj1JuhzLvj4Ol2uUkfRgFCqHmw+mMUz/9vNx5sO4fL14eLYKG5p+RMtNzwHmfugZRc45UYYcgkEhDhdrlKABoRS9Wpvah7Pfb2bd35OpMzAuQPacEvMDrrteAUS10BgBMRdBSOuh7D2TpermjkNCKUccDirkBe/3cOba/eTU+RmaKcIbuuTyWnJS/DZ9iH4uGDghTByLnQY6nS5qpnSgFDKQblFbt6O38+i7xNISMunXVgg84f4cGHJBwT+ugRK8iF6GAy/FvpfAH5BTpesmhENCKUagLIyw/92JPPy6gRW70olwOXD7IFhXB+xhg47FkPaTghqCUMvhbiroVU3p0tWzYAGhFINzI6kHF75LoHlvyRSWFLGwA5h3NIjibHZ7+Pa/hGYUug+HoZfAz0ngK+f0yWrJkoDQqkGKiu/hPfWH2DJmt/YdjiHYH9fLu3vz9VB39J25xIk5xC0aAODLrJ6Fm36Ol2yamI0IJRq4Iwx/LI/k6VrfuODDYcoKCllYLtgbuu6j9NyP8N/90ooc0OHWBhyMQycae2OUuokaUAo1YhkF5bw/vqDvPHTb2w9lI2frzC1pz/XhsfT+9AKfJI3g28A9JkCg2dDt3Hg8ne6bNVIaUAo1QgZY9h8MJvlvxzg/fUHSc0tIjzIj+t65HCR6xuiEt5HCjKs6yr6TYUBM6xhPfRqbVULGhBKNXLu0jJW70rl3Z8P8NmWwxSWlNGjlR/zO+3nzNLVhO37DCnOtY5X9JtmhUXHkeCjt3xR1dOAUKoJySks4dNfD7P8lwP8uCeNMgN9Il3cEL2HcSXfErr/S8RdCGHR1m6o3pOg82jdDaU80oBQqolKySli5ebDfPLrIX7YbYVF31bCjR12MqZkNaEHvkXcBRAQBj3GW/es6Hm2HuBWR2hAKNUMpOUW8dmWJD7edIjvd6dRWmboEiZc3WEf42UdHZK/RvKSQXyh86nQayJ0P9M6dVaHI2+2NCCUamYy8or5fGsSq7Ym8+3OFPKKSwl0wSUxKZwftJE+Wd/il77DahzSDrqPs86G6jYWQts6WbqqZxoQSjVjRe5S1u7N4MttSazalsy+tHwATmudz6xWuxhhNtAm9Sd8CtKtD7QdYAVGlzOg4wgIinCweuVtGhBKKcA6dXZPah6rtibzzc4U1iakU1hShq+UMa1tGtNCtzO4+GfCU39GSosBsQKj0ynQeRR0OlWHKG9iNCCUUh4VuUv5eV8m3+9O5fvdaazfn0lpmSHMVcKMNocZH7yLfiWbaZm+ASnJsz7Usgt0GmWNQBsdawWIK8DRr0OdOMcCQkQmAo8DvsCLxpgHKs0PAF4DhgFpwCxjTIKInA08APgDxcCfjTGrqluXBoRSJy+3yM2avWl8tyuN+IR0Nh/Mxl1mcOHmnMgUJoftYYjZRrus9fgWpFkf8vW3QiI61hoKJHoYtO6pF+w1Eo4EhIj4AjuAs4FEYC0wxxizpUKbG4FBxph5IjIbuMAYM0tEhgJJxpiDIjIAWGmMia5ufRoQStW9/GI3G/ZnsW5fOvH7Mli3L4OcQjdg6BOYxeRWBxkRkEBP9w5aZm7BpyTX+qBfsHV2VNv+Vni07Q9t+kFwKye/HOWBUwExCrjHGHOO/X4hgDHm/1Vos9Ju84OIuIDDQJSpUJSICJAKdDDGFFW1Pg0IpbyvrMywMzmXdfsy2HQgi00HMtl+OIeSUoNQxpCgFCa2PECs/366uBNombMDV1HG7wsIi/49LNr2t3oakT0gINS5L6qZqy4gXF5cbzSwv8L7RGBkVW2MMW4RyQIisQKh3AzgF0/hICJzgbkAnTp1qrvKlVIe+fgIvduF0rvd73/Qi9ylbD+cw8bELH49kMX7iT156Lcc3GUGMLT3yWJsRDIjgg/R1+c3opP3ELL7K6Ss5PcFh3aA1j0gsie07vX76/COOlyIg7wZEJ6uvKncXam2jYj0Bx4EJnhagTHmeeB5sHoQJ1amUupkBLh8GRQTwaCY30+HLXaXsTc1j+1JOWw/nM32wzk8kpTD/vQCAPxw08cvmRFh6QwOTKK7zyHaZyYSduAtXMXZvy/cFQgRna0D4y3Ln+1HRGcICKnPL7XZ8WZAJAIdK7yPAQ5W0SbR3sUUDqQDiEgMsBy43Biz24t1KqXqmL/L5/eexuAOR6bnFrnZmZTD9sM57EjKZU9qLl+m5rE/o4BSu8fRmmyGBKcQ1yKVPv5JxJhkWifvIyThe1wlOUevKLh1hcDoBOHREBZjP0dbQ4roVeInzJsBsRboKSJdgQPAbODiSm1WAFcAPwAzgVXGGCMiEcBHwEJjzHderFEpVY9CAlwM7dSSoZ2OHguq2F3Gb+n57E3NY29qLntT81iVksdLqXmk5JTvXTZEkEs3VyqDW2TSNzCdrr7JtM9PpmXmTwTnv4cY99Er9AuGsA5WWITH2M8VQiSkrYZINbwWEPYxhZuAlVinub5sjNksIvcB8caYFcBLwOsisgur5zDb/vhNQA/g7yLyd3vaBGNMsrfqVUo5x9/lQ482IfRoEwIcPdRHYUkpiRkF7M/IJzE9n/0ZBexPzyfenpaZbx3L8KGM1mTR0TedPsHZ9AzIopNfBu3L0ohMSyHs0FYCClOQynu6ff2toAhpC6HtPDy3sYYjaREFvt78n7rh0QvllFKNWnZhCYnpBRzILOBwVgGHsgo5nFXIwawCDmcVciirkCJ3GQAu3LQhkxjfdHoHZdM5IIdoVzZtJZNIk0F4aRrBxWn4F2ceuyLxsXZphbSFFpHW6xZRFV63/v25RWvrRk6NoGfi1FlMSinldWGBfvTr4Ee/DmEe5xtjyMwvOSowyp+/yS0iJcd6pOUVUf7/sj8ltCaLNpJJZ/9sugbmEu2XQ3vfTKIKswjPT6NF6W4CizPwc+d6LszHBcHl4VExUFpb14MEtTz2ERDWoEJFA0Ip1aSJCC1b+NOyhT/9O4RX2c5dWkZ6fvGRwEjJKSLFDpBdOUX8UGF6TtHvxzr8KaEV2URKDq19cugYkE+Mfy7tXLm09smhVWEO4QWZhLr3ElSSiZ87p8oaEF9rcERP4RHkKVTstoHhXrlyXQNCKaUAl68PbUIDaRMaeNy2hSWlpOUVk55bTHp+Mel5RaTnlRx5/iWviIy8EtLyikjPKyazoORI78QPNxHkEi65RJBLlCufdv4FtPMroLVvPq188okoySWsJJeQzP0El24msCSr6p4KQN+pMOv1OtoSv9OAUEqpWgr08yU6IojoiKAatS8tM2TmF5ORX0xarv2cV0xWQQlZ+SVk5pfwS0EJmQXFZBW4ycq35uUVlx5Zhgs3YeQTYQdLuOTZwZJPu5I+zPLC16kBoZRSXubrI0SGBBAZEkCPNjX/XLG7zAqRghKyCqzQyLQDpXx6QkEJIdFV7zo7GRoQSinVQPm7fIgKDSAq1Jnh1HWQE6WUUh5pQCillPJIA0IppZRHGhBKKaU80oBQSinlkQaEUkopjzQglFJKeaQBoZRSyqMmM9y3iKQA+05iEa05+l7YDYXWVTtaV+011Nq0rto50bo6G2OiPM1oMgFxskQkvqox0Z2kddWO1lV7DbU2rat2vFGX7mJSSinlkQaEUkopjzQgfve80wVUQeuqHa2r9hpqbVpX7dR5XXoMQimllEfag1BKKeWRBoRSSimPmn1AiMhEEdkuIrtEZIGDdXQUka9EZKuIbBaRW+zp94jIARFZbz8mO1RfgohssmuIt6e1EpHPRWSn/dyynmvqXWG7rBeRbBG51YltJiIvi0iyiPxaYZrH7SOW/9g/cxtFJLae63pIRLbZ614uIhH29C4iUlBhuz3rrbqqqa3K752ILLS32XYROaee63qzQk0JIrLenl5v26yavxHe+zkzxjTbB+AL7Aa6Af7ABqCfQ7W0B2Lt16HADqAfcA9wewPYVglA60rT/gUssF8vAB50+Ht5GOjsxDYDzgBigV+Pt32AycAngACnAD/Vc10TAJf9+sEKdXWp2M6hbebxe2f/LmwAAoCu9u+tb33VVWn+v4G76nubVfM3wms/Z829BzEC2GWM2WOMKQaWAtOcKMQYc8gY87P9OgfYCkQ7UUstTANetV+/CpzvYC3jgd3GmJO5mv6EGWO+AdIrTa5q+0wDXjOWH4EIEWlfX3UZYz4zxrjttz8CMd5Y9/FUsc2qMg1YaowpMsbsBXZh/f7Wa10iIsBFwBJvrLs61fyN8NrPWXMPiGhgf4X3iTSAP8oi0gUYCvxkT7rJ7iK+XN+7cSowwGcisk5E5trT2hpjDoH1wwvU4nbsdW42R//SNoRtVtX2aUg/d1dj/ZdZrquI/CIiX4vI6Q7V5Ol711C22elAkjFmZ4Vp9b7NKv2N8NrPWXMPCPEwzdHzfkUkBHgHuNUYkw08A3QHhgCHsLq3TjjNGBMLTALmi8gZDtVxDBHxB6YCb9mTGso2q0qD+LkTkTsAN7DYnnQI6GSMGQrcBrwhImH1XFZV37sGsc2AORz9j0i9bzMPfyOqbOphWq22WXMPiESgY4X3McBBh2pBRPywvvGLjTHvAhhjkowxpcaYMuAFvNStPh5jzEH7ORlYbteRVN5ltZ+TnagNK7R+NsYk2TU2iG1G1dvH8Z87EbkCOBe4xNg7rO3dN2n263VY+/l71Wdd1XzvGsI2cwHTgTfLp9X3NvP0NwIv/pw194BYC/QUka72f6GzgRVOFGLv23wJ2GqMeaTC9Ir7DC8Afq382XqorYWIhJa/xjrI+SvWtrrCbnYF8H5912Y76r+6hrDNbFVtnxXA5fZZJqcAWeW7COqDiEwE/gpMNcbkV5geJSK+9utuQE9gT33VZa+3qu/dCmC2iASISFe7tjX1WRtwFrDNGJNYPqE+t1lVfyPw5s9ZfRx9b8gPrCP9O7CS/w4H6xiN1f3bCKy3H5OB14FN9vQVQHsHauuGdQbJBmBz+XYCIoEvgZ32cysHagsG0oDwCtPqfZthBdQhoATrP7drqto+WF3/p+yfuU1AXD3XtQtr33T5z9mzdtsZ9vd3A/AzcJ4D26zK7x1wh73NtgOT6rMue/oiYF6ltvW2zar5G+G1nzMdakMppZRHzX0Xk1JKqSpoQCillPJIA0IppZRHGhBKKaU80oBQSinlkQaEUg2AiIwVkQ+drkOpijQglFJKeaQBoVQtiMilIrLGHvv/ORHxFZFcEfm3iPwsIl+KSJTddoiI/Ci/33ehfJz+HiLyhYhssD/T3V58iIi8Lda9GhbbV84q5RgNCKVqSET6ArOwBi4cApQClwAtsMaCigW+Bu62P/Ia8FdjzCCsK1nLpy8GnjLGDAZOxbpqF6zROW/FGuO/G3Ca178oparhcroApRqR8cAwYK39z30Q1sBoZfw+gNt/gXdFJByIMMZ8bU9/FXjLHtMq2hizHMAYUwhgL2+Nscf5EeuOZV2A1d7/spTyTANCqZoT4FVjzMKjJor8vVK76savqW63UVGF16Xo76dymO5iUqrmvgRmikgbOHIv4M5Yv0cz7TYXA6uNMVlARoUbyFwGfG2s8fsTReR8exkBIhJcr1+FUjWk/6EoVUPGmC0icifWnfV8sEb7nA/kAf1FZB2QhXWcAqyhl5+1A2APcJU9/TLgORG5z17GhfX4ZShVYzqaq1InSURyjTEhTtehVF3TXUxKKaU80h6EUkopj7QHoZRSyiMNCKWUUh5pQCillPJIA0IppZRHGhBKKaU8+v9Rrh5QghiHvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('AE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.017556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.067737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.029941\n",
       "std      0.012591\n",
       "min      0.017556\n",
       "25%      0.019372\n",
       "50%      0.024825\n",
       "75%      0.038516\n",
       "max      0.067737"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.017862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.025362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.039185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.065786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.030343\n",
       "std      0.012496\n",
       "min      0.017862\n",
       "25%      0.019718\n",
       "50%      0.025362\n",
       "75%      0.039185\n",
       "max      0.065786"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.647027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.020517</td>\n",
       "      <td>1.616053</td>\n",
       "      <td>3.319179</td>\n",
       "      <td>0.604015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.711798</td>\n",
       "      <td>0.422102</td>\n",
       "      <td>0.877366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.729026</td>\n",
       "      <td>1.916097</td>\n",
       "      <td>1.539384</td>\n",
       "      <td>0.003276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.461904</td>\n",
       "      <td>0.307894</td>\n",
       "      <td>0.877388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056192</td>\n",
       "      <td>0.056966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.680876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.605682</td>\n",
       "      <td>1.406316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.325239</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>1.959214</td>\n",
       "      <td>2.992734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444584</td>\n",
       "      <td>0.059368</td>\n",
       "      <td>3.844914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447486</td>\n",
       "      <td>2.453401</td>\n",
       "      <td>0.213089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3    4    5    6    7         8         9   \\\n",
       "0  0.0  1.647027  0.000000  0.660599  0.0  0.0  0.0  0.0  1.020517  1.616053   \n",
       "1  0.0  4.711798  0.422102  0.877366  0.0  0.0  0.0  0.0  1.729026  1.916097   \n",
       "2  0.0  3.461904  0.307894  0.877388  0.0  0.0  0.0  0.0  0.056192  0.056966   \n",
       "3  0.0  0.261865  0.605682  1.406316  0.0  0.0  0.0  0.0  2.325239  0.037095   \n",
       "4  0.0  1.444584  0.059368  3.844914  0.0  0.0  0.0  0.0  0.000000  0.447486   \n",
       "\n",
       "         10        11  \n",
       "0  3.319179  0.604015  \n",
       "1  1.539384  0.003276  \n",
       "2  0.000000  1.680876  \n",
       "3  1.959214  2.992734  \n",
       "4  2.453401  0.213089  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.649090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648386</td>\n",
       "      <td>1.037058</td>\n",
       "      <td>1.621922</td>\n",
       "      <td>3.304917</td>\n",
       "      <td>0.589147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.053474</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>0.543970</td>\n",
       "      <td>3.214760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.209431</td>\n",
       "      <td>0.661148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.075082</td>\n",
       "      <td>0.511508</td>\n",
       "      <td>0.217459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.623912</td>\n",
       "      <td>1.599327</td>\n",
       "      <td>0.611574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.443019</td>\n",
       "      <td>0.057794</td>\n",
       "      <td>3.863482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415654</td>\n",
       "      <td>2.488883</td>\n",
       "      <td>0.206009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.453755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6\n",
       "405  1.649090  0.000000  0.648386  1.037058  1.621922  3.304917  0.589147\n",
       "406  1.053474  0.010654  0.543970  3.214760  0.000000  1.209431  0.661148\n",
       "407  2.075082  0.511508  0.217459  0.000000  2.623912  1.599327  0.611574\n",
       "408  1.443019  0.057794  3.863482  0.000000  0.415654  2.488883  0.206009\n",
       "409  0.453755  0.000000  0.000000  0.000000  0.464154  0.000000  0.000000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77377146"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./dim064_AE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Sparse Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-7))(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                832       \n",
      "=================================================================\n",
      "Total params: 1,612\n",
      "Trainable params: 1,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0669 - val_loss: 0.0645\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0631 - val_loss: 0.0614\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0603 - val_loss: 0.0592\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0585 - val_loss: 0.0579\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0574 - val_loss: 0.0571\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0568 - val_loss: 0.0566\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0563 - val_loss: 0.0562\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0559 - val_loss: 0.0558\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0555 - val_loss: 0.0554\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0547 - val_loss: 0.0545\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0543 - val_loss: 0.0541\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0539 - val_loss: 0.0537\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0535 - val_loss: 0.0533\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0530 - val_loss: 0.0528\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0526 - val_loss: 0.0524\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0522 - val_loss: 0.0519\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0517 - val_loss: 0.0515\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0513 - val_loss: 0.0510\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0509 - val_loss: 0.0506\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0504 - val_loss: 0.0501\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0500 - val_loss: 0.0497\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0496 - val_loss: 0.0493\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0492 - val_loss: 0.0489\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0488 - val_loss: 0.0485\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0484 - val_loss: 0.0481\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0480 - val_loss: 0.0477\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0476 - val_loss: 0.0473\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0473 - val_loss: 0.0470\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0469 - val_loss: 0.0466\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0465 - val_loss: 0.0462\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0462 - val_loss: 0.0459\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0458 - val_loss: 0.0455\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0454 - val_loss: 0.0451\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0450 - val_loss: 0.0448\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0447 - val_loss: 0.0444\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0443 - val_loss: 0.0440\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0439 - val_loss: 0.0436\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0435 - val_loss: 0.0432\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0432 - val_loss: 0.0429\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0428 - val_loss: 0.0425\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0424 - val_loss: 0.0421\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0420 - val_loss: 0.0417\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0416 - val_loss: 0.0413\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0412 - val_loss: 0.0409\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0408 - val_loss: 0.0404\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0404 - val_loss: 0.0400\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0400 - val_loss: 0.0396\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0396 - val_loss: 0.0392\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0391 - val_loss: 0.0388\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0387 - val_loss: 0.0384\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0383 - val_loss: 0.0380\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0379 - val_loss: 0.0376\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.037 - 0s 28us/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0371 - val_loss: 0.0367\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0367 - val_loss: 0.0363\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0363 - val_loss: 0.0359\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0359 - val_loss: 0.0355\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0355 - val_loss: 0.0351\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0351 - val_loss: 0.0348\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0347 - val_loss: 0.0344\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0344 - val_loss: 0.0340\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0340 - val_loss: 0.0336\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0336 - val_loss: 0.0333\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0333 - val_loss: 0.0329\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0329 - val_loss: 0.0326\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0326 - val_loss: 0.0322\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0322 - val_loss: 0.0319\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0316 - val_loss: 0.0312\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0313 - val_loss: 0.0309\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0309 - val_loss: 0.0306\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0306 - val_loss: 0.0303\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0303 - val_loss: 0.0300\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0301 - val_loss: 0.0297\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0298 - val_loss: 0.0294\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0295 - val_loss: 0.0292\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0292 - val_loss: 0.0289\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0289 - val_loss: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0282 - val_loss: 0.0279\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0279 - val_loss: 0.0277\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0277 - val_loss: 0.0274\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0275 - val_loss: 0.0272\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0272 - val_loss: 0.0270\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0270 - val_loss: 0.0268\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0268 - val_loss: 0.0266\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0266 - val_loss: 0.0264\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0264 - val_loss: 0.0262\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0260 - val_loss: 0.0258\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0258 - val_loss: 0.0256\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0256 - val_loss: 0.0254\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0252 - val_loss: 0.0250\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0242 - val_loss: 0.0240\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0240 - val_loss: 0.0239\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0237 - val_loss: 0.0236\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0235 - val_loss: 0.0234\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0234 - val_loss: 0.0233\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0231 - val_loss: 0.0230\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0229 - val_loss: 0.0228\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0195 - val_loss: 0.0196\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0193 - val_loss: 0.0194\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0192 - val_loss: 0.0193\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0192 - val_loss: 0.0193\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0191 - val_loss: 0.0192\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0190 - val_loss: 0.0192\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0189 - val_loss: 0.0190\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0188 - val_loss: 0.0190\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0188 - val_loss: 0.0189\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0187 - val_loss: 0.0188\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0186 - val_loss: 0.0188\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0185 - val_loss: 0.0187\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0185 - val_loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0182 - val_loss: 0.0185\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 35us/step - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0181 - val_loss: 0.0183\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0180 - val_loss: 0.0182\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0175 - val_loss: 0.0179\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 42us/step - loss: 0.0174 - val_loss: 0.0178\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0174 - val_loss: 0.0177\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0174 - val_loss: 0.0177\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 33us/step - loss: 0.0173 - val_loss: 0.0177\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0169 - val_loss: 0.0174\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0168 - val_loss: 0.0172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('SAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.016825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.018942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.066921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.029663\n",
       "std      0.012844\n",
       "min      0.016825\n",
       "25%      0.018942\n",
       "50%      0.024411\n",
       "75%      0.038837\n",
       "max      0.066921"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.017245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.064528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.029574\n",
       "std      0.012601\n",
       "min      0.017245\n",
       "25%      0.019089\n",
       "50%      0.024268\n",
       "75%      0.038487\n",
       "max      0.064528"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168739"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.082953</td>\n",
       "      <td>1.719938</td>\n",
       "      <td>2.794215</td>\n",
       "      <td>1.231354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.376120</td>\n",
       "      <td>3.638447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.313083</td>\n",
       "      <td>1.477354</td>\n",
       "      <td>3.454328</td>\n",
       "      <td>1.329181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069223</td>\n",
       "      <td>1.353905</td>\n",
       "      <td>1.092889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200157</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>1.066647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589930</td>\n",
       "      <td>0.704653</td>\n",
       "      <td>1.400739</td>\n",
       "      <td>0.359647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.822837</td>\n",
       "      <td>1.277856</td>\n",
       "      <td>0.046526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.450487</td>\n",
       "      <td>0.502795</td>\n",
       "      <td>4.184638</td>\n",
       "      <td>1.976546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.661711</td>\n",
       "      <td>1.961034</td>\n",
       "      <td>0.373459</td>\n",
       "      <td>1.882053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.539026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4    5    6    7         8   \\\n",
       "0  0.0  1.082953  1.719938  2.794215  1.231354  0.0  0.0  0.0  0.490155   \n",
       "1  0.0  1.313083  1.477354  3.454328  1.329181  0.0  0.0  0.0  1.069223   \n",
       "2  0.0  0.000000  0.200157  0.002742  1.066647  0.0  0.0  0.0  1.589930   \n",
       "3  0.0  2.822837  1.277856  0.046526  0.000000  0.0  0.0  0.0  1.450487   \n",
       "4  0.0  1.661711  1.961034  0.373459  1.882053  0.0  0.0  0.0  0.640876   \n",
       "\n",
       "         9         10        11  \n",
       "0  0.000000  2.376120  3.638447  \n",
       "1  1.353905  1.092889  0.000000  \n",
       "2  0.704653  1.400739  0.359647  \n",
       "3  0.502795  4.184638  1.976546  \n",
       "4  0.000000  0.000000  3.539026  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.092041</td>\n",
       "      <td>1.720317</td>\n",
       "      <td>2.794890</td>\n",
       "      <td>1.236804</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.367828</td>\n",
       "      <td>3.613643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2.303518</td>\n",
       "      <td>1.493060</td>\n",
       "      <td>1.155429</td>\n",
       "      <td>2.691460</td>\n",
       "      <td>1.473746</td>\n",
       "      <td>0.091799</td>\n",
       "      <td>3.651505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.932236</td>\n",
       "      <td>2.223594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293780</td>\n",
       "      <td>0.697548</td>\n",
       "      <td>0.259376</td>\n",
       "      <td>2.035564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.660553</td>\n",
       "      <td>1.966380</td>\n",
       "      <td>0.358016</td>\n",
       "      <td>1.914140</td>\n",
       "      <td>0.637647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.552371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.094141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.045001</td>\n",
       "      <td>1.704770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "405  1.092041  1.720317  2.794890  1.236804  0.482353  0.000000  2.367828   \n",
       "406  2.303518  1.493060  1.155429  2.691460  1.473746  0.091799  3.651505   \n",
       "407  0.005647  0.932236  2.223594  0.000000  0.293780  0.697548  0.259376   \n",
       "408  1.660553  1.966380  0.358016  1.914140  0.637647  0.000000  0.000000   \n",
       "409  0.000000  2.094141  0.000000  2.045001  1.704770  0.000000  0.236192   \n",
       "\n",
       "            7  \n",
       "405  3.613643  \n",
       "406  0.000000  \n",
       "407  2.035564  \n",
       "408  3.552371  \n",
       "409  0.000000  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./dim064_SAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contractive Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 0s 510us/step - loss: 0.0726 - val_loss: 0.0689\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0674 - val_loss: 0.0647\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0637 - val_loss: 0.0618\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0611 - val_loss: 0.0596\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0592 - val_loss: 0.0581\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0578 - val_loss: 0.0570\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0568 - val_loss: 0.0562\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0560 - val_loss: 0.0555\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0554 - val_loss: 0.0550\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0548 - val_loss: 0.0545\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0543 - val_loss: 0.0540\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0539 - val_loss: 0.0536\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0534 - val_loss: 0.0531\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0530 - val_loss: 0.0527\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0525 - val_loss: 0.0523\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0521 - val_loss: 0.0518\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0514\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0512 - val_loss: 0.0509\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0507 - val_loss: 0.0505\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0502 - val_loss: 0.0500\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0498 - val_loss: 0.0496\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0493 - val_loss: 0.0491\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0489 - val_loss: 0.0487\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0484 - val_loss: 0.0482\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0480 - val_loss: 0.0478\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0475 - val_loss: 0.0474\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0471 - val_loss: 0.0470\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0466 - val_loss: 0.0465\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0462 - val_loss: 0.0461\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0458 - val_loss: 0.0457\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0454 - val_loss: 0.0453\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0450 - val_loss: 0.0449\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0446 - val_loss: 0.0445\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0442 - val_loss: 0.0441\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0438 - val_loss: 0.0437\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0434 - val_loss: 0.0434\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0430 - val_loss: 0.0430\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0426 - val_loss: 0.0426\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0422 - val_loss: 0.0422\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0419 - val_loss: 0.0418\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0415 - val_loss: 0.0415\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0411 - val_loss: 0.0411\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0407 - val_loss: 0.0407\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0404 - val_loss: 0.0403\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0400 - val_loss: 0.0400\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0396 - val_loss: 0.0396\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0392 - val_loss: 0.0392\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0389 - val_loss: 0.0389\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0385 - val_loss: 0.0385\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0378 - val_loss: 0.0378\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0374 - val_loss: 0.0374\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0371 - val_loss: 0.0371\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0367 - val_loss: 0.0367\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0354 - val_loss: 0.0354\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0351 - val_loss: 0.0351\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0348 - val_loss: 0.0348\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0344 - val_loss: 0.0344\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0339 - val_loss: 0.0339\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 34us/step - loss: 0.0336 - val_loss: 0.0336\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0333 - val_loss: 0.0333\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0330 - val_loss: 0.0330\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0327 - val_loss: 0.0327\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0325 - val_loss: 0.0325\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0322 - val_loss: 0.0322\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0319 - val_loss: 0.0320\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0317 - val_loss: 0.0317\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0315\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0310 - val_loss: 0.0310\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0307 - val_loss: 0.0308\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0305 - val_loss: 0.0305\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0302 - val_loss: 0.0303\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0296 - val_loss: 0.0296\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0291 - val_loss: 0.0291\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0289 - val_loss: 0.0289\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0287 - val_loss: 0.0287\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0284 - val_loss: 0.0285\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0282 - val_loss: 0.0283\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0280 - val_loss: 0.0280\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0278 - val_loss: 0.0278\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0271 - val_loss: 0.0272\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0269 - val_loss: 0.0270\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0267 - val_loss: 0.0268\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0265 - val_loss: 0.0265\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0263 - val_loss: 0.0263\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0261 - val_loss: 0.0261\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0259 - val_loss: 0.0259\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0255 - val_loss: 0.0255\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0253 - val_loss: 0.0253\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0249 - val_loss: 0.0250\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0247 - val_loss: 0.0248\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0245 - val_loss: 0.0246\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0243 - val_loss: 0.0244\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0236 - val_loss: 0.0237\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0234 - val_loss: 0.0235\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0231 - val_loss: 0.0232\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0229 - val_loss: 0.0230\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0221 - val_loss: 0.0222\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0215 - val_loss: 0.0216\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0214 - val_loss: 0.0215\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0205 - val_loss: 0.0207\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0204 - val_loss: 0.0206\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0200 - val_loss: 0.0202\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0195 - val_loss: 0.0197\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0194 - val_loss: 0.0196\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0192 - val_loss: 0.0195\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0192 - val_loss: 0.0194\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0191 - val_loss: 0.0193\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0190 - val_loss: 0.0192\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0189 - val_loss: 0.0191\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0188 - val_loss: 0.0190\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0187 - val_loss: 0.0190\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0186 - val_loss: 0.0188\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0185 - val_loss: 0.0188\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0185 - val_loss: 0.0187\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0184 - val_loss: 0.0187\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 18us/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0182 - val_loss: 0.0185\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0181 - val_loss: 0.0183\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0175 - val_loss: 0.0179\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0174 - val_loss: 0.0178\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0174 - val_loss: 0.0177\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0174 - val_loss: 0.0177\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0174 - val_loss: 0.0177\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0173 - val_loss: 0.0177\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0171 - val_loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "########### Contractive Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu', name = 'encoded')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "lam = 10e-6\n",
    "\n",
    "def contractive_loss(y_pred, y_true):\n",
    "    \n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "        W = K.variable(value=autoencoder.get_layer('encoded').get_weights()[0])\n",
    "        W = K.transpose(W)\n",
    "        h = autoencoder.get_layer('encoded').output\n",
    "        dh = h * (1 - h)\n",
    "        contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "        return mse + contractive\n",
    "    \n",
    "autoencoder.compile(optimizer='adam', loss= contractive_loss)\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3wVdfb/8dfJTYNUEkIvoUovMVJUVEQRbCgiwop9Rde2yuqKrt9dl9+uZYviKmtb6+qCWBcb6AqiWKgCUgRCD6ElkJBez++PO+Al3IQEcjMp5/l43Efmznxm5mRyc993Zu58RlQVY4wxprwgtwswxhhTN1lAGGOM8csCwhhjjF8WEMYYY/yygDDGGOOXBYQxxhi/LCCMcYmIvCoif6pi220ict7JLseY6rCAMPWOiPxCRJaJSI6I7BaRT0XkzHJtrhcRFZHx5cafIyJlzry+j6G1+1sYU/dZQJh6RUSmANOBR4CWQAfgn8CYck2vAw44P8tLU9XIco/vAlm3MfWRBYSpN0QkBpgG3K6q76lqrqoWq+qHqnqfT7uOwNnAZOACEWl5EuvcJiL3ichqEckVkZdEpKWz15ItIv8TkWY+7S8VkbUikikiX4pIT59pA0VkhTPfW0B4uXVdLCIrnXm/FZF+J1jzzSKSIiIHRGSOiLRxxouIPCki+0Qky/md+jjTLhSRdU5tu0Tk3hPaYKZBsYAw9clQvG+q7x+n3bXAMlV9F1gPXH2S670COB/oDlwCfAo8CDTH+z90F4CIdAdmAncDCcAnwIciEioiocAHwL+BOOBtZ7k48yYBLwO3APHA88AcEQmrTqEici7wKDAeaA1sB2Y5k0cCZzm/RyxwFZDhTHsJuEVVo4A+wPzqrNc0TBYQpj6JB9JVteQ47a4F/uMM/4djDzO1cT6l+z4iKlne06q6V1V3AV8Di1X1B1UtxBtWA512VwEfq+rnqloM/A1oApwODAFCgOnOXs87wFKfddwMPK+qi1W1VFVfAwqd+arjauBlVV3h1PcAMFREEoFiIAroAYiqrlfV3c58xUAvEYlW1YOquqKa6zUNkAWEqU8ygOYiElxRAxE5A+jEz5+a/wP0FZEBPs3SVDW23CO3kvXu9RnO9/M80hlug/cTOwCqWgbsBNo603bp0b1jbvcZ7gj8xje0gPbOfNVRvoYcvNutrarOB54BZgB7ReQFEYl2ml4BXAhsF5GFdtLegAWEqV++AwqAyyppcx0gwEoR2QMsdsZfG+DaANLwvtED3mP+eN/kdwG7gbbOuMM6+AzvBP5cLrSaqurMk6whAu+e1y4AVf2Hqp4K9MZ7qOk+Z/xSVR0DtMB7KGx2NddrGiALCFNvqGoW8HtghohcJiJNRSREREaLyF9EJBzvsffJwACfx53A1ZXtedSQ2cBFIjJCREKA3+A9TPQt3nArAe4SkWARGQsM8pn3ReBWERnsnEyOEJGLRCSqmjX8B7hBRAY45y8ewXtIbJuInOYsPwTIxRu2pc45kqtFJMY5NHYIKD2J7WAaCAsIU6+o6hPAFOAhYD/eT9534P3UexneQz6vq+qeww+8J2A9wChnMW38XAdxxTErq35tG4BJwNNAOt4T2peoapGqFgFjgeuBg3jPV7znM+8yvOchnnGmpzhtq1vDF8D/Ae/i3WvpAkxwJkfjDaKDeA9DZeA9TwJwDbBNRA4Btzq/h2nkxG4YZIwxxh/bgzDGGOOXBYQxxhi/LCCMMcb4ZQFhjDHGr0B/7a/WNG/eXBMTE90uwxhj6pXly5enq2qCv2kNJiASExNZtmyZ22UYY0y9IiLbK5pmh5iMMcb4ZQFhjDHGLwsIY4wxfjWYcxDGmIajuLiY1NRUCgoK3C6lwQgPD6ddu3aEhIRUeR4LCGNMnZOamkpUVBSJiYkc3QGuORGqSkZGBqmpqXTq1KnK89khJmNMnVNQUEB8fLyFQw0REeLj46u9R2YBYYypkywcataJbM9GHxBpmfk88dkGtqZXdkMxY4xpfBp9QBzILeIf81PYsCfb7VKMMXVERkYGAwYMYMCAAbRq1Yq2bdseeV5UVFSlZdxwww1s2LCh0jYzZszgzTffrImSA6LRn6SOjwwFICO30OVKjDF1RXx8PCtXrgTg4YcfJjIyknvvvfeoNqqKqhIU5P9z9iuvvHLc9dx+++0nX2wANfo9iLgIb0AcyKnapwJjTOOVkpJCnz59uPXWW0lKSmL37t1MnjyZ5ORkevfuzbRp0460PfPMM1m5ciUlJSXExsYydepU+vfvz9ChQ9m3bx8ADz30ENOnTz/SfurUqQwaNIhTTjmFb7/9FoDc3FyuuOIK+vfvz8SJE0lOTj4SXoHW6PcgwoI9RIYFk5FrAWFMXfTHD9eyLu1QjS6zV5to/nBJ7xOad926dbzyyis899xzADz22GPExcVRUlLC8OHDGTduHL169TpqnqysLM4++2wee+wxpkyZwssvv8zUqVOPWbaqsmTJEubMmcO0adOYO3cuTz/9NK1ateLdd99l1apVJCUlnVDdJ6LR70GAdy/igAWEMaYKunTpwmmnnXbk+cyZM0lKSiIpKYn169ezbt26Y+Zp0qQJo0ePBuDUU09l27Ztfpc9duzYY9osWrSICRO8txXv378/vXufWLCdiEa/BwHe8xAWEMbUTSf6ST9QIiIijgxv2rSJp556iiVLlhAbG8ukSZP8XmsQGhp6ZNjj8VBSUuJ32WFhYce0UdWaLL9aAroHISKjRGSDiKSIyDH7UyISJiJvOdMXi0iiM/5qEVnp8ygTkQGBqjM+ItQOMRljqu3QoUNERUURHR3N7t27mTdvXo2v48wzz2T27NkA/Pjjj373UAIlYHsQIuIBZgDnA6nAUhGZo6q+v91NwEFV7SoiE4DHgatU9U3gTWc5fYH/qmrAzsrERYTy466sQC3eGNNAJSUl0atXL/r06UPnzp0544wzanwdd955J9deey39+vUjKSmJPn36EBMTU+Pr8UcCtfsiIkOBh1X1Auf5AwCq+qhPm3lOm+9EJBjYAySoT1Ei8oh3Nv1dZetLTk7WE71h0GOf/sRLi7aw8U+j7epNY+qA9evX07NnT7fLqBNKSkooKSkhPDycTZs2MXLkSDZt2kRwcPU/3/vbriKyXFWT/bUP5DmItsBOn+epwOCK2qhqiYhkAfFAuk+bq4Ax/lYgIpOByQAdOnQ44ULjI0IpLlWyC0uIDq96T4fGGBNoOTk5jBgxgpKSElSV559//oTC4UQEci3+PoqX312ptI2IDAbyVHWNvxWo6gvAC+DdgzjBOo+6FsICwhhTl8TGxrJ8+XJX1h3Ik9SpQHuf5+2AtIraOIeYYoADPtMnADMDWCMAcUeuprYT1cYYc1ggA2Ip0E1EOolIKN43+znl2swBrnOGxwHzD59/EJEg4EpgVgBrhJz9dN31AS05YF91NcYYHwELCFUtAe4A5gHrgdmqulZEponIpU6zl4B4EUkBpgC+X4U9C0hV1S2BqhGArJ20/+o++gVtISPH+mMyxpjDAnqmQ1U/AT4pN+73PsMFePcS/M37JTAkkPUBEN0GgJZy0A4xGWOMD+tqIyIBxEO74Ew7xGSMAeCcc8455qK36dOnc9ttt1U4T2RkJABpaWmMGzeuwuUe7+v406dPJy8v78jzCy+8kMzMzKqWXqMsIII8ENmS9sFZFhDGGAAmTpzIrFlHn/6cNWsWEydOPO68bdq04Z133jnhdZcPiE8++YTY2NgTXt7JsIAAiGpF66BMO8RkjAFg3LhxfPTRRxQWes9Lbtu2jbS0NAYMGMCIESNISkqib9++/Pe//z1m3m3bttGnTx8A8vPzmTBhAv369eOqq64iPz//SLtf/epXR7oJ/8Mf/gDAP/7xD9LS0hg+fDjDhw8HIDExkfR076VhTzzxBH369KFPnz5Hugnftm0bPXv25Oabb6Z3796MHDnyqPWcDOusDyC6DS32r7GT1MbURZ9OhT0/1uwyW/WF0Y9VODk+Pp5BgwYxd+5cxowZw6xZs7jqqqto0qQJ77//PtHR0aSnpzNkyBAuvfTSCntgePbZZ2natCmrV69m9erVR3XV/ec//5m4uDhKS0sZMWIEq1ev5q677uKJJ55gwYIFNG/e/KhlLV++nFdeeYXFixejqgwePJizzz6bZs2asWnTJmbOnMmLL77I+PHjeffdd5k0adJJbybbgwCIakVc2QH2HrKAMMZ4+R5mOnx4SVV58MEH6devH+eddx67du1i7969FS7jq6++OvJG3a9fP/r163dk2uzZs0lKSmLgwIGsXbv2uJ3wLVq0iMsvv5yIiAgiIyMZO3YsX3/9NQCdOnViwABvf6aVdSdeXbYHARDViqalh8guyKaguJTwEI/bFRljDqvkk34gXXbZZUyZMoUVK1aQn59PUlISr776Kvv372f58uWEhISQmJjot3tvX/72LrZu3crf/vY3li5dSrNmzbj++uuPu5zK+s073E04eLsKr6lDTLYHARDl/aprCznInqzK/0jGmMYhMjKSc845hxtvvPHIyemsrCxatGhBSEgICxYsYPv27ZUu46yzzuLNN98EYM2aNaxevRrwdhMeERFBTEwMe/fu5dNPPz0yT1RUFNnZ2X6X9cEHH5CXl0dubi7vv/8+w4YNq6lf1y/bgwCIagVAKw6SlplPYvOI48xgjGkMJk6cyNixY48carr66qu55JJLSE5OZsCAAfTo0aPS+X/1q19xww030K9fPwYMGMCgQYMA753hBg4cSO/evY/pJnzy5MmMHj2a1q1bs2DBgiPjk5KSuP76648s45e//CUDBw6sscNJ/gSsu+/adjLdfbNvPfxzCHcU3cnZY2/hyuT2x5/HGBMw1t13YFS3u287xARH9iBaykHSMu0QkzHGgAWEV3gsBDehU9gh0jJr5uSOMcbUdxYQACIQ1Yr2IVmkZVlAGFMXNJTD33XFiWxPC4jDolrTJuggu2wPwhjXhYeHk5GRYSFRQ1SVjIwMwsPDqzWffYvpsJh2JOz5it05Baiq3ZvaGBe1a9eO1NRU9u/f73YpDUZ4eDjt2rWr1jwWEIfFdSam6G3KivPJzCummXMbUmNM7QsJCaFTp05ul9Ho2SGmw+K7ICjtZZ8dZjLGGCwgfhbXBYBOsscCwhhjsID4WXxnABJlD1vTc10uxhhj3GcBcViTZtA0np5h+0nZl+N2NcYY4zoLCF9xXegRspdNFhDGGGMBcZT4LrQr203K3mz7/rUxptGzgPAV14Xo4v2UFuWx27r9NsY0chYQvuK932RKFDvMZIwxFhC+nIDoLGls2nvsDTuMMaYxsYDw1fwUCArm1LBU+yaTMabRs4DwFRIOLXqSHLLNDjEZYxo9C4jyWg+ga+lmftqdRWmZfZPJGNN4BTQgRGSUiGwQkRQRmepnepiIvOVMXywiiT7T+onIdyKyVkR+FJHq9VN7otoMJKI0i2bFe9mwx85DGGMar4AFhIh4gBnAaKAXMFFEepVrdhNwUFW7Ak8CjzvzBgNvALeqam/gHKA4ULUepc1AAPrIVlbsOFgrqzTGmLookHsQg4AUVd2iqkXALGBMuTZjgNec4XeAEeK9EcNIYLWqrgJQ1QxVLQ1grT9r2RsNCmFw2HZWbLeAMMY0XoEMiLbATp/nqc44v21UtQTIAuKB7oCKyDwRWSEiv/W3AhGZLCLLRGRZjd1YJDgMadmLweHbWW57EMaYRiyQAeHvlmzlz/pW1CYYOBO42vl5uYiMOKah6guqmqyqyQkJCSdb78/ankrXog2kZRwiPaew5pZrjDH1SCADIhVo7/O8HZBWURvnvEMMcMAZv1BV01U1D/gESApgrUfrMoLQ0lxODdrIcjvMZIxppAIZEEuBbiLSSURCgQnAnHJt5gDXOcPjgPnq7SVvHtBPRJo6wXE2sC6AtR6t89loUAjnh6xi4Ua7J64xpnEKWEA45xTuwPtmvx6YraprRWSaiFzqNHsJiBeRFGAKMNWZ9yDwBN6QWQmsUNWPA1XrMcKikI6nMzrsRz5ft5cyux7CGNMIBQdy4ar6Cd7DQ77jfu8zXABcWcG8b+D9qqs7uo2kzdbfEVKwix92HuTUjnGulWKMMW6wK6kr0m0kAKNCljNv7V6XizHGmNpnAVGRhO7Qqi/Xhn/D3DV77AZCxphGxwKiMgOvJbE4haiD6/gmJcPtaowxplZZQFSm35WoJ4xrw7/ite+2uV2NMcbUKguIyjRphvS6lDFBi1iyfgs7D+S5XZExxtQaC4jjOf0uwktzuDF4Li8t2up2NcYYU2ssII6ndT/oeSm3hMzlo8Vr2ZFhexHGmMbBAqIqznmAsLI87vK8y98/3+B2NcYYUyssIKqiZS/ktJu4JmgeO1Yt5OtN1v2GMabhs4CoqhF/gOg2TG/yIg/NXkpWXu3cv8gYY9xiAVFV4dHImGfoULaLuwtm8JvZK+2e1caYBs0Cojq6nIsMf5DLPYvosOk1Hp/7k9sVGWNMwFhAVNewe6HnJTwU8ga7F73BrCU73K7IGGMCwgKiuoKCYOy/kA5DeTL0OT7570y+SUl3uypjjKlxFhAnIiQcmTgTSejOcyFP8tTrb7FyZ6bbVRljTI2ygDhRTWLxXPMeYdHNeTHoUf700tv8tOeQ21UZY0yNsYA4GdGt8Vw/h4iISF5gGg+9+B5b03PdrsoYY2qEBcTJiutM8A0fEt0kjGdLH+b+Fz5gV2a+21UZY8xJs4CoCc27EXzDhzQLF54q/D/ufWEO+7ML3a7KGGNOigVETWnRk+Dr/ktCWDF/yX2Ie1782K62NsbUaxYQNal1P4Kv+4DWIbn8v6wHuPtfc8kpLHG7KmOMOSEWEDWt7akEX/se7YMP8UD6/fzmlf9RUFzqdlXGGFNtFhCB0GEIwZNm0yU4nV+n/Zb7//0lxaVlbldljDHVYgERKJ2G4fnFTE7xpHHDtnv53cxvrHM/Y0y9YgERSF1H4Jnwb/p6djB+4xSmvbsYVQsJY0z9YAERaKeMxnPlyyQFbWbU6nt4fM4PFhLGmHohoAEhIqNEZIOIpIjIVD/Tw0TkLWf6YhFJdMYniki+iKx0Hs8Fss6A6zUGGfscgz3rOX3ZXcz4fK3bFRljzHEFLCBExAPMAEYDvYCJItKrXLObgIOq2hV4EnjcZ9pmVR3gPG4NVJ21RfqNhzEzONOzht5f38YrX9m9rY0xdVsg9yAGASmqukVVi4BZwJhybcYArznD7wAjREQCWJOrggZejV48neGeVbT7/FbeXrzZ7ZKMMaZCgQyItsBOn+epzji/bVS1BMgC4p1pnUTkBxFZKCLDAlhnrfIkX0/x6L9xvmcFUR/dwkc/bHe7JGOM8SuQAeFvT6D82dmK2uwGOqjqQGAK8B8RiT5mBSKTRWSZiCzbv3//SRdcW0IG30zReY8wyrMUeW8yC9btcrskY4w5RiADIhVo7/O8HZBWURsRCQZigAOqWqiqGQCquhzYDHQvvwJVfUFVk1U1OSEhIQC/QuCEnnk7BcMf5iLP92TPmsx3m/a5XZIxxhwlkAGxFOgmIp1EJBSYAMwp12YOcJ0zPA6Yr6oqIgnOSW5EpDPQDdgSwFpdEX72PeQN+x2XBi1izxu/ZOWOA26XZIwxRwQsIJxzCncA84D1wGxVXSsi00TkUqfZS0C8iKTgPZR0+KuwZwGrRWQV3pPXt6pqg3z3bDrit+QMvY/LZSEpL/+Sn3bbrUuNMXWDNJSLtpKTk3XZsmVul3FiVMn65A/ELH2K2TKK0257iU4JkW5XZYxpBERkuaom+5tmV1LXBSLEXPhHDg64lfE6l6XP3cKug3luV2WMaeQsIOoKEZqNeYz0PjcxvvQjvv7nr9iXZbcuNca4xwKiLhGh+RV/Z1+Pa5hQ/AGfz7iD/YcK3K7KGNNIWUDUNSK0GP8P9nabyNVF7/DJjLtJz7H7Wxtjap8FRF0UFETLif9kX5cruK5wJh8+8xsO5Ba5XZUxppGxgKirgoJocfWL7Ot0GTcU/Jv3nrmfzDwLCWNM7bGAqMuCPLSY9BL7OlzEL/Nf5p1nppKVV+x2VcaYRqJKASEivxaRaPF6SURWiMjIQBdnAE8wLa57jX3tR/PLvJf48Jl7OJRvexLGmMCr6h7Ejap6CBgJJAA3AI8FrCpzNE8ILa5/g7SOlzEp79/87+nbyLaQMMYEWFUD4nCvqxcCr6jqKvz3xGoCxRNMm+teYUfnCYzNe5uvnrqRzFz7CqwxJnCqGhDLReQzvAExT0SigLLAlWX8CgqiwzXPsa37jVxU8CGLp1/Nvswct6syxjRQVQ2Im/B2pHeaquYBIXgPM5naJkLixCfY0e/XXFD8P356eiyp+zLcrsoY0wBVNSCGAhtUNVNEJgEP4b37m3GDCB3GTmPnkGmcWbqEjGcvZPP2HW5XZYxpYKoaEM8CeSLSH/gtsB14PWBVmSppP+rX7D7/WXpqCvLKKNatX+t2ScaYBqSqAVGi3n7BxwBPqepTQFTgyjJV1faMiRwY+xYJHCRu1sWsXPat2yUZYxqIqgZEtog8AFwDfOzc7S0kcGWZ6mjV7zyKrvmY4CDo/OEVLFv4kdslGWMagKoGxFVAId7rIfYAbYG/BqwqU23xXZIInvwFWcFx9J1/Pd9++LLbJRlj6rkqBYQTCm8CMSJyMVCgqnYOoo6Jbd2ZZncsYHtYN4Ysm8KXbzxCQ7ljoDGm9lW1q43xwBLgSmA8sFhExgWyMHNiIpu1IPGez1kXNZRzUh7ny2fvoqSk1O2yjDH1UFUPMf0O7zUQ16nqtcAg4P8CV5Y5GaFNIul9zxxWtRjD8H2v8930X5BfYPeUMMZUT1UDIkhV9/k8z6jGvMYF4gmh/69eY1WXWxiWM5c1T1xExoEDbpdljKlHqvomP1dE5onI9SJyPfAx8EngyjI1QoT+1/yFtQMfJqlwGXufuYDU1J1uV2WMqSeqepL6PuAFoB/QH3hBVe8PZGGm5vQecw9bRzxH57KtlP3rPH5au9Ltkowx9YA0lG+5JCcn67Jly9wuo05LXbWAiPevBVW2nP8vTj1zlNslGWNcJiLLVTXZ37RK9yBEJFtEDvl5ZIvIocCUawKlXf/hlN3wGXmeSPp8Polv5/zL7ZKMMXVYpQGhqlGqGu3nEaWq0bVVpKk58R17EnPnQraHdeP0Fb/h61d/j5ZZz+3GmGPZN5EaochmLek05X+sjD6HYdue4runb6CoyO5QZ4w5WkADQkRGicgGEUkRkal+poeJyFvO9MUiklhuegcRyRGRewNZZ2MUEh5B/7vfY1nbazj94AeseeJisrIy3S7LGFOHBCwgnA79ZgCjgV7ARBHpVa7ZTcBBVe0KPAk8Xm76k8CngaqxsZMgD8k3P8MPfR+if/4S9jw1gl07t7pdljGmjgjkHsQgIEVVt6hqETALb3fhvsYArznD7wAjREQAROQyYAtgNzkIsIFX3MfGc1+gQ9lOgl46j59WL3G7JGNMHRDIgGgL+F6VleqM89tGVUvw3qUuXkQigPuBP1a2AhGZLCLLRGTZ/v37a6zwxqjn2eNJH/cBoZTS5t0xLJn/gdslGWNcFsiAED/jyl90UVGbPwJPqmpOZStQ1RdUNVlVkxMSEk6wTHNY+z6nIzf/j8zg5gxYeCNfzv6H9QZrTCMWyIBIBdr7PG8HpFXURkSCgRjgADAY+IuIbAPuBh4UkTsCWKtxxLXtSou7F7K1aV/OWfd/zH/+XusN1phGKpABsRToJiKdRCQUmADMKddmDnCdMzwOmK9ew1Q1UVUTgenAI6r6TABrNT7Co+LoNuUzfmw+mhF7/sV3T04kJy/f7bKMMbUsYAHhnFO4A5gHrAdmq+paEZkmIpc6zV7Ce84hBZgCHPNVWOOOoJAw+t4+kx+73sqw3HlsemIUe/ftO/6MxpgGw/piMsf106fP0uX737EjqA1lV82kW4++bpdkjKkhJ9wXkzEAPUb/irSL3yBBD9J85miWLfzI7ZKMMbXAAsJUScfTLqTohs/J9cTQb/61LJj5d/uGkzENnAWEqbLmHXvR/J6v2RyRxPAN01j4j5spKLQ+nIxpqCwgTLWER8XR4zefsqrtBM45+Dbr/3YB+/budrssY0wAWECYahNPCP1vfp41yX+iT9EqCp89hw2rFrtdljGmhllAmBPW5+I72XXZuzShkHbvXcJ3H73qdknGmBpkAWFOSuLA4Xhu+ZLdoYkMXfZr5j/7awrt3hLGNAgWEOakNWudSOK9X7I64WLO3fsq6/46krRdO9wuyxhzkiwgTI0IDmtKv9veYM2pf6JX0Ro8L57NikV2Kw9j6jMLCFNzROhzyZ2kT/iY0qAw+n3+C7569feUldo9r42pjywgTI1r23Mwze7+jnXRZ3DWtqdY8beLycyw+3UYU99YQJiAaBLdjL73zGF5j/von/c9uc+cwZrFX7hdljGmGiwgTMBIUBCnTniIbZe8TRBl9PhkHF//67cUFRW7XZoxpgosIEzAdUseQdTdi/kx9lyGpT7Ppr+czfbNP7ldljHmOCwgTK2IjIln4D3vsuq0v9CxZAvNXh/ON+/NQMvsBLYxdZUFhKlV/S+6hfybFrInLJEzVj/I6r+O4kDaFrfLMsb4YQFhal1C+1Po+tuv+b77fXTLW0noC6ez/sOnwPYmjKlTLCCMK4KCgxnyi4fYffUXbAruRs/lv2fjX4eTsdPOTRhTV1hAGFd16d6X3vd/yRfdHqJ13gaavjSMlbP/hJaWuF2aMY2eBYRxXWiIhxFX30f6dV+xLmwgA9b9lZTHziBtvXUhboybLCBMndGpc3cG/nYu3/R/lPiiXbScdQGrX7iZwuwMt0szplGygDB1SpAniDMuv42S25fxVcwYeu96m/y/D2D9x0/bSWxjapkFhKmTWrRoxfApr7Hywjns8LSj59KH2PLYEHat/cbt0oxpNCwgTJ126uCz6DF1EQt6/Ymowr20nn0RK/95LbkH97pdmjENngWEqfNCQzwMH38n3LmMr+KvpM/eDyl7agBr356GFuW5XZ4xDZYFhKk3EponcM5dL7Jh7Dx+CulN77V/J+Oxvv3jR5QAABOmSURBVGz+7HkoK3W7PGMaHAsIU+/07j+IUx/4nAVDXmafxtDl29+S+uip7FryX1B1uzxjGoyABoSIjBKRDSKSIiJT/UwPE5G3nOmLRSTRGT9IRFY6j1Uicnkg6zT1T1CQMHzUFXSaupjPej2KFuXR9pNrSfnbuWRssusnjKkJAQsIEfEAM4DRQC9gooj0KtfsJuCgqnYFngQed8avAZJVdQAwCnheRIIDVaupv5qEhTBy/G1E/GYFc9vfQ1zOJuLfHMm6p68ke0+K2+UZU68Fcg9iEJCiqltUtQiYBYwp12YM8Joz/A4wQkREVfNU9XBfC+GAHTcwlYqLjmTUTQ+Te8sy5sVNolP6l4Q/N5i1L99G0SG73akxJyKQAdEW2OnzPNUZ57eNEwhZQDyAiAwWkbXAj8CtPoFxhIhMFpFlIrJs/357EzDQvk0rLrhrBtt+sYhFTc+jx/b/UPREP9bPfpiyghy3yzOmXglkQIifceX3BCpso6qLVbU3cBrwgIiEH9NQ9QVVTVbV5ISEhJMu2DQcPU85hXPum8Xyiz5mTXAfeq57kqzHe7P+vcfsq7HGVFEgAyIVaO/zvB2QVlEb5xxDDHDAt4GqrgdygT4Bq9Q0SCLCoEFncNqDn/H1sDfYEtSBnqsf5cCjvdkw529ocYHbJRpTpwUyIJYC3USkk4iEAhOAOeXazAGuc4bHAfNVVZ15ggFEpCNwCrAtgLWaBswTJAwbcQn9H1zIwqGvkiqtOGXF/yPj0d5s+PgptKTQ7RKNqZMCFhDOOYM7gHnAemC2qq4VkWkicqnT7CUgXkRSgCnA4a/CngmsEpGVwPvAbaqaHqhaTeMQ7Ani7Asup9eDi/hy8Ivs0ThOWfp79j3Sl41zn0NLi90u0Zg6RbSBXFiUnJysy5Ytc7sMU48UFZfyzbyZtFr+BD11M7s9bcgZci/dRlwPQR63yzOmVojIclVN9jfNrqQ2jVZoiIfhF0+i84NLWDBwOjmlIXT7ZgqpjwwgZcHr1r24afQsIEyjFxYSzPAxN9D+weXM7/tXCkvK6LrwTnY8msTmr2Za9x2m0bKAMMYRHhrCuVdMps3UH5jf6xHKigvpMv9Wtj+azNZv37WgMI2OBYQx5TQJD+Xc8beTcP8PfNHjjwQVZdPpsxvZ/NhQti3+0ILCNBoWEMZUIKJJOCMm3E3sfSv5ottDNCncT+Knk9jy2Omkfv+unaMwDZ4FhDHHERXRlBFX30fEvav5X5cHCC1Ip93cG0l9NIktC16F0mN6gTGmQbCAMKaKYiIjOO+aqUTet4q53f9IYXExnRf+mj2P9OGnj5+2K7NNg2PXQRhzgvIKi/j243/T9scZ9NTNpEsce3r/kh4X3Ulwk2i3yzOmSiq7DsICwpiTVFRcyvdfvEfU0qcYWPojWUSyrcskTrnkHsJjW7ldnjGVsoAwphaUlSlLF81FFj3JoKLFFBJCSutL6HDRfUS1K3+vLGPqBgsIY2qRqrL6hyUcnD+dodmfEybFbIo9g/jzf0Ncr3NB/PVyb4w7LCCMcclPmzez9ZOnGJT+HvGSTWp4d4LOuIM2p/8CPCFul2eMBYQxbtuxN50VHz5H/51v0El2k+5J4EDvG+ky6jY8TWPdLs80YhYQxtQRmbkFfPvpf2i19l8k6VpyacK29peROOouItraeQpT+ywgjKljSkrL+H7R/yj7bgZD8r8mVErZHHUaUcNupcWpl4En2O0STSNhAWFMHbZu4ya2fv4cSfveo7UcIMPTgsze15B43i14olu6XZ5p4CwgjKkH9mXm8P2nb9Bq4xsM0h8pwcOO5mcRf9bNxPQZZTcxMgFhAWFMPVJUUsY3i78l59tXGJrzGc3lEAeDm5PbcwJth/8SievkdommAbGAMKaeStl9gOWfz6TNlrc5XVfiEWVH7CAih95I3MAxENrU7RJNPWcBYUw9l19UyoIlK8hZ/DqnH/qEdpJOvjRhf7uRtDxjEmHdzrUT2+aEWEAY04DszMhh8YI5hK9/l7NKviVa8sgOjiO326W0GDqJoPbJdrW2qTILCGMaoLIyZenm3axf+A5tdn7I2awgTEo4ENaWkp5XkDDkKqRlbwsLUykLCGMauNzCEr5ctYl9i9/mlP1zGSzr8IhyoElHtNdlxJ82HiwsjB8WEMY0Ipl5RSxYvoaDy9+lx4H5DJb1eETJCmtDSZfziRtwMdLpLAgJd7tUUwdYQBjTSO3LLmD+0jVk/vABXTO/4YygNTSRIookjKzWZxDb/2JCup8HzTq6XapxiQWEMYaMnEIWrktl1w+fEZ+2gGG6gvZB+wHIbtqeoC7DiegxAjqdBU3jXK7W1BbXAkJERgFPAR7gX6r6WLnpYcDrwKlABnCVqm4TkfOBx4BQoAi4T1XnV7YuCwhjqq6wpJTvN2ew+ofFlKQsoE/hDwwJWk+U5FOGkNOsF2HdzyWs23BodxqE2y1UGypXAkJEPMBG4HwgFVgKTFTVdT5tbgP6qeqtIjIBuFxVrxKRgcBeVU0TkT7APFVtW9n6LCCMOTGqyqZ9OSzasJtd674lJu0bBrOagbKJUCmljCByY7sTmjiUsE5Dof0gaJZoJ7wbCLcCYijwsKpe4Dx/AEBVH/VpM89p852IBAN7gAT1KUpEBEgH2qhqYUXrs4AwpmYUlpSyfPtBFv+0k8yNi4jL+IGBspGBQSlEST4ABWHxaKsBhHdMQtoMhNb9IbqthUY9VFlABPLSy7bATp/nqcDgitqoaomIZAHxeAPhsCuAH/yFg4hMBiYDdOjQoeYqN6YRCwv2cHqX5pzepTlcNJD8olJWpWby+tb97E5ZSejupfTO20CfrRvoun0BHsoAKAqLQ9r0J6RdkjcwWg+A2A4WGvVYIAPC36ui/O5KpW1EpDfwODDS3wpU9QXgBfDuQZxYmcaYyjQJ9TCkczxDOsfDiB6Ull3Fxr3ZLNl+kBe3pJG97Qda5G6gb8lW+mzeQvetXxFMKQAlwREQ343gVj2heXdIOAUSekBsR+sapB4I5F8oFWjv87wdkFZBm1TnEFMMcABARNoB7wPXqurmANZpjKkGT5DQs3U0PVtHc82QjsBQDuYWsTbtEAt3ZfH8zv0U7FpNfPZPdCtJpWvaLrrvnUdLZh5ZRllQKBrXGU/zrhDXGeK7eH/GdYGo1hAU5N4vaI4IZEAsBbqJSCdgFzAB+EW5NnOA64DvgHHAfFVVEYkFPgYeUNVvAlijMaYGNIsI5cxuzTmzW3OgCzCErPxi1qZlsS7tEB/tzSF1zx7K9m+kbckOusouuuxNo0v6StozjxCKjyyrzBMOcZ0IapYIMW0hph1Et/t5OKo1eELc+lUblUB/zfVCYDrer7m+rKp/FpFpwDJVnSMi4cC/gYF49xwmqOoWEXkIeADY5LO4kaq6r6J12UlqY+o+VSUtq4CNe7PZuCebjXtz2JF+iPyMncTk7yBR9pIoe0iUPXT0ZNBGMojUnKOXgUBUKySmnffEeEw7J0TaekMkshVENIfgMJd+y/rFLpQzxtR52QXFbM/IY3tGHtsyctmekcu2jDz2pafjydlNW0mntRygjWTQVjJIDDlIG8mgedl+QrXomOVpeAwSkQARCd7AiGjx83Dk4WHnER7TaE+mu/UtJmOMqbKo8BD6tI2hT9uYY6blFZWw40AeaZn5pGUWsCUzn2+yCtiVmc/uzDwKsvbTQjNoLRkkSCbxHKJFWTZtinJoeegQ8aQRU5ZF09Is5JjvygBBIceGR9N4aBILTZpBeGy54WbeUGngt4G1gDDG1HlNQ4Pp0SqaHq38X9FdWqak5xQeCZDdWfnsyilkZXYh+51Hek4hmYX5NNNs4uUQ8ZJFPIdIkCxah+TQpiCHlkXZxB3cSUzZGiJLMwktK6iwJkWQ8OifA6N8gDSJ9YZIWBSERTs/oyA08ufhOn4uxQLCGFPveYKEltHhtIwOZ2All0SVlJaRkVt0JDT2ZxeyP6eQ1OxCVmQXcCC3iMy8YrLyi8ksKKakuJAYcomRHGLIJdbnZ6zk0qIgn/iSfOLycomRfUTrZiLKcmhSegiPlh6/8OAmP4dFpQ9/AeMzLqRJQA6RWUAYYxqNYE/QkSCpisKSUrLyi8nKKyYzv5jMvGIy84q84/KLWXdkvHfc4enZhcU01QIiySdS8olyfkaST5TkER9cRHxIIc2CC2lGAdFFBUQW59M0O5smuofw0jxCy/IILc4hSIuPX2ivy2D8aye5dY5lAWGMMRUIC/bQIspDi6jq3TujtEzJLnACI//oUPGGSDHr84uOBE9WfjE5BSXkFHofvkIpPjpoyCdS8oj1FBIfXEhccCHxhT25siZ/cYcFhDHG1DBPkBDbNJTYpqHVnresTMkt8gZFbmEJ2YeDwydAfIf3FpbQ18+J/ZpgAWGMMXVIUJAQFR5CVLj7J7DtenZjjDF+WUAYY4zxywLCGGOMXxYQxhhj/LKAMMYY45cFhDHGGL8sIIwxxvhlAWGMMcavBnM/CBHZD2w/iUU0B9JrqJyaZHVVj9VVfXW1Nqurek60ro6qmuBvQoMJiJMlIssqummGm6yu6rG6qq+u1mZ1VU8g6rJDTMYYY/yygDDGGOOXBcTPXnC7gApYXdVjdVVfXa3N6qqeGq/LzkEYY4zxy/YgjDHG+GUBYYwxxq9GHxAiMkpENohIiohMdbGO9iKyQETWi8haEfm1M/5hEdklIiudx4Uu1bdNRH50aljmjIsTkc9FZJPzs1kt13SKz3ZZKSKHRORuN7aZiLwsIvtEZI3POL/bR7z+4bzmVotIUi3X9VcR+clZ9/siEuuMTxSRfJ/t9lyg6qqktgr/diLygLPNNojIBbVc11s+NW0TkZXO+FrbZpW8RwTudaaqjfYBeIDNQGcgFFgF9HKpltZAkjMcBWwEegEPA/fWgW21DWhebtxfgKnO8FTgcZf/lnuAjm5sM+AsIAlYc7ztA1wIfAoIMARYXMt1jQSCneHHfepK9G3n0jbz+7dz/hdWAWFAJ+f/1lNbdZWb/nfg97W9zSp5jwjY66yx70EMAlJUdYuqFgGzgDFuFKKqu1V1hTOcDawH2rpRSzWMAV5zhl8DLnOxlhHAZlU9mavpT5iqfgUcKDe6ou0zBnhdvb4HYkWkdW3VpaqfqWqJ8/R7oF0g1n08FWyziowBZqlqoapuBVLw/v/Wal0iIsB4YGYg1l2ZSt4jAvY6a+wB0RbY6fM8lTrwpiwiicBAYLEz6g5nF/Hl2j6M40OBz0RkuYhMdsa1VNXd4H3xAi1cqg1gAkf/09aFbVbR9qlLr7sb8X7KPKyTiPwgIgtFZJhLNfn729WVbTYM2Kuqm3zG1fo2K/ceEbDXWWMPCPEzztXv/YpIJPAucLeqHgKeBboAA4DdeHdv3XCGqiYBo4HbReQsl+o4hoiEApcCbzuj6so2q0ideN2JyO+AEuBNZ9RuoIOqDgSmAP8RkehaLquiv12d2GbARI7+IFLr28zPe0SFTf2Mq9Y2a+wBkQq093neDkhzqRZEJATvH/5NVX0PQFX3qmqpqpYBLxKg3erjUdU05+c+4H2njr2Hd1mdn/vcqA1vaK1Q1b1OjXVim1Hx9nH9dSci1wEXA1erc8DaOXyT4Qwvx3ucv3tt1lXJ364ubLNgYCzw1uFxtb3N/L1HEMDXWWMPiKVANxHp5HwKnQDMcaMQ59jmS8B6VX3CZ7zvMcPLgTXl562F2iJEJOrwMN6TnGvwbqvrnGbXAf+t7docR32qqwvbzFHR9pkDXOt8y2QIkHX4EEFtEJFRwP3Apaqa5zM+QUQ8znBnoBuwpbbqctZb0d9uDjBBRMJEpJNT25LarA04D/hJVVMPj6jNbVbRewSBfJ3Vxtn3uvzAe6Z/I97k/52LdZyJd/dvNbDSeVwI/Bv40Rk/B2jtQm2d8X6DZBWw9vB2AuKBL4BNzs84F2prCmQAMT7jan2b4Q2o3UAx3k9uN1W0ffDu+s9wXnM/Asm1XFcK3mPTh19nzzltr3D+vquAFcAlLmyzCv92wO+cbbYBGF2bdTnjXwVuLde21rZZJe8RAXudWVcbxhhj/Grsh5iMMcZUwALCGGOMXxYQxhhj/LKAMMYY45cFhDHGGL8sIIypA0TkHBH5yO06jPFlAWGMMcYvCwhjqkFEJonIEqfv/+dFxCMiOSLydxFZISJfiEiC03aAiHwvP9934XA//V1F5H8issqZp4uz+EgReUe892p407ly1hjXWEAYU0Ui0hO4Cm/HhQOAUuBqIAJvX1BJwELgD84srwP3q2o/vFeyHh7/JjBDVfsDp+O9ahe8vXPejbeP/87AGQH/pYypRLDbBRhTj4wATgWWOh/um+DtGK2MnztwewN4T0RigFhVXeiMfw142+nTqq2qvg+gqgUAzvKWqNPPj3jvWJYILAr8r2WMfxYQxlSdAK+p6gNHjRT5v3LtKuu/prLDRoU+w6XY/6dxmR1iMqbqvgDGiUgLOHIv4I54/4/GOW1+ASxS1SzgoM8NZK4BFqq3//5UEbnMWUaYiDSt1d/CmCqyTyjGVJGqrhORh/DeWS8Ib2+ftwO5QG8RWQ5k4T1PAd6ul59zAmALcIMz/hrgeRGZ5izjylr8NYypMuvN1ZiTJCI5qhrpdh3G1DQ7xGSMMcYv24Mwxhjjl+1BGGOM8csCwhhjjF8WEMYYY/yygDDGGOOXBYQxxhi//j/fmWbr2qU/mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('CAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.018829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.025205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.037880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.072575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.029721\n",
       "std      0.012799\n",
       "min      0.017072\n",
       "25%      0.018829\n",
       "50%      0.025205\n",
       "75%      0.037880\n",
       "max      0.072575"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.017404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.025245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.037855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.068888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.029741\n",
       "std      0.012492\n",
       "min      0.017404\n",
       "25%      0.019056\n",
       "50%      0.025245\n",
       "75%      0.037855\n",
       "max      0.068888"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79766583"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944791</td>\n",
       "      <td>0.826066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.052547</td>\n",
       "      <td>1.758963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.258051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279328</td>\n",
       "      <td>2.331589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.215151</td>\n",
       "      <td>0.131307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.537620</td>\n",
       "      <td>0.876586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335007</td>\n",
       "      <td>2.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.680979</td>\n",
       "      <td>1.608862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.159663</td>\n",
       "      <td>0.649761</td>\n",
       "      <td>1.996020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.644471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.028079</td>\n",
       "      <td>0.710731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.954616</td>\n",
       "      <td>1.111267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.305335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425506</td>\n",
       "      <td>3.485317</td>\n",
       "      <td>1.421772</td>\n",
       "      <td>1.219794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.521893</td>\n",
       "      <td>0.795483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2    3    4         5         6         7         8   \\\n",
       "0  0.944791  0.826066  0.0  0.0  0.0  1.052547  1.758963  0.000000  2.258051   \n",
       "1  2.215151  0.131307  0.0  0.0  0.0  2.537620  0.876586  0.000000  0.000000   \n",
       "2  0.680979  1.608862  0.0  0.0  0.0  1.159663  0.649761  1.996020  0.000000   \n",
       "3  0.000000  0.325800  0.0  0.0  0.0  0.000000  0.000000  2.028079  0.710731   \n",
       "4  0.000000  1.305335  0.0  0.0  0.0  0.425506  3.485317  1.421772  1.219794   \n",
       "\n",
       "    9         10        11  \n",
       "0  0.0  2.279328  2.331589  \n",
       "1  0.0  0.335007  2.017787  \n",
       "2  0.0  0.000000  2.644471  \n",
       "3  0.0  2.954616  1.111267  \n",
       "4  0.0  1.521893  0.795483  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.953424</td>\n",
       "      <td>0.823370</td>\n",
       "      <td>1.059648</td>\n",
       "      <td>1.758754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.251103</td>\n",
       "      <td>2.272204</td>\n",
       "      <td>2.327313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>2.722368</td>\n",
       "      <td>0.118066</td>\n",
       "      <td>0.965843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.493709</td>\n",
       "      <td>2.469431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.420167</td>\n",
       "      <td>0.887110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.418706</td>\n",
       "      <td>0.139652</td>\n",
       "      <td>2.166840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.128346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.309697</td>\n",
       "      <td>0.435070</td>\n",
       "      <td>3.520647</td>\n",
       "      <td>1.415735</td>\n",
       "      <td>1.225957</td>\n",
       "      <td>1.553437</td>\n",
       "      <td>0.794334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1.627320</td>\n",
       "      <td>2.877653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.861414</td>\n",
       "      <td>0.888510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.305366</td>\n",
       "      <td>1.873148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "405  0.953424  0.823370  1.059648  1.758754  0.000000  2.251103  2.272204   \n",
       "406  0.009724  0.574174  2.722368  0.118066  0.965843  0.000000  2.493709   \n",
       "407  1.420167  0.887110  0.000000  1.418706  0.139652  2.166840  0.000000   \n",
       "408  0.000000  1.309697  0.435070  3.520647  1.415735  1.225957  1.553437   \n",
       "409  1.627320  2.877653  0.000000  1.861414  0.888510  0.000000  1.305366   \n",
       "\n",
       "            7  \n",
       "405  2.327313  \n",
       "406  2.469431  \n",
       "407  2.128346  \n",
       "408  0.794334  \n",
       "409  1.873148  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./dim064_CAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 0s 467us/step - loss: 0.0705 - val_loss: 0.0678\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0664 - val_loss: 0.0644\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0633 - val_loss: 0.0619\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0610 - val_loss: 0.0600\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0593 - val_loss: 0.0586\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0580 - val_loss: 0.0575\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0570 - val_loss: 0.0567\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0562 - val_loss: 0.0560\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0555 - val_loss: 0.0554\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0549 - val_loss: 0.0548\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0544 - val_loss: 0.0543\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0538 - val_loss: 0.0538\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0533 - val_loss: 0.0533\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0529 - val_loss: 0.0529\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0524 - val_loss: 0.0525\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0520 - val_loss: 0.0521\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0517 - val_loss: 0.0518\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0513 - val_loss: 0.0515\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0510 - val_loss: 0.0512\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0507 - val_loss: 0.0510\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0505 - val_loss: 0.0508\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0502 - val_loss: 0.0505\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0500 - val_loss: 0.0504\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0498 - val_loss: 0.0502\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0496 - val_loss: 0.0500\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0494 - val_loss: 0.0498\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0492 - val_loss: 0.0497\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0490 - val_loss: 0.0495\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0488 - val_loss: 0.0494\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0486 - val_loss: 0.0492\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0484 - val_loss: 0.0490\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0483 - val_loss: 0.0489\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0481 - val_loss: 0.0487\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0479 - val_loss: 0.0486\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0477 - val_loss: 0.0484\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0475 - val_loss: 0.0482\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0473 - val_loss: 0.0480\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0471 - val_loss: 0.0479\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0469 - val_loss: 0.0477\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0467 - val_loss: 0.0475\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0465 - val_loss: 0.0473\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0463 - val_loss: 0.0471\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0460 - val_loss: 0.0469\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0458 - val_loss: 0.0467\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0455 - val_loss: 0.0464\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0453 - val_loss: 0.0462\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0450 - val_loss: 0.0459\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0447 - val_loss: 0.0456\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0444 - val_loss: 0.0454\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0441 - val_loss: 0.0451\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0438 - val_loss: 0.0448\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0434 - val_loss: 0.0445\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0431 - val_loss: 0.0442\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0428 - val_loss: 0.0439\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0425 - val_loss: 0.0436\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0421 - val_loss: 0.0433\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0418 - val_loss: 0.0431\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0415 - val_loss: 0.0428\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0412 - val_loss: 0.0425\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0409 - val_loss: 0.0423\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0406 - val_loss: 0.0420\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0403 - val_loss: 0.0418\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0400 - val_loss: 0.0415\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0397 - val_loss: 0.0413\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0394 - val_loss: 0.0410\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0392 - val_loss: 0.0408\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0389 - val_loss: 0.0406\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0387 - val_loss: 0.0404\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0384 - val_loss: 0.0402\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0382 - val_loss: 0.0400\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0380 - val_loss: 0.0399\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0378 - val_loss: 0.0397\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0376 - val_loss: 0.0395\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0374 - val_loss: 0.0394\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0372 - val_loss: 0.0392\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0370 - val_loss: 0.0391\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0368 - val_loss: 0.0389\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0367 - val_loss: 0.0388\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0365 - val_loss: 0.0386\n",
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0364 - val_loss: 0.0385\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0362 - val_loss: 0.0384\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0361 - val_loss: 0.0383\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0359 - val_loss: 0.0382\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0358 - val_loss: 0.0380\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0356 - val_loss: 0.0379\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0355 - val_loss: 0.0378\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0354 - val_loss: 0.0377\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 37us/step - loss: 0.0353 - val_loss: 0.0376\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0351 - val_loss: 0.0375\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0350 - val_loss: 0.0375\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0349 - val_loss: 0.0374\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0348 - val_loss: 0.0373\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0347 - val_loss: 0.0372\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0346 - val_loss: 0.0371\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0345 - val_loss: 0.0370\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0344 - val_loss: 0.0369\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 13us/step - loss: 0.0343 - val_loss: 0.0369\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0342 - val_loss: 0.0368\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0341 - val_loss: 0.0367\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0340 - val_loss: 0.0366\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0339 - val_loss: 0.0366\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 12us/step - loss: 0.0338 - val_loss: 0.0365\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0337 - val_loss: 0.0364\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0336 - val_loss: 0.0364\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0335 - val_loss: 0.0363\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0335 - val_loss: 0.0362\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 31us/step - loss: 0.0334 - val_loss: 0.0362\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0333 - val_loss: 0.0361\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0332 - val_loss: 0.0360\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 30us/step - loss: 0.0331 - val_loss: 0.0360\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0330 - val_loss: 0.0359\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0330 - val_loss: 0.0358\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0329 - val_loss: 0.0358\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 32us/step - loss: 0.0328 - val_loss: 0.0357\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0327 - val_loss: 0.0357\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0327 - val_loss: 0.0356\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 43us/step - loss: 0.0326 - val_loss: 0.0355\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0325 - val_loss: 0.0355\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0324 - val_loss: 0.0354\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0324 - val_loss: 0.0354\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0323 - val_loss: 0.0353\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0322 - val_loss: 0.0353\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0321 - val_loss: 0.0352\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0321 - val_loss: 0.0352\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0320 - val_loss: 0.0351\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0319 - val_loss: 0.0351\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0318 - val_loss: 0.0350\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0318 - val_loss: 0.0349\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0317 - val_loss: 0.0349\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0316 - val_loss: 0.0348\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0316 - val_loss: 0.0348\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0315 - val_loss: 0.0347\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0347\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0314 - val_loss: 0.0346\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0313 - val_loss: 0.0346\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0312 - val_loss: 0.0345\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0312 - val_loss: 0.0345\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0311 - val_loss: 0.0344\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0310 - val_loss: 0.0344\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0309 - val_loss: 0.0344\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0309 - val_loss: 0.0343\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0308 - val_loss: 0.0343\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 15us/step - loss: 0.0308 - val_loss: 0.0342\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0307 - val_loss: 0.0342\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0306 - val_loss: 0.0341\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0306 - val_loss: 0.0341\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 26us/step - loss: 0.0305 - val_loss: 0.0340\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0304 - val_loss: 0.0340\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0304 - val_loss: 0.0339\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0303 - val_loss: 0.0339\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0302 - val_loss: 0.0339\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0302 - val_loss: 0.0338\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0301 - val_loss: 0.0338\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0301 - val_loss: 0.0337\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0300 - val_loss: 0.0337\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0299 - val_loss: 0.0336\n",
      "Epoch 157/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0299 - val_loss: 0.0336\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0298 - val_loss: 0.0336\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 28us/step - loss: 0.0298 - val_loss: 0.0335\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 27us/step - loss: 0.0297 - val_loss: 0.0335\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0296 - val_loss: 0.0334\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0296 - val_loss: 0.0334\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0295 - val_loss: 0.0334\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0295 - val_loss: 0.0333\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0294 - val_loss: 0.0333\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0294 - val_loss: 0.0333\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0293 - val_loss: 0.0332\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0293 - val_loss: 0.0332\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0292 - val_loss: 0.0332\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0292 - val_loss: 0.0331\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0291 - val_loss: 0.0331\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0290 - val_loss: 0.0331\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0290 - val_loss: 0.0330\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0289 - val_loss: 0.0330\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0289 - val_loss: 0.0330\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0288 - val_loss: 0.0329\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 20us/step - loss: 0.0288 - val_loss: 0.0329\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 28us/step - loss: 0.0287 - val_loss: 0.0329\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 21us/step - loss: 0.0287 - val_loss: 0.0328\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0287 - val_loss: 0.0328\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0286 - val_loss: 0.0328\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0286 - val_loss: 0.0327\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0285 - val_loss: 0.0327\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 24us/step - loss: 0.0285 - val_loss: 0.0327\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0284 - val_loss: 0.0327\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 29us/step - loss: 0.0284 - val_loss: 0.0326\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0283 - val_loss: 0.0326\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 22us/step - loss: 0.0283 - val_loss: 0.0326\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0282 - val_loss: 0.0326\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0282 - val_loss: 0.0325\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 23us/step - loss: 0.0282 - val_loss: 0.0325\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 25us/step - loss: 0.0281 - val_loss: 0.0325\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 19us/step - loss: 0.0281 - val_loss: 0.0325\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 18us/step - loss: 0.0280 - val_loss: 0.0325\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0280 - val_loss: 0.0324\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0279 - val_loss: 0.0324\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 17us/step - loss: 0.0279 - val_loss: 0.0324\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 16us/step - loss: 0.0279 - val_loss: 0.0324\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0278 - val_loss: 0.0323\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 14us/step - loss: 0.0278 - val_loss: 0.0323\n"
     ]
    }
   ],
   "source": [
    "############ Denoiding Autoencoder ###########\n",
    "\n",
    "# add noise\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "ae_train = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test_noisy, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('DAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.037420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.027787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.033943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.043844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.070522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.037420\n",
       "std      0.009075\n",
       "min      0.027787\n",
       "25%      0.030289\n",
       "50%      0.033943\n",
       "75%      0.043844\n",
       "max      0.070522"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.039768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.032316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.033885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.036599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.044852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.067807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.039768\n",
       "std      0.007599\n",
       "min      0.032316\n",
       "25%      0.033885\n",
       "50%      0.036599\n",
       "75%      0.044852\n",
       "max      0.067807"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1746352"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.220984</td>\n",
       "      <td>1.940642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.684275</td>\n",
       "      <td>0.227641</td>\n",
       "      <td>2.449126</td>\n",
       "      <td>2.147067</td>\n",
       "      <td>2.170053</td>\n",
       "      <td>0.077559</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>1.757728</td>\n",
       "      <td>0.069888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.968812</td>\n",
       "      <td>3.238817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.066789</td>\n",
       "      <td>0.177035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.960600</td>\n",
       "      <td>1.780434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.018597</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.230328</td>\n",
       "      <td>2.980853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.748695</td>\n",
       "      <td>0.027787</td>\n",
       "      <td>0.283013</td>\n",
       "      <td>0.436139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651146</td>\n",
       "      <td>1.272934</td>\n",
       "      <td>1.782294</td>\n",
       "      <td>0.231273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.724967</td>\n",
       "      <td>0.982878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.447081</td>\n",
       "      <td>1.968588</td>\n",
       "      <td>1.663136</td>\n",
       "      <td>1.662016</td>\n",
       "      <td>0.366428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.738567</td>\n",
       "      <td>1.752355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.403010</td>\n",
       "      <td>0.861354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.147466</td>\n",
       "      <td>1.117492</td>\n",
       "      <td>2.956586</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.915187</td>\n",
       "      <td>0.090498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2         3         4         5         6         7   \\\n",
       "0  2.220984  1.940642  0.0  1.684275  0.227641  2.449126  2.147067  2.170053   \n",
       "1  1.968812  3.238817  0.0  3.066789  0.177035  0.000000  1.960600  1.780434   \n",
       "2  2.230328  2.980853  0.0  1.748695  0.027787  0.283013  0.436139  0.000000   \n",
       "3  0.724967  0.982878  0.0  2.447081  1.968588  1.663136  1.662016  0.366428   \n",
       "4  2.403010  0.861354  0.0  2.147466  1.117492  2.956586  0.906854  0.000000   \n",
       "\n",
       "         8         9         10        11  \n",
       "0  0.077559  0.763158  1.757728  0.069888  \n",
       "1  0.000000  0.000000  2.018597  0.000000  \n",
       "2  0.651146  1.272934  1.782294  0.231273  \n",
       "3  0.000000  2.738567  1.752355  0.000000  \n",
       "4  0.995451  0.000000  2.915187  0.090498  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2.219769</td>\n",
       "      <td>1.950292</td>\n",
       "      <td>1.690442</td>\n",
       "      <td>0.237050</td>\n",
       "      <td>2.436228</td>\n",
       "      <td>2.159743</td>\n",
       "      <td>2.174981</td>\n",
       "      <td>0.071580</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>1.758039</td>\n",
       "      <td>0.071856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.522994</td>\n",
       "      <td>2.516430</td>\n",
       "      <td>2.984616</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>1.243248</td>\n",
       "      <td>1.594074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.151968</td>\n",
       "      <td>0.118128</td>\n",
       "      <td>0.544539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.757012</td>\n",
       "      <td>2.006558</td>\n",
       "      <td>1.151283</td>\n",
       "      <td>0.379375</td>\n",
       "      <td>0.731454</td>\n",
       "      <td>1.155770</td>\n",
       "      <td>2.568758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228847</td>\n",
       "      <td>2.802526</td>\n",
       "      <td>1.681634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2.416167</td>\n",
       "      <td>0.865532</td>\n",
       "      <td>2.142457</td>\n",
       "      <td>1.115771</td>\n",
       "      <td>2.990214</td>\n",
       "      <td>0.908190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.889506</td>\n",
       "      <td>0.093890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1.023318</td>\n",
       "      <td>1.953173</td>\n",
       "      <td>1.978827</td>\n",
       "      <td>0.274079</td>\n",
       "      <td>0.919832</td>\n",
       "      <td>1.057205</td>\n",
       "      <td>0.241212</td>\n",
       "      <td>2.710854</td>\n",
       "      <td>0.673560</td>\n",
       "      <td>0.669287</td>\n",
       "      <td>2.101536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "405  2.219769  1.950292  1.690442  0.237050  2.436228  2.159743  2.174981   \n",
       "406  1.522994  2.516430  2.984616  0.584416  1.243248  1.594074  0.000000   \n",
       "407  1.757012  2.006558  1.151283  0.379375  0.731454  1.155770  2.568758   \n",
       "408  2.416167  0.865532  2.142457  1.115771  2.990214  0.908190  0.000000   \n",
       "409  1.023318  1.953173  1.978827  0.274079  0.919832  1.057205  0.241212   \n",
       "\n",
       "           7         8         9         10  \n",
       "405  0.071580  0.754923  1.758039  0.071856  \n",
       "406  0.000000  2.151968  0.118128  0.544539  \n",
       "407  0.000000  0.228847  2.802526  1.681634  \n",
       "408  1.003806  0.000000  2.889506  0.093890  \n",
       "409  2.710854  0.673560  0.669287  2.101536  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./dim064_DAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# tranform the input format, add a dimension\n",
    "x_train_con = x_train.as_matrix()\n",
    "x_train_con = np.reshape(x_train_con, (-1, input_dim, 1))\n",
    "x_text_con = x_test.as_matrix()\n",
    "x_text_con = np.reshape(x_text_con, (-1, input_dim, 1))\n",
    "\n",
    "input_layer = Input(shape=(input_dim,1))\n",
    "\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling1D(4, padding='same')(x)\n",
    "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D(4, padding='same')(x)\n",
    "x = Conv1D(4, 3, activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling1D(2, padding='same')(x)\n",
    "\n",
    "\n",
    "x = Conv1D(4, 3, activation='relu', padding='same')(encoded)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling1D(4)(x)\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling1D(4)(x)\n",
    "decoded = Conv1D(1, 1, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        (None, 64, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_306 (Conv1D)          (None, 64, 32)            128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_307 (Conv1D)          (None, 16, 16)            1552      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_308 (Conv1D)          (None, 4, 4)              196       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 2, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_309 (Conv1D)          (None, 2, 4)              52        \n",
      "_________________________________________________________________\n",
      "up_sampling1d_130 (UpSamplin (None, 4, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_310 (Conv1D)          (None, 4, 16)             208       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_131 (UpSamplin (None, 16, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_311 (Conv1D)          (None, 16, 32)            1568      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_132 (UpSamplin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_312 (Conv1D)          (None, 64, 1)             33        \n",
      "=================================================================\n",
      "Total params: 3,737\n",
      "Trainable params: 3,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 410 samples\n",
      "Epoch 1/200\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 0.0578 - val_loss: 0.0573\n",
      "Epoch 2/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0565 - val_loss: 0.0560\n",
      "Epoch 3/200\n",
      "614/614 [==============================] - 0s 124us/step - loss: 0.0554 - val_loss: 0.0557\n",
      "Epoch 4/200\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.0554 - val_loss: 0.0557\n",
      "Epoch 5/200\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.0551 - val_loss: 0.0554\n",
      "Epoch 6/200\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.0550 - val_loss: 0.0554\n",
      "Epoch 7/200\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.0550 - val_loss: 0.0553\n",
      "Epoch 8/200\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.0549 - val_loss: 0.0552\n",
      "Epoch 9/200\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.0548 - val_loss: 0.0552\n",
      "Epoch 10/200\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.0547 - val_loss: 0.0551\n",
      "Epoch 11/200\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.0547 - val_loss: 0.0550\n",
      "Epoch 12/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0546 - val_loss: 0.0549\n",
      "Epoch 13/200\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.0545 - val_loss: 0.0548\n",
      "Epoch 14/200\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.0544 - val_loss: 0.0547\n",
      "Epoch 15/200\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.0543 - val_loss: 0.0546\n",
      "Epoch 16/200\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.0542 - val_loss: 0.0545\n",
      "Epoch 17/200\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.0541 - val_loss: 0.0544\n",
      "Epoch 18/200\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.0540 - val_loss: 0.0543\n",
      "Epoch 19/200\n",
      "614/614 [==============================] - 0s 136us/step - loss: 0.0539 - val_loss: 0.0542\n",
      "Epoch 20/200\n",
      "614/614 [==============================] - 0s 136us/step - loss: 0.0538 - val_loss: 0.0541\n",
      "Epoch 21/200\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.0537 - val_loss: 0.0540\n",
      "Epoch 22/200\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.0536 - val_loss: 0.0538\n",
      "Epoch 23/200\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.0534 - val_loss: 0.0537\n",
      "Epoch 24/200\n",
      "614/614 [==============================] - 0s 124us/step - loss: 0.0533 - val_loss: 0.0536\n",
      "Epoch 25/200\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.0532 - val_loss: 0.0535\n",
      "Epoch 26/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0531 - val_loss: 0.0534\n",
      "Epoch 27/200\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.0530 - val_loss: 0.0532\n",
      "Epoch 28/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0528 - val_loss: 0.0531\n",
      "Epoch 29/200\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.0527 - val_loss: 0.0529\n",
      "Epoch 30/200\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.0525 - val_loss: 0.0527\n",
      "Epoch 31/200\n",
      "614/614 [==============================] - 0s 147us/step - loss: 0.0523 - val_loss: 0.0525\n",
      "Epoch 32/200\n",
      "614/614 [==============================] - 0s 129us/step - loss: 0.0521 - val_loss: 0.0524\n",
      "Epoch 33/200\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.0519 - val_loss: 0.0522\n",
      "Epoch 34/200\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.0517 - val_loss: 0.0521\n",
      "Epoch 35/200\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.0515 - val_loss: 0.0520\n",
      "Epoch 36/200\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.0514 - val_loss: 0.0519\n",
      "Epoch 37/200\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.0513 - val_loss: 0.0518\n",
      "Epoch 38/200\n",
      "614/614 [==============================] - 0s 152us/step - loss: 0.0512 - val_loss: 0.0517\n",
      "Epoch 39/200\n",
      "614/614 [==============================] - 0s 195us/step - loss: 0.0512 - val_loss: 0.0516\n",
      "Epoch 40/200\n",
      "614/614 [==============================] - 0s 155us/step - loss: 0.0511 - val_loss: 0.0516\n",
      "Epoch 41/200\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.0510 - val_loss: 0.0515\n",
      "Epoch 42/200\n",
      "614/614 [==============================] - 0s 176us/step - loss: 0.0509 - val_loss: 0.0514\n",
      "Epoch 43/200\n",
      "614/614 [==============================] - 0s 148us/step - loss: 0.0509 - val_loss: 0.0513\n",
      "Epoch 44/200\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.0508 - val_loss: 0.0513\n",
      "Epoch 45/200\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.0507 - val_loss: 0.0512\n",
      "Epoch 46/200\n",
      "614/614 [==============================] - 0s 182us/step - loss: 0.0506 - val_loss: 0.0511\n",
      "Epoch 47/200\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.0506 - val_loss: 0.0510\n",
      "Epoch 48/200\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.0505 - val_loss: 0.0510\n",
      "Epoch 49/200\n",
      "614/614 [==============================] - 0s 155us/step - loss: 0.0504 - val_loss: 0.0509\n",
      "Epoch 50/200\n",
      "614/614 [==============================] - 0s 152us/step - loss: 0.0503 - val_loss: 0.0508\n",
      "Epoch 51/200\n",
      "614/614 [==============================] - 0s 165us/step - loss: 0.0502 - val_loss: 0.0507\n",
      "Epoch 52/200\n",
      "614/614 [==============================] - 0s 148us/step - loss: 0.0501 - val_loss: 0.0506\n",
      "Epoch 53/200\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.0500 - val_loss: 0.0504\n",
      "Epoch 54/200\n",
      "614/614 [==============================] - 0s 172us/step - loss: 0.0499 - val_loss: 0.0503\n",
      "Epoch 55/200\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.0497 - val_loss: 0.0502\n",
      "Epoch 56/200\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.0496 - val_loss: 0.0501\n",
      "Epoch 57/200\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.0495 - val_loss: 0.0499\n",
      "Epoch 58/200\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.0493 - val_loss: 0.0498\n",
      "Epoch 59/200\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.0492 - val_loss: 0.0496\n",
      "Epoch 60/200\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.0490 - val_loss: 0.0495\n",
      "Epoch 61/200\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.0489 - val_loss: 0.0494\n",
      "Epoch 62/200\n",
      "614/614 [==============================] - 0s 205us/step - loss: 0.0488 - val_loss: 0.0492\n",
      "Epoch 63/200\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.0486 - val_loss: 0.0491\n",
      "Epoch 64/200\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.0485 - val_loss: 0.0490\n",
      "Epoch 65/200\n",
      "614/614 [==============================] - 0s 197us/step - loss: 0.0484 - val_loss: 0.0489\n",
      "Epoch 66/200\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.0483 - val_loss: 0.0488\n",
      "Epoch 67/200\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.0482 - val_loss: 0.0487\n",
      "Epoch 68/200\n",
      "614/614 [==============================] - 0s 155us/step - loss: 0.0481 - val_loss: 0.0486\n",
      "Epoch 69/200\n",
      "614/614 [==============================] - 0s 185us/step - loss: 0.0479 - val_loss: 0.0485\n",
      "Epoch 70/200\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.0478 - val_loss: 0.0484\n",
      "Epoch 71/200\n",
      "614/614 [==============================] - 0s 182us/step - loss: 0.0477 - val_loss: 0.0483\n",
      "Epoch 72/200\n",
      "614/614 [==============================] - 0s 147us/step - loss: 0.0476 - val_loss: 0.0482\n",
      "Epoch 73/200\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.0476 - val_loss: 0.0481\n",
      "Epoch 74/200\n",
      "614/614 [==============================] - 0s 126us/step - loss: 0.0475 - val_loss: 0.0480\n",
      "Epoch 75/200\n",
      "614/614 [==============================] - 0s 144us/step - loss: 0.0474 - val_loss: 0.0479\n",
      "Epoch 76/200\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.0473 - val_loss: 0.0479\n",
      "Epoch 77/200\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.0473 - val_loss: 0.0478\n",
      "Epoch 78/200\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.0472 - val_loss: 0.0477\n",
      "Epoch 79/200\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.0471 - val_loss: 0.0477\n",
      "Epoch 80/200\n",
      "614/614 [==============================] - 0s 148us/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 81/200\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.0470 - val_loss: 0.0475\n",
      "Epoch 82/200\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.0469 - val_loss: 0.0475\n",
      "Epoch 83/200\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.0468 - val_loss: 0.0474\n",
      "Epoch 84/200\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.0468 - val_loss: 0.0473\n",
      "Epoch 85/200\n",
      "614/614 [==============================] - 0s 201us/step - loss: 0.0467 - val_loss: 0.0473\n",
      "Epoch 86/200\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.0467 - val_loss: 0.0472\n",
      "Epoch 87/200\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 88/200\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.0465 - val_loss: 0.0471\n",
      "Epoch 89/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0465 - val_loss: 0.0471\n",
      "Epoch 90/200\n",
      "614/614 [==============================] - 0s 122us/step - loss: 0.0464 - val_loss: 0.0470\n",
      "Epoch 91/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0464 - val_loss: 0.0470\n",
      "Epoch 92/200\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 93/200\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 94/200\n",
      "614/614 [==============================] - 0s 172us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 95/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 96/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 97/200\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.0461 - val_loss: 0.0467\n",
      "Epoch 98/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0460 - val_loss: 0.0466\n",
      "Epoch 99/200\n",
      "614/614 [==============================] - 0s 116us/step - loss: 0.0460 - val_loss: 0.0466\n",
      "Epoch 100/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0460 - val_loss: 0.0465\n",
      "Epoch 101/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0459 - val_loss: 0.0465\n",
      "Epoch 102/200\n",
      "614/614 [==============================] - 0s 122us/step - loss: 0.0459 - val_loss: 0.0464\n",
      "Epoch 103/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0458 - val_loss: 0.0464\n",
      "Epoch 104/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0458 - val_loss: 0.0464\n",
      "Epoch 105/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0458 - val_loss: 0.0463\n",
      "Epoch 106/200\n",
      "614/614 [==============================] - 0s 116us/step - loss: 0.0457 - val_loss: 0.0463\n",
      "Epoch 107/200\n",
      "614/614 [==============================] - 0s 120us/step - loss: 0.0457 - val_loss: 0.0463\n",
      "Epoch 108/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0456 - val_loss: 0.0462\n",
      "Epoch 109/200\n",
      "614/614 [==============================] - 0s 122us/step - loss: 0.0456 - val_loss: 0.0462\n",
      "Epoch 110/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0456 - val_loss: 0.0462\n",
      "Epoch 111/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0456 - val_loss: 0.0461\n",
      "Epoch 112/200\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.0455 - val_loss: 0.0461\n",
      "Epoch 113/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0455 - val_loss: 0.0461\n",
      "Epoch 114/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0455 - val_loss: 0.0461\n",
      "Epoch 115/200\n",
      "614/614 [==============================] - 0s 176us/step - loss: 0.0455 - val_loss: 0.0460\n",
      "Epoch 116/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0454 - val_loss: 0.0460\n",
      "Epoch 117/200\n",
      "614/614 [==============================] - 0s 124us/step - loss: 0.0454 - val_loss: 0.0460\n",
      "Epoch 118/200\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.0454 - val_loss: 0.0461\n",
      "Epoch 119/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0454 - val_loss: 0.0459\n",
      "Epoch 120/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0453 - val_loss: 0.0459\n",
      "Epoch 121/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0453 - val_loss: 0.0459\n",
      "Epoch 122/200\n",
      "614/614 [==============================] - 0s 116us/step - loss: 0.0453 - val_loss: 0.0459\n",
      "Epoch 123/200\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.0453 - val_loss: 0.0459\n",
      "Epoch 124/200\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.0452 - val_loss: 0.0458\n",
      "Epoch 125/200\n",
      "614/614 [==============================] - 0s 155us/step - loss: 0.0452 - val_loss: 0.0458\n",
      "Epoch 126/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0452 - val_loss: 0.0458\n",
      "Epoch 127/200\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.0452 - val_loss: 0.0458\n",
      "Epoch 128/200\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.0452 - val_loss: 0.0458\n",
      "Epoch 129/200\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.0452 - val_loss: 0.0458\n",
      "Epoch 130/200\n",
      "614/614 [==============================] - 0s 124us/step - loss: 0.0452 - val_loss: 0.0457\n",
      "Epoch 131/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0451 - val_loss: 0.0458\n",
      "Epoch 132/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0451 - val_loss: 0.0457\n",
      "Epoch 133/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0451 - val_loss: 0.0457\n",
      "Epoch 134/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0451 - val_loss: 0.0457\n",
      "Epoch 135/200\n",
      "614/614 [==============================] - 0s 111us/step - loss: 0.0451 - val_loss: 0.0456\n",
      "Epoch 136/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0451 - val_loss: 0.0457\n",
      "Epoch 137/200\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 138/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 139/200\n",
      "614/614 [==============================] - 0s 120us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 140/200\n",
      "614/614 [==============================] - 0s 116us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 141/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 142/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 143/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 144/200\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 145/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0450 - val_loss: 0.0455\n",
      "Epoch 146/200\n",
      "614/614 [==============================] - 0s 123us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 147/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 148/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 149/200\n",
      "614/614 [==============================] - 0s 120us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 150/200\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 151/200\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 152/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 153/200\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 154/200\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 155/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 156/200\n",
      "614/614 [==============================] - 0s 116us/step - loss: 0.0449 - val_loss: 0.0454\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 125us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 158/200\n",
      "614/614 [==============================] - 0s 116us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 159/200\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 160/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 161/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0448 - val_loss: 0.0455\n",
      "Epoch 162/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 163/200\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 164/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 165/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 166/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 167/200\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 168/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 169/200\n",
      "614/614 [==============================] - 0s 108us/step - loss: 0.0448 - val_loss: 0.0454\n",
      "Epoch 170/200\n",
      "614/614 [==============================] - 0s 111us/step - loss: 0.0448 - val_loss: 0.0453\n",
      "Epoch 171/200\n",
      "614/614 [==============================] - 0s 120us/step - loss: 0.0448 - val_loss: 0.0453\n",
      "Epoch 172/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0448 - val_loss: 0.0453\n",
      "Epoch 173/200\n",
      "614/614 [==============================] - 0s 111us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 174/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 175/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 176/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 177/200\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 178/200\n",
      "614/614 [==============================] - 0s 120us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 179/200\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 180/200\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 181/200\n",
      "614/614 [==============================] - 0s 111us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 182/200\n",
      "614/614 [==============================] - 0s 111us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 183/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 184/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 185/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 186/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 187/200\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 188/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 189/200\n",
      "614/614 [==============================] - 0s 124us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 190/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 191/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 192/200\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 193/200\n",
      "614/614 [==============================] - 0s 120us/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 194/200\n",
      "614/614 [==============================] - 0s 113us/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 195/200\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 196/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0447 - val_loss: 0.0453\n",
      "Epoch 197/200\n",
      "614/614 [==============================] - 0s 118us/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 198/200\n",
      "614/614 [==============================] - 0s 119us/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 199/200\n",
      "614/614 [==============================] - 0s 111us/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 200/200\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.0446 - val_loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "ae_train = autoencoder.fit(x_train_con, x_train_con,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_text_con, x_text_con),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Con_AE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('Conv_AE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.047674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.044647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.044894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.045932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.050242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.057788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.047674\n",
       "std      0.003464\n",
       "min      0.044647\n",
       "25%      0.044894\n",
       "50%      0.045932\n",
       "75%      0.050242\n",
       "max      0.057788"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.045225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.045482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.050706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.057305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.048182\n",
       "std      0.003342\n",
       "min      0.045225\n",
       "25%      0.045482\n",
       "50%      0.046512\n",
       "75%      0.050706\n",
       "max      0.057305"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder.predict(x_text_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 2, 4)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "\n",
    "encoded_data = encoded_data.reshape(-1, 2*4)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3529571"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.619695</td>\n",
       "      <td>3.798434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.843804</td>\n",
       "      <td>0.339530</td>\n",
       "      <td>2.324364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.212742</td>\n",
       "      <td>2.632632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.092621</td>\n",
       "      <td>0.685427</td>\n",
       "      <td>3.347438</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>1.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040923</td>\n",
       "      <td>2.643014</td>\n",
       "      <td>0.353879</td>\n",
       "      <td>0.381635</td>\n",
       "      <td>0.512060</td>\n",
       "      <td>1.497391</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>1.597433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986684</td>\n",
       "      <td>4.391051</td>\n",
       "      <td>0.170206</td>\n",
       "      <td>0.582877</td>\n",
       "      <td>0.511271</td>\n",
       "      <td>1.523611</td>\n",
       "      <td>0.661759</td>\n",
       "      <td>2.568826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.049106</td>\n",
       "      <td>3.626737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.891596</td>\n",
       "      <td>0.866574</td>\n",
       "      <td>2.053646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.619695  3.798434  0.000000  0.974055  0.000000  1.843804  0.339530   \n",
       "1  1.212742  2.632632  0.000000  1.092621  0.685427  3.347438  0.280657   \n",
       "2  0.040923  2.643014  0.353879  0.381635  0.512060  1.497391  0.118033   \n",
       "3  0.986684  4.391051  0.170206  0.582877  0.511271  1.523611  0.661759   \n",
       "4  1.049106  3.626737  0.000000  1.891596  0.866574  2.053646  0.000000   \n",
       "\n",
       "          7  \n",
       "0  2.324364  \n",
       "1  1.907474  \n",
       "2  1.597433  \n",
       "3  2.568826  \n",
       "4  1.282843  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.636510</td>\n",
       "      <td>3.797700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.834277</td>\n",
       "      <td>0.326925</td>\n",
       "      <td>2.319141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.305329</td>\n",
       "      <td>3.746118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.691917</td>\n",
       "      <td>0.378015</td>\n",
       "      <td>1.846060</td>\n",
       "      <td>0.601684</td>\n",
       "      <td>1.798794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.097444</td>\n",
       "      <td>2.695361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.129987</td>\n",
       "      <td>0.449520</td>\n",
       "      <td>2.808614</td>\n",
       "      <td>0.646239</td>\n",
       "      <td>2.579397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.050361</td>\n",
       "      <td>3.620308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.931498</td>\n",
       "      <td>0.849957</td>\n",
       "      <td>2.073496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.274005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.819094</td>\n",
       "      <td>2.803680</td>\n",
       "      <td>0.293457</td>\n",
       "      <td>1.181901</td>\n",
       "      <td>1.253280</td>\n",
       "      <td>2.726597</td>\n",
       "      <td>0.619012</td>\n",
       "      <td>1.926305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "405  1.636510  3.797700  0.000000  0.977368  0.000000  1.834277  0.326925   \n",
       "406  0.305329  3.746118  0.000000  0.691917  0.378015  1.846060  0.601684   \n",
       "407  1.097444  2.695361  0.000000  1.129987  0.449520  2.808614  0.646239   \n",
       "408  1.050361  3.620308  0.000000  1.931498  0.849957  2.073496  0.000000   \n",
       "409  0.819094  2.803680  0.293457  1.181901  1.253280  2.726597  0.619012   \n",
       "\n",
       "            7  \n",
       "405  2.319141  \n",
       "406  1.798794  \n",
       "407  2.579397  \n",
       "408  1.274005  \n",
       "409  1.926305  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./dim064_ConAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
