{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for Satellite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model,load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "x_train = pd.read_csv('./dataset/sat_train.csv')\n",
    "x_test = pd.read_csv('./dataset/sat_test.csv')\n",
    "y_train = pd.read_csv('./dataset/sat_train_label.csv')\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = pd.read_csv('./dataset/sat_test_label.csv')\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "#x_train.max().max()\n",
    "x_train = x_train.astype('float32') / 157.\n",
    "x_test = x_test.astype('float32') / 157."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [3],\n",
       "       [4],\n",
       "       ...,\n",
       "       [5],\n",
       "       [5],\n",
       "       [5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Basic Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 8\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 296       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 36)                324       \n",
      "=================================================================\n",
      "Total params: 620\n",
      "Trainable params: 620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4435 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "4435/4435 [==============================] - 0s 70us/step - loss: 0.0234 - val_loss: 0.0180\n",
      "Epoch 2/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0152\n",
      "Epoch 3/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0137\n",
      "Epoch 4/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 5/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 6/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 7/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 8/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 9/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 10/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 11/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 12/200\n",
      "4435/4435 [==============================] - 0s 24us/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 13/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 14/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 15/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 16/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 17/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 18/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 19/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 20/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 21/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 22/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 23/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 24/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 25/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 26/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 27/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 28/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 29/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 30/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 31/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 32/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 33/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 34/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 35/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 36/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 37/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 38/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 39/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 40/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 41/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 42/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 43/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 44/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 45/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 46/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 47/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 48/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 49/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 50/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 51/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 52/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 53/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 54/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 55/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 56/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 57/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 58/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 59/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 60/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 61/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 62/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 63/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 64/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 65/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 66/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 67/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 68/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 69/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 70/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 71/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 72/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 73/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 74/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 77/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 78/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 80/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 81/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 82/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 83/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 84/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 85/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 86/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 87/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 88/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 89/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 90/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 91/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 92/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 93/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 94/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 95/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 96/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 97/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 98/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 99/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 100/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 101/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 102/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 103/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 104/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 105/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 106/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 107/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 108/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 109/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 110/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 111/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 112/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 113/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 114/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 115/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 116/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 117/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 118/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 119/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 120/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 121/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 122/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 123/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 124/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 125/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 126/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 127/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 128/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 129/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 130/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 131/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 132/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 133/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 134/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 135/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 136/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 137/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 138/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 139/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 140/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 141/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 142/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 143/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 144/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 145/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 146/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 147/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 148/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 149/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 150/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 151/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 152/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 153/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 154/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 155/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 156/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 158/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 159/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 160/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 161/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 162/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 163/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 164/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 165/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 166/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 167/200\n",
      "4435/4435 [==============================] - 0s 24us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 168/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 169/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 170/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 171/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 172/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 173/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 174/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 175/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 176/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 177/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 178/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 179/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 180/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 181/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 182/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 183/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 185/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 186/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 187/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 189/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 190/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 191/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 192/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 193/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 194/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 195/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 196/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 197/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 198/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 199/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 200/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('AE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.023419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.003521\n",
       "std      0.003034\n",
       "min      0.001324\n",
       "25%      0.001771\n",
       "50%      0.002453\n",
       "75%      0.003736\n",
       "max      0.023419"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.018006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.003318\n",
       "std      0.002725\n",
       "min      0.001257\n",
       "25%      0.001755\n",
       "50%      0.002448\n",
       "75%      0.003252\n",
       "max      0.018006"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214918</td>\n",
       "      <td>1.129380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101194</td>\n",
       "      <td>0.461256</td>\n",
       "      <td>0.634595</td>\n",
       "      <td>0.672134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172555</td>\n",
       "      <td>1.152339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.105224</td>\n",
       "      <td>0.462174</td>\n",
       "      <td>0.636067</td>\n",
       "      <td>0.666911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157411</td>\n",
       "      <td>0.900301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911588</td>\n",
       "      <td>0.407731</td>\n",
       "      <td>0.445517</td>\n",
       "      <td>0.521917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213926</td>\n",
       "      <td>0.872880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.846269</td>\n",
       "      <td>0.464452</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>0.478968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216366</td>\n",
       "      <td>0.849333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.837768</td>\n",
       "      <td>0.421976</td>\n",
       "      <td>0.396192</td>\n",
       "      <td>0.498435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2    3         4         5         6         7\n",
       "0  0.0  0.214918  1.129380  0.0  1.101194  0.461256  0.634595  0.672134\n",
       "1  0.0  0.172555  1.152339  0.0  1.105224  0.462174  0.636067  0.666911\n",
       "2  0.0  0.157411  0.900301  0.0  0.911588  0.407731  0.445517  0.521917\n",
       "3  0.0  0.213926  0.872880  0.0  0.846269  0.464452  0.415377  0.478968\n",
       "4  0.0  0.216366  0.849333  0.0  0.837768  0.421976  0.396192  0.498435"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45587128"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.553358</td>\n",
       "      <td>0.729503</td>\n",
       "      <td>0.187408</td>\n",
       "      <td>0.789887</td>\n",
       "      <td>0.188233</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.869085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.593841</td>\n",
       "      <td>0.550664</td>\n",
       "      <td>0.326164</td>\n",
       "      <td>0.612031</td>\n",
       "      <td>0.051632</td>\n",
       "      <td>0.624883</td>\n",
       "      <td>0.868620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.523561</td>\n",
       "      <td>0.510507</td>\n",
       "      <td>0.259064</td>\n",
       "      <td>0.587196</td>\n",
       "      <td>0.044986</td>\n",
       "      <td>0.500826</td>\n",
       "      <td>0.733869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.557289</td>\n",
       "      <td>0.642132</td>\n",
       "      <td>0.249553</td>\n",
       "      <td>0.570662</td>\n",
       "      <td>0.205687</td>\n",
       "      <td>0.586527</td>\n",
       "      <td>0.683223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.780255</td>\n",
       "      <td>0.658296</td>\n",
       "      <td>0.403594</td>\n",
       "      <td>0.533067</td>\n",
       "      <td>0.091198</td>\n",
       "      <td>0.720527</td>\n",
       "      <td>0.865444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6\n",
       "1995  0.553358  0.729503  0.187408  0.789887  0.188233  0.753118  0.869085\n",
       "1996  0.593841  0.550664  0.326164  0.612031  0.051632  0.624883  0.868620\n",
       "1997  0.523561  0.510507  0.259064  0.587196  0.044986  0.500826  0.733869\n",
       "1998  0.557289  0.642132  0.249553  0.570662  0.205687  0.586527  0.683223\n",
       "1999  0.780255  0.658296  0.403594  0.533067  0.091198  0.720527  0.865444"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./sat_AE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4435 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "4435/4435 [==============================] - 0s 92us/step - loss: 0.0229 - val_loss: 0.0181\n",
      "Epoch 2/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0167 - val_loss: 0.0157\n",
      "Epoch 3/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0150 - val_loss: 0.0142\n",
      "Epoch 4/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 5/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 6/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 7/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 8/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 9/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 10/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 11/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 12/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 13/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 14/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 15/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 16/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 17/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 19/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 20/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 21/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 22/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 23/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 24/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 25/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 26/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 27/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 28/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 29/200\n",
      "4435/4435 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 30/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 31/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 32/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 33/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 34/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 35/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 36/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 37/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 38/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 39/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 40/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 41/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 42/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 43/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 44/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 45/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 46/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 47/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 48/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 49/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 50/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 51/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 52/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 53/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 54/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 55/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 56/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 57/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 58/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 59/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 60/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 61/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 62/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 63/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 64/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 65/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 66/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 67/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 68/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 69/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 70/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 71/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 72/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 73/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 74/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 75/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 76/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 77/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 78/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 80/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 81/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 82/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 83/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 84/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 85/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 86/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 87/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 88/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 89/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 90/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 91/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 92/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 93/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 94/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 95/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 96/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 97/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 98/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 99/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 100/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 101/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 102/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 103/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 104/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 105/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 106/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 107/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 108/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 109/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 110/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 111/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 112/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 113/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 114/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 115/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 116/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 117/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 118/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 119/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 120/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 121/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 122/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 123/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 124/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 125/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 126/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 127/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 128/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 129/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 130/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 131/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 132/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 133/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 134/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 135/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 136/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 137/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 138/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 139/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 140/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 141/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 142/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 143/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 144/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 145/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 146/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 147/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 148/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 149/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 150/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 151/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 152/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 153/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 154/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 155/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 156/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 158/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 159/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 160/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 161/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 162/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 163/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 164/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 165/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 166/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 167/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 168/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 169/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 170/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 171/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 172/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 173/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 174/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 175/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 176/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 177/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 178/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 179/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 180/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 181/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 182/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 183/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 185/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 186/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 187/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 188/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 189/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 190/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 191/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 192/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 193/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 194/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 195/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 196/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 197/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 198/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 199/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 200/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "########### Sparse Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-7))(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('SAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.022888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.003582\n",
       "std      0.002855\n",
       "min      0.001233\n",
       "25%      0.001906\n",
       "50%      0.002734\n",
       "75%      0.004051\n",
       "max      0.022888"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.018135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.003452\n",
       "std      0.002512\n",
       "min      0.001200\n",
       "25%      0.001953\n",
       "50%      0.002837\n",
       "75%      0.003875\n",
       "max      0.018135"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19548284"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.442497</td>\n",
       "      <td>0.151610</td>\n",
       "      <td>0.206632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218555</td>\n",
       "      <td>0.279418</td>\n",
       "      <td>0.442487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.495470</td>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.450411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.355215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273261</td>\n",
       "      <td>0.306045</td>\n",
       "      <td>0.355911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276200</td>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291826</td>\n",
       "      <td>0.229986</td>\n",
       "      <td>0.348940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262522</td>\n",
       "      <td>0.021445</td>\n",
       "      <td>0.171532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271645</td>\n",
       "      <td>0.203328</td>\n",
       "      <td>0.341682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3    4         5         6         7    8   \\\n",
       "0  0.442497  0.151610  0.206632  0.0  0.0  0.218555  0.279418  0.442487  0.0   \n",
       "1  0.495470  0.086018  0.175026  0.0  0.0  0.154667  0.331902  0.450411  0.0   \n",
       "2  0.355215  0.000000  0.147549  0.0  0.0  0.273261  0.306045  0.355911  0.0   \n",
       "3  0.276200  0.010565  0.176352  0.0  0.0  0.291826  0.229986  0.348940  0.0   \n",
       "4  0.262522  0.021445  0.171532  0.0  0.0  0.271645  0.203328  0.341682  0.0   \n",
       "\n",
       "         9    10        11  \n",
       "0  0.872129  0.0  0.000000  \n",
       "1  0.889451  0.0  0.000000  \n",
       "2  0.748749  0.0  0.017409  \n",
       "3  0.718656  0.0  0.042865  \n",
       "4  0.697918  0.0  0.080053  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.406194</td>\n",
       "      <td>0.205906</td>\n",
       "      <td>0.103922</td>\n",
       "      <td>0.364590</td>\n",
       "      <td>0.160046</td>\n",
       "      <td>0.620461</td>\n",
       "      <td>0.067357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.379159</td>\n",
       "      <td>0.356151</td>\n",
       "      <td>0.280715</td>\n",
       "      <td>0.163460</td>\n",
       "      <td>0.374971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471289</td>\n",
       "      <td>0.182745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.360583</td>\n",
       "      <td>0.289250</td>\n",
       "      <td>0.348469</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433544</td>\n",
       "      <td>0.204931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.194437</td>\n",
       "      <td>0.279660</td>\n",
       "      <td>0.278754</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>0.329406</td>\n",
       "      <td>0.080450</td>\n",
       "      <td>0.413424</td>\n",
       "      <td>0.176662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.256853</td>\n",
       "      <td>0.421904</td>\n",
       "      <td>0.300119</td>\n",
       "      <td>0.057415</td>\n",
       "      <td>0.418423</td>\n",
       "      <td>0.039746</td>\n",
       "      <td>0.415670</td>\n",
       "      <td>0.202156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1995  0.387692  0.406194  0.205906  0.103922  0.364590  0.160046  0.620461   \n",
       "1996  0.379159  0.356151  0.280715  0.163460  0.374971  0.000000  0.471289   \n",
       "1997  0.360583  0.289250  0.348469  0.133371  0.218664  0.000000  0.433544   \n",
       "1998  0.194437  0.279660  0.278754  0.034335  0.329406  0.080450  0.413424   \n",
       "1999  0.256853  0.421904  0.300119  0.057415  0.418423  0.039746  0.415670   \n",
       "\n",
       "             7  \n",
       "1995  0.067357  \n",
       "1996  0.182745  \n",
       "1997  0.204931  \n",
       "1998  0.176662  \n",
       "1999  0.202156  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./sat_SAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contractive Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4435 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "4435/4435 [==============================] - 1s 164us/step - loss: 0.0213 - val_loss: 0.0182\n",
      "Epoch 2/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0173 - val_loss: 0.0167\n",
      "Epoch 3/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0161 - val_loss: 0.0158\n",
      "Epoch 4/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 5/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 6/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0134\n",
      "Epoch 7/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 8/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 9/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 10/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 11/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 12/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 13/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 14/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 15/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 16/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 17/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 18/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 19/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 20/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 21/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 22/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 23/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 24/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 25/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 26/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 27/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 28/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 29/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 30/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 31/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 32/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 33/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 34/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 35/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 36/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 37/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 38/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 39/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 40/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 41/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 42/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 43/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 44/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 45/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 46/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 47/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 48/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 49/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 50/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 51/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 52/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 53/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 54/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 55/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 56/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 57/200\n",
      "4435/4435 [==============================] - 0s 26us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 58/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 59/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 60/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 61/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 62/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 63/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 64/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 65/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 66/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 67/200\n",
      "4435/4435 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 68/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 69/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 70/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 71/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 72/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 73/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 74/200\n",
      "4435/4435 [==============================] - 0s 18us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 75/200\n",
      "4435/4435 [==============================] - 0s 18us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 76/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 77/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 78/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 79/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 80/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 81/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 82/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 83/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 84/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 85/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 86/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 87/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 88/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 89/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 90/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 91/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 92/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 93/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 94/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 95/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 96/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 97/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 98/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 99/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 100/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 101/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 102/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 103/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 104/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 105/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 106/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 107/200\n",
      "4435/4435 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 108/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 109/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 110/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 111/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 112/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 113/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 114/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 115/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 116/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 117/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 118/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 119/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 120/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 121/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 122/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 123/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 124/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 125/200\n",
      "4435/4435 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 126/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 127/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 128/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 129/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 130/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 131/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 132/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 133/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 134/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 135/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 136/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 137/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 138/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 139/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 140/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 141/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 142/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 143/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 144/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 145/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 146/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 147/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 148/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 149/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 150/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 151/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 152/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 153/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 154/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 156/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 157/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 158/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 159/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 160/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 161/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 162/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 163/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 164/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 165/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 166/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 167/200\n",
      "4435/4435 [==============================] - 0s 18us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 168/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 169/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 170/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 171/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 172/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 173/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 174/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 175/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 176/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 177/200\n",
      "4435/4435 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 178/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 179/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 180/200\n",
      "4435/4435 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 181/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 182/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 183/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 184/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 185/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 186/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 187/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 188/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 189/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 190/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 191/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 192/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 193/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 194/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 195/200\n",
      "4435/4435 [==============================] - 0s 15us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 196/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 197/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 198/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 199/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 200/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "########### Contractive Autoencoder ##########\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu', name = 'encoded')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "lam = 10e-7\n",
    "\n",
    "def contractive_loss(y_pred, y_true):\n",
    "    \n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "        W = K.variable(value=autoencoder.get_layer('encoded').get_weights()[0])\n",
    "        W = K.transpose(W)\n",
    "        h = autoencoder.get_layer('encoded').output\n",
    "        dh = h * (1 - h)\n",
    "        contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "        return mse + contractive\n",
    "    \n",
    "autoencoder.compile(optimizer='adadelta', loss= contractive_loss)\n",
    "ae_train = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('CAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.021252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.003973\n",
       "std      0.003334\n",
       "min      0.001817\n",
       "25%      0.001981\n",
       "50%      0.002395\n",
       "75%      0.004613\n",
       "max      0.021252"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.018248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.003811\n",
       "std      0.003248\n",
       "min      0.001702\n",
       "25%      0.001858\n",
       "50%      0.002253\n",
       "75%      0.004421\n",
       "max      0.018248"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31003293"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120736</td>\n",
       "      <td>0.216592</td>\n",
       "      <td>1.476388</td>\n",
       "      <td>0.592430</td>\n",
       "      <td>0.692733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137616</td>\n",
       "      <td>0.202824</td>\n",
       "      <td>1.511296</td>\n",
       "      <td>0.642235</td>\n",
       "      <td>0.674722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091751</td>\n",
       "      <td>0.197358</td>\n",
       "      <td>1.153303</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.624151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125687</td>\n",
       "      <td>0.183826</td>\n",
       "      <td>1.081301</td>\n",
       "      <td>0.412930</td>\n",
       "      <td>0.640337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112133</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>1.041194</td>\n",
       "      <td>0.401044</td>\n",
       "      <td>0.629156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1         2    3         4         5         6         7         8   \\\n",
       "0  0.0  0.0  0.794206  0.0  0.120736  0.216592  1.476388  0.592430  0.692733   \n",
       "1  0.0  0.0  0.816276  0.0  0.137616  0.202824  1.511296  0.642235  0.674722   \n",
       "2  0.0  0.0  0.769959  0.0  0.091751  0.197358  1.153303  0.461900  0.624151   \n",
       "3  0.0  0.0  0.785560  0.0  0.125687  0.183826  1.081301  0.412930  0.640337   \n",
       "4  0.0  0.0  0.753468  0.0  0.112133  0.208300  1.041194  0.401044  0.629156   \n",
       "\n",
       "    9    10   11  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.561580</td>\n",
       "      <td>0.634534</td>\n",
       "      <td>0.570987</td>\n",
       "      <td>1.203641</td>\n",
       "      <td>0.584229</td>\n",
       "      <td>0.576371</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.508694</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>0.645241</td>\n",
       "      <td>1.034415</td>\n",
       "      <td>0.517116</td>\n",
       "      <td>0.533473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.495993</td>\n",
       "      <td>0.697974</td>\n",
       "      <td>0.591894</td>\n",
       "      <td>0.866980</td>\n",
       "      <td>0.465010</td>\n",
       "      <td>0.599563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.637723</td>\n",
       "      <td>0.607751</td>\n",
       "      <td>0.890813</td>\n",
       "      <td>0.363513</td>\n",
       "      <td>0.499826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.488311</td>\n",
       "      <td>0.896041</td>\n",
       "      <td>0.667947</td>\n",
       "      <td>1.110583</td>\n",
       "      <td>0.518453</td>\n",
       "      <td>0.459832</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5    6\n",
       "1995  0.561580  0.634534  0.570987  1.203641  0.584229  0.576371  0.0\n",
       "1996  0.508694  0.740950  0.645241  1.034415  0.517116  0.533473  0.0\n",
       "1997  0.495993  0.697974  0.591894  0.866980  0.465010  0.599563  0.0\n",
       "1998  0.570517  0.637723  0.607751  0.890813  0.363513  0.499826  0.0\n",
       "1999  0.488311  0.896041  0.667947  1.110583  0.518453  0.459832  0.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./sat_CAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4435 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "4435/4435 [==============================] - 1s 122us/step - loss: 0.0192 - val_loss: 0.0180\n",
      "Epoch 2/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0172 - val_loss: 0.0165\n",
      "Epoch 3/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0158 - val_loss: 0.0153\n",
      "Epoch 4/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 5/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 6/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 7/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 8/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 9/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 10/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 11/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 12/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 13/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 14/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 15/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 16/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 17/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 18/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 19/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 20/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 21/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 22/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 23/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 24/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 25/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 26/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 27/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 28/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 29/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 30/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 31/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 32/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 33/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 34/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 35/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 36/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 37/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 38/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 40/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 41/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 42/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 43/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 44/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 45/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 46/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 47/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 48/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 49/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 50/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 51/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 52/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 53/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 54/200\n",
      "4435/4435 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 55/200\n",
      "4435/4435 [==============================] - 0s 18us/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 56/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 57/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 58/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 59/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 60/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 61/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 62/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 63/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 64/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 65/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 66/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 67/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 68/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 69/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 70/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 71/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 72/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 73/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 74/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 75/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 76/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 77/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 78/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 79/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 80/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 81/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 82/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 83/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 84/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 85/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 86/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 87/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 88/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 89/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 90/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 91/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 92/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 93/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 94/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 95/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 96/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 97/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 98/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 99/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 100/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 101/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 102/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 103/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 104/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 105/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 106/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 107/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 108/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 109/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 110/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 111/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 112/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 113/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 114/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 115/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 116/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 117/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 118/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 119/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 120/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 121/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 122/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 123/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 124/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 125/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 126/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 127/200\n",
      "4435/4435 [==============================] - 0s 13us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 128/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 129/200\n",
      "4435/4435 [==============================] - 0s 14us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 130/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 131/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 132/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 133/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 134/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 135/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 136/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 137/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 138/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 139/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 140/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 141/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 142/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 143/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 144/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 145/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 146/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 147/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 148/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 149/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 150/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 151/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 152/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 153/200\n",
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 154/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 155/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435/4435 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 157/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 158/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 159/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 160/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 161/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 162/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 163/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 164/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 165/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 166/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 167/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 168/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 169/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 170/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 171/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 172/200\n",
      "4435/4435 [==============================] - 0s 11us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 173/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 174/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 175/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 176/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 177/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 178/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 179/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 180/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 181/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 182/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 183/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 184/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 185/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 186/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 187/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 188/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 189/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 190/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 191/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 192/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 193/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 194/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 195/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 196/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 197/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 198/200\n",
      "4435/4435 [==============================] - 0s 10us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 199/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 200/200\n",
      "4435/4435 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0081\n"
     ]
    }
   ],
   "source": [
    "############ Denoiding Autoencoder ###########\n",
    "\n",
    "# add noise\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoding_dim = 12\n",
    "#learning_rate = 1e-7\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# implenment an autoencoder, creat encoder and decoder\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "                                             \n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "ae_train = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_test_noisy, x_test)\n",
    "                ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DAE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('DAE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.007627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.008208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.009025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.019170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.008810\n",
       "std      0.001723\n",
       "min      0.007627\n",
       "25%      0.007816\n",
       "50%      0.008208\n",
       "75%      0.009025\n",
       "max      0.019170"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.008084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.008198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.008519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.009147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.018025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.009026\n",
       "std      0.001489\n",
       "min      0.008084\n",
       "25%      0.008198\n",
       "50%      0.008519\n",
       "75%      0.009147\n",
       "max      0.018025"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "encoded_data = encoder.predict(x_test)\n",
    "#decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36931983"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.983365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.794121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.009765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.817123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.825023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.757096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.592825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.740648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.586637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2         3    4    5    6         7    8    9    10        11\n",
       "0  0.0  0.0  0.0  1.983365  0.0  0.0  0.0  1.794121  0.0  0.0  0.0  0.944839\n",
       "1  0.0  0.0  0.0  2.009765  0.0  0.0  0.0  1.817123  0.0  0.0  0.0  0.959566\n",
       "2  0.0  0.0  0.0  1.825023  0.0  0.0  0.0  1.666132  0.0  0.0  0.0  0.805290\n",
       "3  0.0  0.0  0.0  1.757096  0.0  0.0  0.0  1.592825  0.0  0.0  0.0  0.761949\n",
       "4  0.0  0.0  0.0  1.740648  0.0  0.0  0.0  1.586637  0.0  0.0  0.0  0.756928"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.700664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.405238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.557762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.271051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.456014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.181055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.485580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.201317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.563267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.249660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1         2    3    4         5    6    7         8\n",
       "1995  0.0  0.0  1.700664  0.0  0.0  1.405238  0.0  0.0  0.917400\n",
       "1996  0.0  0.0  1.557762  0.0  0.0  1.271051  0.0  0.0  0.864720\n",
       "1997  0.0  0.0  1.456014  0.0  0.0  1.181055  0.0  0.0  0.777323\n",
       "1998  0.0  0.0  1.485580  0.0  0.0  1.201317  0.0  0.0  0.741247\n",
       "1999  0.0  0.0  1.563267  0.0  0.0  1.249660  0.0  0.0  0.901492"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./sat_DAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# tranform the input format, add a dimension\n",
    "x_train_con = x_train.as_matrix()\n",
    "x_train_con = np.reshape(x_train_con, (-1, input_dim, 1))\n",
    "x_text_con = x_test.as_matrix()\n",
    "x_text_con = np.reshape(x_text_con, (-1, input_dim, 1))\n",
    "\n",
    "input_layer = Input(shape=(input_dim,1))\n",
    "\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D(2, padding='same')(x)\n",
    "x = Conv1D(2, 3, activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling1D(2, padding='same')(x)\n",
    "\n",
    "\n",
    "x = Conv1D(2, 3, activation='relu', padding='same')(encoded)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling1D(2)(x)\n",
    "decoded = Conv1D(1, 5, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 36, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 36, 32)            128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 18, 16)            1552      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 9, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 9, 2)              98        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5, 2)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5, 2)              14        \n",
      "_________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1 (None, 10, 2)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 10, 16)            112       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1 (None, 20, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 20, 32)            1568      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1 (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 36, 1)             161       \n",
      "=================================================================\n",
      "Total params: 3,633\n",
      "Trainable params: 3,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4435 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "4435/4435 [==============================] - 1s 212us/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 2/200\n",
      "4435/4435 [==============================] - 0s 96us/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 3/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 4/200\n",
      "4435/4435 [==============================] - 0s 95us/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 5/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 6/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 7/200\n",
      "4435/4435 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 8/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 9/200\n",
      "4435/4435 [==============================] - 1s 122us/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 10/200\n",
      "4435/4435 [==============================] - 1s 136us/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 11/200\n",
      "4435/4435 [==============================] - 1s 114us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 12/200\n",
      "4435/4435 [==============================] - 1s 145us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 13/200\n",
      "4435/4435 [==============================] - 0s 110us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 14/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 15/200\n",
      "4435/4435 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 16/200\n",
      "4435/4435 [==============================] - 0s 110us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 17/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 18/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 19/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 20/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 21/200\n",
      "4435/4435 [==============================] - 1s 116us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 22/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 23/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 24/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 25/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 26/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 27/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 28/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 29/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 30/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 31/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 32/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 33/200\n",
      "4435/4435 [==============================] - 0s 96us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 34/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 35/200\n",
      "4435/4435 [==============================] - 0s 96us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 36/200\n",
      "4435/4435 [==============================] - 1s 130us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 37/200\n",
      "4435/4435 [==============================] - 1s 128us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 38/200\n",
      "4435/4435 [==============================] - 1s 117us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 39/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 40/200\n",
      "4435/4435 [==============================] - 1s 121us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 41/200\n",
      "4435/4435 [==============================] - 1s 132us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 42/200\n",
      "4435/4435 [==============================] - 1s 140us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 43/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 44/200\n",
      "4435/4435 [==============================] - 1s 119us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 45/200\n",
      "4435/4435 [==============================] - 1s 113us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 46/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 47/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 48/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 49/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 50/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 51/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 52/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 53/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 54/200\n",
      "4435/4435 [==============================] - 0s 97us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 55/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 56/200\n",
      "4435/4435 [==============================] - 0s 95us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 57/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 58/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 59/200\n",
      "4435/4435 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 60/200\n",
      "4435/4435 [==============================] - 1s 116us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 61/200\n",
      "4435/4435 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 62/200\n",
      "4435/4435 [==============================] - 1s 129us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 63/200\n",
      "4435/4435 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 64/200\n",
      "4435/4435 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 65/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 66/200\n",
      "4435/4435 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 67/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 68/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 69/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 70/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 71/200\n",
      "4435/4435 [==============================] - 1s 154us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 72/200\n",
      "4435/4435 [==============================] - 1s 118us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 73/200\n",
      "4435/4435 [==============================] - 1s 120us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 74/200\n",
      "4435/4435 [==============================] - 1s 122us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 75/200\n",
      "4435/4435 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 76/200\n",
      "4435/4435 [==============================] - 1s 132us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 77/200\n",
      "4435/4435 [==============================] - 1s 139us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435/4435 [==============================] - 1s 150us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 79/200\n",
      "4435/4435 [==============================] - 1s 118us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 80/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 81/200\n",
      "4435/4435 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 82/200\n",
      "4435/4435 [==============================] - 1s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 83/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 84/200\n",
      "4435/4435 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 85/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 86/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 87/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 88/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 89/200\n",
      "4435/4435 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 90/200\n",
      "4435/4435 [==============================] - 1s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 91/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 92/200\n",
      "4435/4435 [==============================] - 1s 118us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 93/200\n",
      "4435/4435 [==============================] - 1s 126us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 94/200\n",
      "4435/4435 [==============================] - 1s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "4435/4435 [==============================] - 1s 129us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 96/200\n",
      "4435/4435 [==============================] - 1s 132us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 97/200\n",
      "4435/4435 [==============================] - 1s 116us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 98/200\n",
      "4435/4435 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 99/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "4435/4435 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 101/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 102/200\n",
      "4435/4435 [==============================] - 1s 119us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 103/200\n",
      "4435/4435 [==============================] - 1s 115us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 104/200\n",
      "4435/4435 [==============================] - 1s 132us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 105/200\n",
      "4435/4435 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 106/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 107/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 108/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 109/200\n",
      "4435/4435 [==============================] - 0s 97us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 110/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 111/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 112/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 113/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 114/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 115/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 116/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 117/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 118/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 119/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 120/200\n",
      "4435/4435 [==============================] - 0s 95us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 121/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 122/200\n",
      "4435/4435 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 123/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 124/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 125/200\n",
      "4435/4435 [==============================] - 0s 97us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 126/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 127/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 128/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 129/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 130/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 131/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 132/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 133/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 134/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 135/200\n",
      "4435/4435 [==============================] - 1s 127us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 136/200\n",
      "4435/4435 [==============================] - 1s 123us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 137/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 138/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 139/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 140/200\n",
      "4435/4435 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 141/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 142/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 143/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 144/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 145/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 146/200\n",
      "4435/4435 [==============================] - 0s 97us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 147/200\n",
      "4435/4435 [==============================] - 0s 99us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 148/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "4435/4435 [==============================] - 0s 97us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 150/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 151/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 152/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 153/200\n",
      "4435/4435 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 154/200\n",
      "4435/4435 [==============================] - 0s 97us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 156/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 157/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 158/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 159/200\n",
      "4435/4435 [==============================] - 1s 132us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 160/200\n",
      "4435/4435 [==============================] - 1s 123us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 161/200\n",
      "4435/4435 [==============================] - 1s 137us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 162/200\n",
      "4435/4435 [==============================] - 1s 124us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 163/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 164/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 165/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 166/200\n",
      "4435/4435 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 167/200\n",
      "4435/4435 [==============================] - 1s 117us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 168/200\n",
      "4435/4435 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 169/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 170/200\n",
      "4435/4435 [==============================] - 1s 121us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 171/200\n",
      "4435/4435 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 172/200\n",
      "4435/4435 [==============================] - 1s 120us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 173/200\n",
      "4435/4435 [==============================] - 1s 124us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 174/200\n",
      "4435/4435 [==============================] - 1s 131us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 175/200\n",
      "4435/4435 [==============================] - 1s 186us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 176/200\n",
      "4435/4435 [==============================] - 1s 160us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 177/200\n",
      "4435/4435 [==============================] - 1s 163us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 178/200\n",
      "4435/4435 [==============================] - 1s 147us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 179/200\n",
      "4435/4435 [==============================] - 1s 161us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 180/200\n",
      "4435/4435 [==============================] - 1s 163us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 181/200\n",
      "4435/4435 [==============================] - 1s 145us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 182/200\n",
      "4435/4435 [==============================] - 1s 159us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 183/200\n",
      "4435/4435 [==============================] - 1s 132us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 184/200\n",
      "4435/4435 [==============================] - 1s 120us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 185/200\n",
      "4435/4435 [==============================] - 1s 122us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "4435/4435 [==============================] - 1s 118us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 187/200\n",
      "4435/4435 [==============================] - 1s 115us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 188/200\n",
      "4435/4435 [==============================] - 1s 140us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 189/200\n",
      "4435/4435 [==============================] - 1s 120us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 190/200\n",
      "4435/4435 [==============================] - 1s 122us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 191/200\n",
      "4435/4435 [==============================] - 1s 117us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 192/200\n",
      "4435/4435 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 193/200\n",
      "4435/4435 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 194/200\n",
      "4435/4435 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 195/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 196/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 197/200\n",
      "4435/4435 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 198/200\n",
      "4435/4435 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 199/200\n",
      "4435/4435 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 200/200\n",
      "4435/4435 [==============================] - 1s 118us/step - loss: 0.0014 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "ae_train = autoencoder.fit(x_train_con, x_train_con,\n",
    "                epochs=200,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_text_con, x_text_con),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxcdbn48c8zWyb73n1JN6ALbRpCBUUKVrFFpAhVWlEBUURFr3L1WtzlXrzoVUEEUfgBIgIFQbQqiyxlE22bli60pTRt0zZN2qZpmmZPZub5/XFOwjQkaZLOZJL2eb9e88qZ7/me73nOSTLPfM/yPaKqGGOMMbHgSXQAxhhjThyWVIwxxsSMJRVjjDExY0nFGGNMzFhSMcYYEzOWVIwxxsSMJRVjjDExY0nFmJOAiPxORP6nl3XLROSDx9uOOTlZUjFDioh8UkRKRKReRCpF5GkROSfBMV0lIioin+hUfp6IRNxYo19nJypWY+LNkooZMkTkBuA24MfAcGAc8GtgYSLjAq4EDrk/O6tQ1bROr38NcHzGDBhLKmZIEJFM4Cbgy6r6J1VtUNU2Vf2rqn7TrZMkIreJSIX7uk1Ektx554lIuYj8p4gccHs5V7vzzhKRfSLijVrfx0RkQy/iGg/MBa4FPiwiw49jG8tE5JsiskFEGkTkXhEZ7vbG6kTkeRHJjqp/sYhsEpHDIvKSiEyNmjdbRNa6yz0KBDut6yIRWecu+7qIzOxnzJ8XkVIROSQiy0VklFsuInKru69r3W2a4c67UEQ2u7HtFZFv9GuHmUHJkooZKs7G+WB8soc63wHOAgqBWcAc4LtR80cAmcBo4BrgThHJVtV/Aw3AB6LqfhJ4uBdxfQYoUdUngC3AFb3amu5dBnwIOAX4KPA08G0gD+f/9asAInIK8AjwNSAfeAr4q4gERCQA/Bl4EMgB/ui2i7tsEXAf8AUgF/gtsLw9AfeWiHwA+F/gE8BIYBewzJ19AXCuux1ZwOVAtTvvXuALqpoOzABe7Mt6zeBmScUMFbnAQVUN9VDnCuAmVT2gqlXAj4BPR81vc+e3qepTQD1wqjvvEWAJgIikAxe6ZcfyGd5JPg/z7kNgo9zeQPQrtYf2fqWq+1V1L/AqsFJV31DVFpyEOtutdznwd1V9TlXbgJ8BycB7cRKrH7jN3dbHgdVR6/g88FtVXamqYVV9AGhxl+uLK4D7VHWtG9+NwNkiUoCzr9OB0wBR1S2qWuku1wZME5EMVa1R1bV9XK8ZxCypmKGiGsgTEV8PdUbhfFtut8st62ijU1JqBNLc6YeBS91v65cCa1U1uq13EZH3ARN459v5w8DpIlIYVa1CVbM6vRp6aHZ/1HRTF+/b4z1qW1U1AuzB6YWNAvbq0UOQR2/LeOA/oxMdMJaj91VvdI6hHuf3NFpVXwTuAO4E9ovI3SKS4Va9DCdp7xKRl+3ChROLJRUzVPwLaAYu6aFOBc4HZrtxbtkxqepmnA/IBfT+0NeVgADrRGQfsNIt/0xv1nmcjtpWERGcxLAXqARGu2XtxkVN7wFu7pToUlS1Nz2znmJIxelR7gVQ1dtV9QxgOs5hsG+65atVdSEwDOcw3WN9XK8ZxCypmCFBVWuB7+OcB7lERFJExC8iC0Tkp261R4Dviki+iOS59f/Qh9U8jHPO4lyc8xDdEpEgzrmEa3HO4bS/vgJccYweVSw8BnxEROaJiB/4T5xDWK/jJOAQ8FUR8YnIpTjnl9rdA1wnIu9xT6inishH3MN+ffEwcLWIFLo9vB/jHK4rE5Ez3fb9OOermoGwe87nChHJdA/bHQHCx7EfzCBjScUMGar6C+AGnJPvVTjfuK/H+bYL8D9ACbAB2Aisdct66xHgPOBFVT14jLqX4ByO+r2q7mt/4ZyE9gLz3Xqj5N33qVzWXaO9papbgU8BvwIO4pzU/6iqtqpqK84hvKuAGpzzL3+KWrYE57zKHe78UrduX2N4Afge8ARO72gSsNidnYGTvGpweoDVOOd9wDnPVSYiR4Dr3O0wJwixJz8aY4yJFeupGGOMiRlLKsb0wL3xsPPhq3oR+XaiYzNmMLLDX8YYY2Im3leoDGp5eXlaUFCQ6DCMMWZIWbNmzUFVze9q3kmdVAoKCigpKUl0GMYYM6SISLc3Bts5FWOMMTFjScUYY0zMWFIxxhgTMyf1ORVjzImjra2N8vJympubEx3KCSMYDDJmzBj8fn+vl7GkYow5IZSXl5Oenk5BQQFHj6Vp+kNVqa6upry8nAkTJvR6OTv8ZYw5ITQ3N5Obm2sJJUZEhNzc3D73/CypGGNOGJZQYqs/+9OSSj+sLjvE/z37FuGIjUZgjDHR4ppURGS+iGwVkVIRWdrF/CQRedSdv9J9DCkikisiK9wxlu6Iqp8uIuuiXgdF5DZ33lUiUhU173Px2q51uw9z54rtNLb29GRbY8zJorq6msLCQgoLCxkxYgSjR4/ueN/a2tqrNq6++mq2bt3aY50777yThx56KBYhx03cTtSLiBfnUaIfAsqB1SKy3H3CXrtrgBpVnSwii4Gf4Dz7oRnnOQ0z3BcAqlqH8yCk9nWsIeo5EcCjqnp9nDapQ0qSF4Cm1jDpwd5fFWGMOTHl5uaybt06AH74wx+SlpbGN77xjaPqqCqqisfT9Xf5+++//5jr+fKXv3z8wcZZPHsqc4BSVd3hPjRoGbCwU52FwAPu9OPAPBERVW1Q1ddwkkuXRGQKzuNIX4196D1LDTi5uKHVHlhnjOleaWkpM2bM4LrrrqOoqIjKykquvfZaiouLmT59OjfddFNH3XPOOYd169YRCoXIyspi6dKlzJo1i7PPPpsDBw4A8N3vfpfbbruto/7SpUuZM2cOp556Kq+//joADQ0NXHbZZcyaNYslS5ZQXFzckfAGQjwvKR6N82S+duXAe7qro6ohEanFecb1sZ66B7AEp2cSfWLjMhE5F3gb+Lqq7um8kIhci/MIWMaNG9d5dq8kB5yeih3+MmZw+tFfN7G54khM25w2KoMffHR6n5fbvHkz999/P7/5zW8AuOWWW8jJySEUCnH++eezaNEipk2bdtQytbW1zJ07l1tuuYUbbriB++67j6VL33UGAVVl1apVLF++nJtuuolnnnmGX/3qV4wYMYInnniC9evXU1RU1L8N7qd49lS6umyg85nt3tTpzmKcx7+2+ytQoKozged5pwd0dOOqd6tqsaoW5+d3OcjmMbX3VBqtp2KMOYZJkyZx5plndrx/5JFHKCoqoqioiC1btrB58+Z3LZOcnMyCBQsAOOOMMygrK+uy7UsvvfRddV577TUWL3ae6jxr1iymT+97Ijwe8eyplANjo96PASq6qVMuIj4gEzh0rIZFZBbgU9U17WWqWh1V5R6c8zNx8U5PxZKKMYNRf3oU8ZKamtoxvW3bNn75y1+yatUqsrKy+NSnPtXlfSCBQKBj2uv1Egp1fVQkKSnpXXUS/YysePZUVgNTRGSCiARwehbLO9VZDlzpTi8CXtTe7ZElHN1LQURGRr29GNjSr6h7Ic3TzCgO0tjcFq9VGGNOQEeOHCE9PZ2MjAwqKyt59tlnY76Oc845h8ceewyAjRs3dtkTiqe49VTccyTXA88CXuA+Vd0kIjcBJaq6HLgXeFBESnF6KIvblxeRMiADCIjIJcAFUVeOfQK4sNMqvyoiFwMht62r4rVtw7Y8yOvBm/lzkz2LxRjTe0VFRUybNo0ZM2YwceJE3ve+98V8HV/5ylf4zGc+w8yZMykqKmLGjBlkZmbGfD3dOakfJ1xcXKz9eUhX/cu/Im3Fd3n0/Fe4fO6sOERmjOmrLVu2MHXq1ESHkXChUIhQKEQwGGTbtm1ccMEFbNu2DZ+vf32IrvariKxR1eKu6tuAkv3gD6YA0NLSlOBIjDHmaPX19cybN49QKISq8tvf/rbfCaU/LKn0gz+QDEBbS2OCIzHGmKNlZWWxZs2aY1eMExv7qx88/iAAbc3WUzHGmGiWVPrD5ySVUKv1VIwxJpollf7wOdeGh+2cijHGHMWSSn+4PZVwmz221BhjollS6Q/3nEqk1ZKKMcZx3nnnvetmxttuu40vfelL3S6TlpYGQEVFBYsWLeq23WPd+nDbbbfR2PjO4fgLL7yQw4cP9zb0mLKk0h9uTyXSZoe/jDGOJUuWsGzZsqPKli1bxpIlS4657KhRo3j88cf7ve7OSeWpp54iKyur3+0dD0sq/eEmFQ21JDgQY8xgsWjRIv72t7/R0uJ8LpSVlVFRUUFhYSHz5s2jqKiI008/nb/85S/vWrasrIwZM5xHRzU1NbF48WJmzpzJ5ZdfTlPTO19ev/jFL3YMm/+DH/wAgNtvv52KigrOP/98zj//fAAKCgo4eNAZ7P0Xv/gFM2bMYMaMGR3D5peVlTF16lQ+//nPM336dC644IKj1nM87D6V/nBP1BOyw1/GDEpPL4V9G2Pb5ojTYcEt3c7Ozc1lzpw5PPPMMyxcuJBly5Zx+eWXk5yczJNPPklGRgYHDx7krLPO4uKLL+72+e933XUXKSkpbNiwgQ0bNhw1dP3NN99MTk4O4XCYefPmsWHDBr761a/yi1/8ghUrVpCXl3dUW2vWrOH+++9n5cqVqCrvec97mDt3LtnZ2Wzbto1HHnmEe+65h0984hM88cQTfOpTnzru3WQ9lf5weypiScUYEyX6EFj7oS9V5dvf/jYzZ87kgx/8IHv37mX//v3dtvHKK690fLjPnDmTmTNndsx77LHHKCoqYvbs2WzatOmYg0W+9tprfOxjHyM1NZW0tDQuvfRSXn3Vea7hhAkTKCx0HqTb0/D6fWU9lf7oSCp2+MuYQamHHkU8XXLJJdxwww2sXbuWpqYmioqK+N3vfkdVVRVr1qzB7/dTUFDQ5XD30brqxezcuZOf/exnrF69muzsbK666qpjttPT2I7tw+aDM3R+rA5/WU+lP9qTSriFSOTkHZDTGHO0tLQ0zjvvPD772c92nKCvra1l2LBh+P1+VqxYwa5du3ps49xzz+Whhx4C4M0332TDhg2AM2x+amoqmZmZ7N+/n6effrpjmfT0dOrq6rps689//jONjY00NDTw5JNP8v73vz9Wm9sl66n0h9dHRLwkSRtNbWFSk2w3GmMcS5Ys4dJLL+04DHbFFVfw0Y9+lOLiYgoLCznttNN6XP6LX/wiV199NTNnzqSwsJA5c+YAzlMcZ8+ezfTp0981bP61117LggULGDlyJCtWrOgoLyoq4qqrrupo43Of+xyzZ8+O2aGurtjQ9/0Y+h6g7b9HcH/LB/jYt+4nPz3p2AsYY+LKhr6Pj74OfW+Hv/op4kkiSCuNrV0/5tMYY05GllT6KeILkkSbPafeGGOiWFLpJ/UmkSTWUzFmMDmZD+fHQ3/2pyWV/rKeijGDSjAYpLq62hJLjKgq1dXVBIPBPi1nly31k/iTSKKNhhZLKsYMBmPGjKG8vJyqqqpEh3LCCAaDjBkzpk/LWFLpJ/EFCVJPbZsd/jJmMPD7/UyYMCHRYZz04nr4S0Tmi8hWESkVkaVdzE8SkUfd+StFpMAtzxWRFSJSLyJ3dFrmJbfNde5rWE9txYvHHyRJrKdijDHR4pZURMQL3AksAKYBS0RkWqdq1wA1qjoZuBX4iVveDHwP+EY3zV+hqoXu68Ax2ooLTyCFJNposnMqxhjTIZ49lTlAqaruUNVWYBmwsFOdhcAD7vTjwDwREVVtUNXXcJJLb3XZVv/D75kn4Jyob7Crv4wxpkM8k8poYE/U+3K3rMs6qhoCaoHcXrR9v3vo63tRiaNXbYnItSJSIiIlx3NCz+MLEhTrqRhjTLR4JpWuegmdr/XrTZ3OrlDV04H3u69P96UtVb1bVYtVtTg/P/8Yq+qBL4mgtFHfYj0VY4xpF8+kUg6MjXo/Bqjoro6I+IBM4FBPjarqXvdnHfAwzmG2frV1XHxBd5gW66kYY0y7eCaV1cAUEZkgIgFgMbC8U53lwJXu9CLgRe3hziUR8YlInjvtBy4C3uxPW8fNHyRAGw3WUzHGmA5xu09FVUMicj3wLOAF7lPVTSJyE1CiqsuBe4EHRaQUp1exuH15ESkDMoCAiFwCXADsAp51E4oXeB64x12k27biwhckiVYaWtriuhpjjBlK4nrzo6o+BTzVqez7UdPNwMe7Wbagm2bP6KZ+t23Fhfuc+pYWe/qjMca0s7G/+st9+mNbS2OCAzHGmMHDkkp/uT2VcGtfbqUxxpgTmyWV/nJ7KmHrqRhjTAdLKv3lJpVIW1OCAzHGmMHDkkp/uUnFG2mlJWT3qhhjDFhS6T83qSTRRqONVGyMMYAllf5zT9Qn2VAtxhjTwZJKf0X3VGyoFmOMASyp9J/fSSpBWq2nYowxLksq/XVUT8WSijHGgCWV/us4p9Jqg0oaY4zLkkp/RfVU7Dn1xhjjsKTSX+09FXuksDHGdLCk0l++ZMB6KsYYE82SSn95/ShC0M6pGGNMB0sq/SWC+IKkecN2+MsYY1yWVI5HIIUsb4sN02KMMS5LKscjazzjZB/11lMxxhjAksrxyZvCeK2g0c6pGGMMYEnl+OROIT9SRaipIdGRGGPMoGBJ5XjkTQEgq3lXggMxxpjBIa5JRUTmi8hWESkVkaVdzE8SkUfd+StFpMAtzxWRFSJSLyJ3RNVPEZG/i8hbIrJJRG6JmneViFSJyDr39bl4bhvQkVTyW3bHfVXGGDMUxC2piIgXuBNYAEwDlojItE7VrgFqVHUycCvwE7e8Gfge8I0umv6Zqp4GzAbeJyILouY9qqqF7uv/xXBzupYzkQjC8LbyuK/KGGOGgnj2VOYApaq6Q1VbgWXAwk51FgIPuNOPA/NERFS1QVVfw0kuHVS1UVVXuNOtwFpgTBy3oWf+ZI4ERjA6bEnFGGMgvkllNLAn6n25W9ZlHVUNAbVAbm8aF5Es4KPAC1HFl4nIBhF5XETGdrPctSJSIiIlVVVVvduSHhxOGU+B7iUS0eNuyxhjhrp4JhXpoqzzJ29v6ry7YREf8Ahwu6rucIv/ChSo6kzged7pAR3duOrdqlqsqsX5+fnHWtUx1aVNYIJU2jNVjDGG+CaVciC6tzAGqOiujpsoMoFDvWj7bmCbqt7WXqCq1ara4r69Bzijn3H3SXPmZFKlhSOV2wdidcYYM6jFM6msBqaIyAQRCQCLgeWd6iwHrnSnFwEvqmqPPRUR+R+c5PO1TuUjo95eDGw5jth7LXXyewGo3vzSQKzOGGMGNV+8GlbVkIhcDzwLeIH7VHWTiNwElKjqcuBe4EERKcXpoSxuX15EyoAMICAilwAXAEeA7wBvAWtFBOAO90qvr4rIxUDIbeuqeG1btAnTzuTwn1Nh1z+B6wZilcYYM2jFLakAqOpTwFOdyr4fNd0MfLybZQu6abar8zCo6o3Ajf0K9DgkJ/lZ55/BxEMlA71qY4wZdOyO+hg4mHsGw0MV6JHOp4yMMebkYkklBqTgHAAOv/VyYgMxxpgEs6QSAyNPm0OdJlO31ZKKMebkZkklBqaNzmGTFuDbvzHRoRhjTEJZUomB5ICXfcHJ5DSUQiSS6HCMMSZhLKnESGjYdILaTKR6x7ErG2PMCcqSSoxkFswGYH/p6gRHYowxiWNJJUYmTjuDkHqo2fFGokMxxpiEsaQSIxNG5FEmo2Dfm4kOxRhjEsaSSox4PEJVyhRy699OdCjGGJMwllRiKJQ/neFaRf3hg4kOxRhjEsKSSgylj5kOwJ5SOwRmjDk5WVKJodzREwE4vG9ngiMxxpjEsKQSQ8PHTAKg8eCeY9Q0xpgTkyWVGAqk59FCAK0tT3QoxhiTEJZUYkmEGl8evvrKREdijDEJYUklxpqCI0hv3c8xnopsjDEnJEsqMRbJGMVwqjlQ15LoUIwxZsBZUokxf/YYhlPDzgNHEh2KMcYMOEsqMZaWX4Bfwuyr2J3oUIwxZsBZUomxzOHjAajZV5bYQIwxJgHimlREZL6IbBWRUhFZ2sX8JBF51J2/UkQK3PJcEVkhIvUickenZc4QkY3uMreLiLjlOSLynIhsc39mx3PbuuPNGgNAy0HrqRhjTj5xSyoi4gXuBBYA04AlIjKtU7VrgBpVnQzcCvzELW8Gvgd8o4um7wKuBaa4r/lu+VLgBVWdArzgvh94GaMB8DfaZcXGmJNPPHsqc4BSVd2hqq3AMmBhpzoLgQfc6ceBeSIiqtqgqq/hJJcOIjISyFDVf6lzze7vgUu6aOuBqPKBlZJDqwRIad6fkNUbY0wi9SqpiMh/iEiGOO4VkbUicsExFhsNRI9XUu6WdVlHVUNALZB7jDajb1ePbnO4qla6bVUCw7rZlmtFpERESqqqqo6xCf0gQl1gOFmtB2LftjHGDHK97al8VlWPABcA+cDVwC3HWEa6KOt8R2Bv6hxP/XdXVr1bVYtVtTg/P78vi/ZaSzCPbA7T0BKKS/vGGDNY9TaptH+YXwjcr6rr6foDPlo5MDbq/Rigors6IuIDMoFDx2hzTDdt7ncPj7UfJktYVyGSnEsORzhYbzdAGmNOLr1NKmtE5B84SeVZEUkHIsdYZjUwRUQmiEgAWAws71RnOXClO70IeFF7GN/EPaxVJyJnuVd9fQb4SxdtXRlVPuAkLZ8cqbOkYow56fh6We8aoBDYoaqNIpKDcwisW6oaEpHrgWcBL3Cfqm4SkZuAElVdDtwLPCgipTg9lMXty4tIGZABBETkEuACVd0MfBH4HZAMPO2+wDkc95iIXAPsBj7ey22LOX/6MHKoo+RIU6JCMMaYhOhtUjkbWKeqDSLyKaAI+OWxFlLVp4CnOpV9P2q6mW4+/FW1oJvyEmBGF+XVwLxjxTQQgpnD8IhSV3OAd1+bYIwxJ67eHv66C2gUkVnAfwG7cC7nNV1IyRkBQFPNvgRHYowxA6u3SSXknutYCPxSVX8JpMcvrKHNl+ZcVdZ2xC4rNsacXHp7+KtORG4EPg28371b3h+/sIa4VCepROoPJjgQY4wZWL3tqVwOtODcr7IP50TB/8UtqqEuNQ8AabSkYow5ufQqqbiJ5CEgU0QuAppV1c6pdCc5BwBfc0+33BhjzImnt8O0fAJYhXOl1ieAlSKyKJ6BDWleH43eTIKtllSMMSeX3p5T+Q5wpqoeABCRfOB5nEEgTReak7JJbz1Mc1uYoN+b6HCMMWZA9Paciqc9obiq+7DsSSkUzCVPbKgWY8zJpbc9lWdE5FngEff95XS6qdF0kpJHDvuoqmthTHZKoqMxxpgB0aukoqrfFJHLgPfhDCR5t6o+GdfIhjhfej65Usu22mZmJzoYY4wZIL3tqaCqTwBPxDGWE0pK9ggCNFBxqD7RoRhjzIDpMamISB1dP69EAFXVjLhEdQJIyhyGiFJzcB/OU4+NMebE12NSUVUbiqWfxL2rvt7G/zLGnETsCq54yRoHgL9mR4IDMcaYgWNJJV6GzyAkPkY3bEp0JMYYM2AsqcSLP0h12qmcFt5mz6o3xpw0LKnEUUPeLE737LArwIwxJw1LKnEkY84gTZqp2b0x0aEYY8yAsKQSR6mTzgIgsqckwZEYY8zAsKQSR7ljp1GrqSQfeCPRoRhjzICwpBJHXq+HDd5pTKx+BdqaEh2OMcbEXVyTiojMF5GtIlIqIku7mJ8kIo+681eKSEHUvBvd8q0i8mG37FQRWRf1OiIiX3Pn/VBE9kbNuzCe29Zbr+R8gvRwDbzxh0SHYowxcRe3pOI+x/5OYAEwDVgiItM6VbsGqFHVycCtwE/cZacBi4HpwHzg1yLiVdWtqlqoqoXAGUAjED2w5a3t81V1UIyiPKrwg6yJTKHt1dsg3JbocIwxJq7i2VOZA5Sq6g5VbQWWAQs71VkIPOBOPw7MExFxy5epaouq7gRK3faizQO2q+quuG1BDCw4fRR3hi/BX1cOj18NrQ2JDskYY+ImnkllNLAn6n25W9ZlHVUNAbVAbi+XXcw7z3dpd72IbBCR+0Qku6ugRORaESkRkZKqqqq+bE+/jMgMUjfmfH4TvAbe+js8+um4r9MYYxIlnklFuijrPOJxd3V6XFZEAsDFwB+j5t8FTAIKgUrg510Fpap3q2qxqhbn5+d3H30MfWTmKG45PI8Dxd+A7S9A1dsDsl5jjBlo8Uwq5cDYqPdjgIru6oiID8gEDvVi2QXAWlXd316gqvtVNayqEeAe3n24LGEuLhxNZrKfb5cVoh4fvPH7RIdkjDFxEc+kshqYIiIT3J7FYmB5pzrLgSvd6UXAi6qqbvli9+qwCTgPJFkVtdwSOh36EpGRUW8/BrwZsy05TjmpAb530TSe3wO78+bCukcg1JrosIwxJubillTccyTXA88CW4DHVHWTiNwkIhe71e4FckWkFLgBWOouuwl4DNgMPAN8WVXDACKSAnwI+FOnVf5URDaKyAbgfODr8dq2/risaDRzT8nnx/vOhMaD8PbTiQ7JGGNiTpyOwcmpuLhYS0oGbgiVvYebmP+LFbzk/wo5EwqRT9nTmY0xQ4+IrFHV4q7m2R31A2h0VjL/tWAaf2g5F0pfgMN7jr2QMcYMIZZUBtgV7xnPmuwLUSBid9kbY04wllQGmMcjXP6hc3gtPIPmVQ9AJJzokIwxJmYsqSTAghkjeDl9ASlNlURKVyQ6HGOMiRlLKgng8QizPvBJqjWdqlfuSXQ4xhgTM5ZUEmTB7PH8w3ceueXPQ338h4sxxpiBYEklQfxeD/45V+MjRMWK3yY6HGOMiQlLKgk0/7y5/FNnkrb+Xgi1JDocY4w5bpZUEigtycemCVeRETpEy9rOAy4bY8zQY0klwQrPvYRNkfE0v3pHokMxxpjjZkklwc6ckMOrSXPJrNsGjYcSHY4xxhwXSyoJJiIMO/UsAA6Vrk5wNMYYc3wsqQwChXPmArBjw2sJjsQYY46PJZVBYOK4MVR4RhDasybRoRhjzHGxpDJI1Oeczujmt9l/pDnRoRhjTL9ZUhkkcqacyVip4qU33kp0KMYY02+WVAaJ3MnvAexkvTFmaLOkMkjIqFkAePdvSHAkxhjTf5ZUBovkbOoDeWQ3lnGkuS3R0RhjTL9YUhlE2rInM1ZilKIAABm3SURBVMlTwZvltYkOxRhj+sWSyiCSPHIqk6SC9XsOJzoUY4zpl7gmFRGZLyJbRaRURJZ2MT9JRB51568UkYKoeTe65VtF5MNR5WUislFE1olISVR5jog8JyLb3J/Z8dy2eAiOnEqmNFK2a2eiQzHGmH6JW1IRES9wJ7AAmAYsEZFpnapdA9So6mTgVuAn7rLTgMXAdGA+8Gu3vXbnq2qhqhZHlS0FXlDVKcAL7vuhJW8KAPV7Nyc4EGOM6Z949lTmAKWqukNVW4FlwMJOdRYCD7jTjwPzRETc8mWq2qKqO4FSt72eRLf1AHBJDLZhYOWdAkCWnaw3xgxR8Uwqo4E9Ue/L3bIu66hqCKgFco+xrAL/EJE1InJtVJ3hqlrptlUJDOsqKBG5VkRKRKSkqmqQPcY3YzQhbwqTZS87qhoSHY0xxvRZPJOKdFGmvazT07LvU9UinMNqXxaRc/sSlKrerarFqlqcn5/fl0XjT4RQzmQmSQU7quoTHY0xxvRZPJNKOTA26v0YoKK7OiLiAzKBQz0tq6rtPw8AT/LOYbH9IjLSbWskcCCG2zJg/MNPZZKn0noqxpghKZ5JZTUwRUQmiEgA58T78k51lgNXutOLgBdVVd3yxe7VYROAKcAqEUkVkXQAEUkFLgDe7KKtK4G/xGm74sqbfyqj5SDlBwbZoTljjOkFX7waVtWQiFwPPAt4gftUdZOI3ASUqOpy4F7gQREpxemhLHaX3SQijwGbgRDwZVUNi8hw4EnnXD4+4GFVfcZd5S3AYyJyDbAb+Hi8ti2u8p2T9W373wbOSWwsxhjTR3FLKgCq+hTwVKey70dNN9PNh7+q3gzc3KlsBzCrm/rVwLzjDDnx3CvAkmq3E44oXk9Xp5eMMWZwsjvqB5uciUTwMF73UnG4KdHRGGNMn1hSGWx8SbSmj2OSVLDdrgAzxgwxllQGIRl2KpOlgu12BZgxZoixpDIIBYafykRPJW/sOpjoUIwxpk8sqQxCkncKAULs3LaFcKTz/aLGGDN4WVIZjNwrwIa17mZ9uQ2Db4wZOiypDEbuaMWnesp55W27CdIYM3RYUhmMUnJg2DQuDa6xpGKMGVIsqQxWsz/NKaG3aS7fwO7qxkRHY4wxvWJJZbCaeTnqDXCN7xn+9fitUL090REZY8wxWVIZrFJzkdMu4jLPS1xe+VPq/3pjoiMyxphjsqQymH3guzSd9TVe4Ey8ZS+xtXx/oiMyxpgeWVIZzHInkTz/RxR8+Csk08Jtd9/LnkN2fsUYM3hZUhkCJp05n4g/lfMo4X+f3pLocIwxpluWVIYCXxKeKR/kI8H1PLtxL69vt+FbjDGDkyWVoeL0j5PWepD7Uu7g63/4N+v22J32xpjBx5LKUDH1ozD/FuZGVnKX3MLn7n6Ru1/ZTmsokujIjDGmgyWVoeSsL8LH7ma2bubx5B/z+6df5ZI7/8nOgzZEvjFmcLCkMtTMuhxZ8ggF7GNF6neYefg5Pvqr1/jr+opER2aMMZZUhqRTPgzXvYp/xDRu0V9yR/Au/uuRf3HDY+vYf6Q50dEZY05illSGqpwJcPXTMHcpc1tf5sXcn/Gv9Vs47/9e4p5XdthzWIwxCRHXpCIi80Vkq4iUisjSLuYnicij7vyVIlIQNe9Gt3yriHzYLRsrIitEZIuIbBKR/4iq/0MR2Ssi69zXhfHctkHB64Pzb0Quf4iRLTv5Z+o3uTXnCe58ahUfuvVlfv1SKbWNbYmO0hhzEhHV+HyjFREv8DbwIaAcWA0sUdXNUXW+BMxU1etEZDHwMVW9XESmAY8Ac4BRwPPAKcAwYKSqrhWRdGANcImqbhaRHwL1qvqz3sZYXFysJSUlsdjcxNu/GV79Gbrpz7T6M3g8sJBnDw1nS7CIL5x/Ch+ZOZKRmcmJjtIYcwIQkTWqWtzVPF8c1zsHKFXVHW4Qy4CFwOaoOguBH7rTjwN3iIi45ctUtQXYKSKlwBxV/RdQCaCqdSKyBRjdqc2T0/BpsOg+5JwbSPr7f3LFnt9xRQC2eU/j2qc+z//8fSSFY7O4aGoWH6/7PRlzrkBGzkx01MaYE0w8D3+NBvZEvS93y7qso6ohoBbI7c2y7qGy2cDKqOLrRWSDiNwnItldBSUi14pIiYiUVFWdgA/AGjEDrnkW/msnXPIbpngreTH4Xzw39n5mNa9m/IrryXzjN7x11xVceOsK1ttNlMaYGIpnUpEuyjofa+uuTo/Likga8ATwNVU94hbfBUwCCnF6Mz/vKihVvVtVi1W1OD8/v+ctGMpScqBwCXx5FfLe65lSt4of1f2AD3nXUjb8AqZ6dnNewzNcdtfrfOOP63lqYyXb9tcRsRP8xpjjEM/DX+XA2Kj3Y4DON1O01ykXER+QCRzqaVkR8eMklIdU9U/tFVS1Y1x4EbkH+FvMtmQoSx8BH7oJzvs2bH8Bwm0UTFsIv/sI39xzL5dnvUbLpiO0bPRwVevXSR8xkW9fOJWZKYfIzMlHUnISvQXGmCEknj2V1cAUEZkgIgFgMbC8U53lwJXu9CLgRXWuHFgOLHavDpsATAFWuedb7gW2qOovohsSkZFRbz8GvBnzLRrK/EE47SMw/RIQgcvuRc66jvG5aUyefCrTgof4e97tBBr38ejvbif5nvdS9tNz+NYfXmHNrkOJjt4YM0TE7eovAPey3tsAL3Cfqt4sIjcBJaq6XESCwIM450YOAYujTux/B/gsEMI5zPW0iJwDvApsBNoHvfq2qj4lIg/iHPpSoAz4gqpW9hTfCXX11/Ha8RL84TKIhAA4mD6V7Lq3WckMvtD8FaZOGMMXzp3I7HHOqaqaxlYm5qXi5HljzMmkp6u/4ppUBjtLKp1Uroddr0O4DeZcCxv/CMuvp9mfxa8jl3FXw1za8OEjxESpZOrpxdyyaDbJAW+iIzfGDCBLKt2wpNILFevgue/DzpdpTh7OoeA4sutLSW6rYVNkPDfr1exKncXpozMZl5tCXXOIsybm8OHpIwj6vWyvqqeqroX3TMixXo0xJwhLKt2wpNJLqs5J/pL7oeEgZIyEMWfS/NqdBBr28djwr3F37ZmU1ytJPi91zSH8XiE3NYl97lhks8dl8ZUPTGbuKcM4UNfMQ//eTcmuQ9y0cAanDE9P8AYaY/rCkko3LKkcp+Yj8PjVUPq88z6YiY4uZnfKNNY2j6Ky2U/+6EmEM8dz24oy9h1pJuD1MDayhxrSaQvkoMAXzp3IlOFp5KUl0dAaprq+hdNHZzJ5WBoiQlNrmO1V9ZTXNDJzTBajsmI4MkDtXufChYxRsWvTmBOcJZVuWFKJgXDIOfdSVwmHd8Ge1XBgM0fdkiQeNHMcVUljaak/zNiGjUR8QZpOW8SDuzJ5rTqDMh1OheYRibogMcnnISvZx6H6RtrUS/vtS+NzU8hM9jN5WBpjs1NoaAlR1xwi4PPw/il55KUnUdPQyvaqekZnpXDeqfmkJvloC0c66gV9HmTHS8gfP02bL40XP7Cc4lMLyE9PGtj9dyL4151wpAI+fHOiIzEDxJJKNyypxEnzEagpg9Z6OLwbqrdDdSkc2g6hFii8Ag5uhY1PQKipY7GIx0/El4JHQ0TCITyREB7CTpPBYRw+ZREbW0fydl2A6rYAcvBtfC2HKfVOpCZpFHta06lq6frWK79XmBTZxQLvSh4OzeP93o38r+//sVuHUSD7+GN4Lt+JfIGRmUEON7bh9QhBv4eUgI8pw9IYl+OcL0oP+hieEWRYRhJtYaUlFCY3NUBqko+A10PA5+mYrqncyb5GKGtKZl9tE3lpSVxcOIq8tCTe3FvLP0sP8oGpwykcm3X07msLs/9IMxGF8TkpeDyD+FxUWxP87FRoOQL/sR6yxyc6IjMALKl0w5JKgkUiUL8PDu1wXtXboa0RPD7n5fW/M11eAqXPgfb8+OSwL5mI+PEQwUMEjYRpw0918nhG1L+FhzBtniD+SDO7Muewes5tnFXxAGM2/Za3cuaxMulsklLSaCXAsLotzDj8Am9GCvhzy5k0BXIY2baLrPAh1ulkKjWHkHrxSRgfYUJ42a3DUDyc5dnMPf6f00CQT7Z+h0lJh2lojfB6ZDqdB4yYnBtkRONb1KaMp80TZNShf7MpPJ795JCZ7Cc3LUCy39tx2K81FGF22iEUYVNTDnsPN5OW5GXqyAzqmkMcqGvmSEMzi5NXkZ0WZGPOBaQHfST7vbSGIozIDJKVEqCqroW0JB+ZyX4aW0PUt4SIqDI2O4WUgI8mN7l5RGhoCfHQyl1kJvv56rwphCKKAFP2P03m018CoGzaF5F532NstpMIVZXWcIQkn3N1oKqy82ADfq+HEZlB/N6jb5OrbWxjT00j00ZmDO5EGitrfw9HKuG8byU6kj6zpNINSypDTHMt1B+AxkPQfBhyJ0NyNuzb4JwbaTjgXEgQCYF43nm1NcK+N2HE6VD4SXjlZ85IA/NvAV/A6T2t+DGsud9ZR7QxZ8KBLU6vqxfaApm0BLJJaSinOX08Sa01eFpqEXV6XIdTJ3IkOBK/P4ns9GR217SSffhN8kOVtEiQJk8qWeFqQp4ge4efD7V7qPbkst03mXDTYTzAmEgF7237FwDlnlGsTf8Amyig4fAhzvDtoMB7gHHhPeSGnbHt7glfxJOh9zJMajhdduKXEIc1nbWRKfgJkSpN7NbhAGRRT6Y0kEkDfgmxOTKeDGlkguxjV+Yc3m5Kx990kCqyaMPHH/w3M04OUKqjmeEp470tt+P3JzE+N4WGw/vxtdRyODiW9OQAdc1t1DS2kUIz4zwHmJ5yhPrgSHb7CqhvDVFe04QqjM1J5pRh6VQfaeDjjctAIzwcXExWegrD04NkJPt5q7yK1uZGCkaP4u0DdeyrbWFyfgrFbCY3tJ+1GR8g7AkgIgjgESHg8zA2O4XkgIe2UIQZda9S29DM8pYi8lM8jMhKJTk5yCsbd9LY1MSpEwuYNiqDrGQ/hxpaSQ54yU0NkJ0aoLktTE1DG4ebWslKDjAqK0jA53GTegtVdS20hSOkBLyMTYOUYIA2ArRFImQEfYxo2s7IR+fj0RAPFdyMf/pCisZnMSwjSHqSr+NKSVWluS1CQ2uIPYcaqa5vZVhGEiMzk8lNDXQk7/qWEMl+J3k3tIZpag0T9HvITPYfddXl7upGKmqbmDoyg8xkf3//Ey2pdMeSijlKWxPU7IJQs5No0vIhZyK01DlJqbHaeZ8+Avaucd6HW8EbcHpTrQ1OeUsdpA2Dud+Cun3w8i1w6kdAw7D+EWd+JOScj4q0QfpImLUY9qx0kubMy2HLctj5KuSd4hxKrKtw1iFe8CfDnM9Daj689XfY+Qod57AC6ZA3BdJHoIVXwPYXkZJ7j9pMFQ9yjB5fdxRBUFQ8tCblkNR8kN2zvk7yuNnk//UztPrSqfXl0RJWRrXtwoNy2D+MJkkhqE2kaiOBUN1RbR725lAVGEu21JHZUkmZp4AyRjJJ9jKxdSsAO5JOo5J8WttCHAn7medZS4o2slam0hAcSZY/RF7DNkaH9wJOsl3lO4OICgFaSdIWNBJmT2sa9ZpMoaeU873rnfVLJmlaT5t62aLjmOEpI0CITTqRFeHTeSsyjqC0kkwLinBI37lasYZ08jlMpjSwPjKJed43eI9nC38Kn8MRTWW+dxXzPatpwc8T4XN5JXI69ZrM9/x/YLQcpFpyyKOGV8IzaNIA94cXEPB5GB1ooLwtg7K2TBo1SBKtzPes4lzvBnKoY4NO4lk9i7ODO8luqyIUifBWZBwbIhOpILcjvpSAD48IKQEvOakBKvdVki11VGou3104m0+fXdCvvwNLKt2wpGKGBFWnpxRIc65U66xuP9TvB3+K80RQj/foZXe9Dk01kJwFo2ZDINU5sV6+2mkzkAY1O52ElZztvtzzPJXrICkDssbB2886caSPdJZvOOAkxw/+CFJyYf0y2FvixBIJw8hZTuIre9WpF0iHpDQnKWcXQOZYqHoLyv7pJM6gu579m5yeJ8AHf+Ac8nzuB04y9XidZD7xPMgaD9uec3qXvoCT8E+7yGn/xf+Gmt3Oev3Jzr4RQRuqkLZG1J9K3Xu/RSBnLMG3/wrZBYRb6omUr8E3bg6SkoNufxH2rOroZfZWa/o4AnW7AYgkZVE94SKkqYac3c/iUWfECkXYd8FdjJx4Onr/AkL+NKSpBl+46V3thcWPV52H7bUl59McyCa99u3u1+9NwxtpQYjQ6kmmxZNCqwTQcIhh4X0d9SrOuZlRH7y+T9vWzpJKNyypGHMSiri9NE8vhj5sOuwk0EAK+FMBhYYqQJxk13QIUvKcRF2+GvJPheEzoOw159Dr2Pc4T2gFaKmHirVOL3jYVMgc45SrOl8WGg7ChsecpJ4+wknOdZVODL4kGHc2TJjrxF31Nux6Dcae5awz3OYk44q1ULXVicfjdXrPLfXvXBAzbJpz+XxtOUz5kPMlox8sqXTDkooxxvRdT0klrs+oN8YYc3KxpGKMMSZmLKkYY4yJGUsqxhhjYsaSijHGmJixpGKMMSZmLKkYY4yJGUsqxhhjYuakvvlRRKqAXf1cPA84GMNwYmmwxmZx9Y3F1XeDNbYTLa7xqprf1YyTOqkcDxEp6e6O0kQbrLFZXH1jcfXdYI3tZIrLDn8ZY4yJGUsqxhhjYsaSSv/dnegAejBYY7O4+sbi6rvBGttJE5edUzHGGBMz1lMxxhgTM5ZUjDHGxIwllX4QkfkislVESkVkaQLjGCsiK0Rki4hsEpH/cMt/KCJ7RWSd+7owAbGVichGd/0lblmOiDwnItvcn9kDHNOpUftknYgcEZGvJWp/ich9InJARN6MKutyH4njdvdvboOIFA1wXP8nIm+5635SRLLc8gIRaYrad78Z4Li6/d2JyI3u/toqIh+OV1w9xPZoVFxlIrLOLR+QfdbD50N8/8ZU1V59eAFeYDswEQgA64FpCYplJFDkTqcDbwPTgB8C30jwfioD8jqV/RRY6k4vBX6S4N/jPmB8ovYXcC5QBLx5rH0EXAg8DQhwFrBygOO6APC50z+Jiqsgul4C9leXvzv3/2A9kARMcP9nvQMZW6f5Pwe+P5D7rIfPh7j+jVlPpe/mAKWqukNVW4FlwMJEBKKqlaq61p2uA7YAoxMRSy8tBB5wpx8ALklgLPOA7ara3xEVjpuqvgIc6lTc3T5aCPxeHf8GskRk5EDFpar/UNWQ+/bfwJh4rLuvcfVgIbBMVVtUdSdQivO/O+CxiYgAnwAeidf6u4mpu8+HuP6NWVLpu9HAnqj35QyCD3IRKQBmAyvdouvdLux9A32YyaXAP0RkjYhc65YNV9VKcP7ggWEJiKvdYo7+J0/0/mrX3T4aTH93n8X5Rttugoi8ISIvi8j7ExBPV7+7wbS/3g/sV9VtUWUDus86fT7E9W/MkkrfSRdlCb0uW0TSgCeAr6nqEeAuYBJQCFTidL0H2vtUtQhYAHxZRM5NQAxdEpEAcDHwR7doMOyvYxkUf3ci8h0gBDzkFlUC41R1NnAD8LCIZAxgSN397gbF/nIt4egvMAO6z7r4fOi2ahdlfd5nllT6rhwYG/V+DFCRoFgQET/OH8xDqvonAFXdr6phVY0A9xDHbn93VLXC/XkAeNKNYX97d9r9eWCg43ItANaq6n43xoTvryjd7aOE/92JyJXARcAV6h6Edw8vVbvTa3DOXZwyUDH18LtL+P4CEBEfcCnwaHvZQO6zrj4fiPPfmCWVvlsNTBGRCe433sXA8kQE4h6rvRfYoqq/iCqPPg76MeDNzsvGOa5UEUlvn8Y5yfsmzn660q12JfCXgYwrylHfHBO9vzrpbh8tBz7jXqFzFlDbfghjIIjIfOBbwMWq2hhVni8iXnd6IjAF2DGAcXX3u1sOLBaRJBGZ4Ma1aqDiivJB4C1VLW8vGKh91t3nA/H+G4v3FQgn4gvnKom3cb5hfCeBcZyD0z3dAKxzXxcCDwIb3fLlwMgBjmsizpU364FN7fsIyAVeALa5P3MSsM9SgGogM6osIfsLJ7FVAm043xKv6W4f4RyauNP9m9sIFA9wXKU4x9vb/85+49a9zP0drwfWAh8d4Li6/d0B33H311ZgwUD/Lt3y3wHXdao7IPush8+HuP6N2TAtxhhjYsYOfxljjIkZSyrGGGNixpKKMcaYmLGkYowxJmYsqRhjjIkZSyrGDFEicp6I/C3RcRgTzZKKMcaYmLGkYkycicinRGSV++yM34qIV0TqReTnIrJWRF4QkXy3bqGI/FveeW5J+7MuJovI8yKy3l1mktt8mog8Ls6zTh5y76I2JmEsqRgTRyIyFbgcZ4DNQiAMXAGk4ow/VgS8DPzAXeT3wLdUdSbOXc3t5Q8Bd6rqLOC9OHdvgzPy7NdwnpMxEXhf3DfKmB74Eh2AMSe4ecAZwGq3E5GMM4BfhHcGGfwD8CcRyQSyVPVlt/wB4I/uOGqjVfVJAFVtBnDbW6XuuFLiPFmwAHgt/ptlTNcsqRgTXwI8oKo3HlUo8r1O9XoaL6mnQ1otUdNh7H/aJJgd/jImvl4AFonIMOh4Pvh4nP+9RW6dTwKvqWotUBP10KZPAy+r8wyMchG5xG0jSURSBnQrjOkl+1ZjTByp6mYR+S7OUzA9OKPYfhloAKaLyBqgFue8CzhDkf/GTRo7gKvd8k8DvxWRm9w2Pj6Am2FMr9koxcYkgIjUq2paouMwJtbs8JcxxpiYsZ6KMcaYmLGeijHGmJixpGKMMSZmLKkYY4yJGUsqxhhjYsaSijHGmJj5/xdlLBkzxASOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Con_AE loss\n",
    "plt.plot(ae_train['loss'])\n",
    "plt.plot(ae_train['val_loss'])\n",
    "plt.title('Conv_AE model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.017745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.002270\n",
       "std      0.002299\n",
       "min      0.001331\n",
       "25%      0.001409\n",
       "50%      0.001511\n",
       "75%      0.001839\n",
       "max      0.017745"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(ae_train['loss'])\n",
    "loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.017128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.002177\n",
       "std      0.002251\n",
       "min      0.001256\n",
       "25%      0.001335\n",
       "50%      0.001421\n",
       "75%      0.001709\n",
       "max      0.017128"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = pd.DataFrame(ae_train['val_loss'])\n",
    "val_loss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder.predict(x_text_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded data\n",
    "\n",
    "encoded_data = encoded_data.reshape(-1, 5*2)\n",
    "\n",
    "# transform to SOM input type\n",
    "encoded_som = pd.DataFrame(encoded_data)\n",
    "#decoded_som = pd.DataFrame(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59157705"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.371149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.593048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.604938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.623924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.409046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.641388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.605050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.369724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.458377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.305204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.401067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.391451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.388346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.288046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.379741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.384114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.367234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1    2         3    4         5    6         7    8         9\n",
       "0  0.0  1.371149  0.0  1.593048  0.0  1.604938  0.0  1.623924  0.0  0.907349\n",
       "1  0.0  1.409046  0.0  1.641388  0.0  1.646178  0.0  1.605050  0.0  0.924437\n",
       "2  0.0  1.369724  0.0  1.446093  0.0  1.458377  0.0  1.394984  0.0  0.864227\n",
       "3  0.0  1.305204  0.0  1.401067  0.0  1.391451  0.0  1.388346  0.0  0.843543\n",
       "4  0.0  1.288046  0.0  1.379741  0.0  1.384114  0.0  1.367234  0.0  0.835359"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_som.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.138076</td>\n",
       "      <td>1.426342</td>\n",
       "      <td>1.437318</td>\n",
       "      <td>1.443515</td>\n",
       "      <td>0.682963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.002539</td>\n",
       "      <td>1.326898</td>\n",
       "      <td>1.377075</td>\n",
       "      <td>1.343874</td>\n",
       "      <td>0.645719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.852720</td>\n",
       "      <td>1.250983</td>\n",
       "      <td>1.299184</td>\n",
       "      <td>1.290081</td>\n",
       "      <td>0.663860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.956343</td>\n",
       "      <td>1.265429</td>\n",
       "      <td>1.296823</td>\n",
       "      <td>1.307425</td>\n",
       "      <td>0.646354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.889550</td>\n",
       "      <td>1.355648</td>\n",
       "      <td>1.330567</td>\n",
       "      <td>1.409474</td>\n",
       "      <td>0.612648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4\n",
       "1995  1.138076  1.426342  1.437318  1.443515  0.682963\n",
       "1996  1.002539  1.326898  1.377075  1.343874  0.645719\n",
       "1997  0.852720  1.250983  1.299184  1.290081  0.663860\n",
       "1998  0.956343  1.265429  1.296823  1.307425  0.646354\n",
       "1999  0.889550  1.355648  1.330567  1.409474  0.612648"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero = list(map(lambda i: any(encoded_data[:,i] != 0), range(encoded_data.shape[1])))\n",
    "\n",
    "encoded_som_nonzero = pd.DataFrame(encoded_data[:,nonzero])\n",
    "\n",
    "encoded_som_nonzero.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_som_nonzero.to_csv(path_or_buf='./sat_ConAE_encoded.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
